// Merged C++ file generated by script
// Total files merged: 60
// WARNING: Review this file carefully for compilation and logic errors.
// Issues like multiple main() functions, global variable redefinitions,
// and order-dependent declarations might need manual fixing.

// --- Unique Global Includes (from all files) ---
#include <../RISCV/specialize.h>
#include <VX_config.h>
#include <VX_types.h>
#include <algorithm>
#include <array>
#include <assert.h>
#include <base/base.h>
#include <base/config.h>
#include <base/request.h>
#include <bitmanip.h>
#include <bitset>
#include <bitvector.h>
#include <cassert>
#include <climits>
#include <cstdint>
#include <cstdlib>
#include <dram_sim.h>
#include <frontend/frontend.h>
#include <fstream>
#include <functional>
#include <internals.h>
#include <iomanip>
#include <iostream>
#include <limits>
#include <list>
#include <map>
#include <math.h>
#include <mem.h>
#include <memory>
#include <memory_system/memory_system.h>
#include <queue>
#include <rvfloats.h>
#include <simobject.h>
#include <softfloat.h>
#include <softfloat_types.h>
#include <sstream>
#include <stack>
#include <stdbool.h>
#include <stdexcept>
#include <stdint.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <string>
#include <stringutil.h>
#include <sys/stat.h>
#include <sys/types.h>
#include <unistd.h>
#include <unordered_map>
#include <unordered_set>
#include <util.h>
#include <vector>
// --- End of Unique Global Includes ---

// --- Start of content from sim/include/VX_types.h ---
// Original include guard: VX_TYPES_VH
// auto-generated by gen_config.py. DO NOT EDIT
// Generated at 2025-05-05 15:38:08.400286

// Translated from /vortex/hw/rtl/VX_types.vh:

// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


// Device configuration registers /////////////////////////////////////////////

#define VX_CSR_ADDR_BITS                12
#define VX_DCR_ADDR_BITS                12

#define VX_DCR_BASE_STATE_BEGIN         0x001
#define VX_DCR_BASE_STARTUP_ADDR0       0x001
#define VX_DCR_BASE_STARTUP_ADDR1       0x002
#define VX_DCR_BASE_STARTUP_ARG0        0x003
#define VX_DCR_BASE_STARTUP_ARG1        0x004
#define VX_DCR_BASE_MPM_CLASS           0x005
#define VX_DCR_BASE_STATE_END           0x006

#define VX_DCR_BASE_STATE(addr)         ((addr) - VX_DCR_BASE_STATE_BEGIN)
#define VX_DCR_BASE_STATE_COUNT         (VX_DCR_BASE_STATE_END-VX_DCR_BASE_STATE_BEGIN)

// Machine Performance-monitoring counters classes ////////////////////////////

#define VX_DCR_MPM_CLASS_NONE           0
#define VX_DCR_MPM_CLASS_CORE           1
#define VX_DCR_MPM_CLASS_MEM            2

// User Floating-Point CSRs ///////////////////////////////////////////////////

#define VX_CSR_FFLAGS                   0x001
#define VX_CSR_FRM                      0x002
#define VX_CSR_FCSR                     0x003

#define VX_CSR_SATP                     0x180

#define VX_CSR_PMPCFG0                  0x3A0
#define VX_CSR_PMPADDR0                 0x3B0

#define VX_CSR_MSTATUS                  0x300
#define VX_CSR_MISA                     0x301
#define VX_CSR_MEDELEG                  0x302
#define VX_CSR_MIDELEG                  0x303
#define VX_CSR_MIE                      0x304
#define VX_CSR_MTVEC                    0x305

#define VX_CSR_MSCRATCH                 0x340
#define VX_CSR_MEPC                     0x341
#define VX_CSR_MCAUSE                   0x342

#define VX_CSR_MNSTATUS                 0x744

#define VX_CSR_MPM_BASE                 0xB00
#define VX_CSR_MPM_BASE_H               0xB80
#define VX_CSR_MPM_USER                 0xB03
#define VX_CSR_MPM_USER_H               0xB83

// Machine Performance-monitoring core counters (Standard) ////////////////////

#define VX_CSR_MCYCLE                   0xB00
#define VX_CSR_MCYCLE_H                 0xB80
#define VX_CSR_MPM_RESERVED             0xB01
#define VX_CSR_MPM_RESERVED_H           0xB81
#define VX_CSR_MINSTRET                 0xB02
#define VX_CSR_MINSTRET_H               0xB82

// Machine Performance-monitoring core counters (class 1) /////////////////////

// PERF: pipeline
#define VX_CSR_MPM_SCHED_ID             0xB03
#define VX_CSR_MPM_SCHED_ID_H           0xB83
#define VX_CSR_MPM_SCHED_ST             0xB04
#define VX_CSR_MPM_SCHED_ST_H           0xB84
#define VX_CSR_MPM_IBUF_ST              0xB05
#define VX_CSR_MPM_IBUF_ST_H            0xB85
#define VX_CSR_MPM_SCRB_ST              0xB06
#define VX_CSR_MPM_SCRB_ST_H            0xB86
#define VX_CSR_MPM_OPDS_ST              0xB07
#define VX_CSR_MPM_OPDS_ST_H            0xB87
#define VX_CSR_MPM_SCRB_ALU             0xB08
#define VX_CSR_MPM_SCRB_ALU_H           0xB88
#define VX_CSR_MPM_SCRB_FPU             0xB09
#define VX_CSR_MPM_SCRB_FPU_H           0xB89
#define VX_CSR_MPM_SCRB_LSU             0xB0A
#define VX_CSR_MPM_SCRB_LSU_H           0xB8A
#define VX_CSR_MPM_SCRB_SFU             0xB0B
#define VX_CSR_MPM_SCRB_SFU_H           0xB8B
#define VX_CSR_MPM_SCRB_CSRS            0xB0C
#define VX_CSR_MPM_SCRB_CSRS_H          0xB8C
#define VX_CSR_MPM_SCRB_WCTL            0xB0D
#define VX_CSR_MPM_SCRB_WCTL_H          0xB8D
// PERF: memory
#define VX_CSR_MPM_IFETCHES             0xB0E
#define VX_CSR_MPM_IFETCHES_H           0xB8E
#define VX_CSR_MPM_LOADS                0xB0F
#define VX_CSR_MPM_LOADS_H              0xB8F
#define VX_CSR_MPM_STORES               0xB10
#define VX_CSR_MPM_STORES_H             0xB90
#define VX_CSR_MPM_IFETCH_LT            0xB11
#define VX_CSR_MPM_IFETCH_LT_H          0xB91
#define VX_CSR_MPM_LOAD_LT              0xB12
#define VX_CSR_MPM_LOAD_LT_H            0xB92

// Machine Performance-monitoring memory counters (class 2) ///////////////////

// PERF: icache
#define VX_CSR_MPM_ICACHE_READS         0xB03     // total reads
#define VX_CSR_MPM_ICACHE_READS_H       0xB83
#define VX_CSR_MPM_ICACHE_MISS_R        0xB04     // read misses
#define VX_CSR_MPM_ICACHE_MISS_R_H      0xB84
#define VX_CSR_MPM_ICACHE_MSHR_ST       0xB05     // MSHR stalls
#define VX_CSR_MPM_ICACHE_MSHR_ST_H     0xB85
// PERF: dcache
#define VX_CSR_MPM_DCACHE_READS         0xB06     // total reads
#define VX_CSR_MPM_DCACHE_READS_H       0xB86
#define VX_CSR_MPM_DCACHE_WRITES        0xB07     // total writes
#define VX_CSR_MPM_DCACHE_WRITES_H      0xB87
#define VX_CSR_MPM_DCACHE_MISS_R        0xB08     // read misses
#define VX_CSR_MPM_DCACHE_MISS_R_H      0xB88
#define VX_CSR_MPM_DCACHE_MISS_W        0xB09     // write misses
#define VX_CSR_MPM_DCACHE_MISS_W_H      0xB89
#define VX_CSR_MPM_DCACHE_BANK_ST       0xB0A     // bank conflicts
#define VX_CSR_MPM_DCACHE_BANK_ST_H     0xB8A
#define VX_CSR_MPM_DCACHE_MSHR_ST       0xB0B     // MSHR stalls
#define VX_CSR_MPM_DCACHE_MSHR_ST_H     0xB8B
// PERF: l2cache
#define VX_CSR_MPM_L2CACHE_READS        0xB0C     // total reads
#define VX_CSR_MPM_L2CACHE_READS_H      0xB8C
#define VX_CSR_MPM_L2CACHE_WRITES       0xB0D     // total writes
#define VX_CSR_MPM_L2CACHE_WRITES_H     0xB8D
#define VX_CSR_MPM_L2CACHE_MISS_R       0xB0E     // read misses
#define VX_CSR_MPM_L2CACHE_MISS_R_H     0xB8E
#define VX_CSR_MPM_L2CACHE_MISS_W       0xB0F     // write misses
#define VX_CSR_MPM_L2CACHE_MISS_W_H     0xB8F
#define VX_CSR_MPM_L2CACHE_BANK_ST      0xB10     // bank conflicts
#define VX_CSR_MPM_L2CACHE_BANK_ST_H    0xB90
#define VX_CSR_MPM_L2CACHE_MSHR_ST      0xB11     // MSHR stalls
#define VX_CSR_MPM_L2CACHE_MSHR_ST_H    0xB91
// PERF: l3cache
#define VX_CSR_MPM_L3CACHE_READS        0xB12     // total reads
#define VX_CSR_MPM_L3CACHE_READS_H      0xB92
#define VX_CSR_MPM_L3CACHE_WRITES       0xB13     // total writes
#define VX_CSR_MPM_L3CACHE_WRITES_H     0xB93
#define VX_CSR_MPM_L3CACHE_MISS_R       0xB14     // read misses
#define VX_CSR_MPM_L3CACHE_MISS_R_H     0xB94
#define VX_CSR_MPM_L3CACHE_MISS_W       0xB15     // write misses
#define VX_CSR_MPM_L3CACHE_MISS_W_H     0xB95
#define VX_CSR_MPM_L3CACHE_BANK_ST      0xB16     // bank conflicts
#define VX_CSR_MPM_L3CACHE_BANK_ST_H    0xB96
#define VX_CSR_MPM_L3CACHE_MSHR_ST      0xB17     // MSHR stalls
#define VX_CSR_MPM_L3CACHE_MSHR_ST_H    0xB97
// PERF: memory
#define VX_CSR_MPM_MEM_READS            0xB18     // total reads
#define VX_CSR_MPM_MEM_READS_H          0xB98
#define VX_CSR_MPM_MEM_WRITES           0xB19     // total writes
#define VX_CSR_MPM_MEM_WRITES_H         0xB99
#define VX_CSR_MPM_MEM_LT               0xB1A     // memory latency
#define VX_CSR_MPM_MEM_LT_H             0xB9A
#define VX_CSR_MPM_MEM_BANK_ST          0xB1E     // bank conflicts
#define VX_CSR_MPM_MEM_BANK_ST_H        0xB9E
// PERF: lmem
#define VX_CSR_MPM_LMEM_READS           0xB1B     // memory reads
#define VX_CSR_MPM_LMEM_READS_H         0xB9B
#define VX_CSR_MPM_LMEM_WRITES          0xB1C     // memory writes
#define VX_CSR_MPM_LMEM_WRITES_H        0xB9C
#define VX_CSR_MPM_LMEM_BANK_ST         0xB1D     // bank conflicts
#define VX_CSR_MPM_LMEM_BANK_ST_H       0xB9D
// PERF: coalescer
#define VX_CSR_MPM_COALESCER_MISS       0xB1F     // coalescer misses
#define VX_CSR_MPM_COALESCER_MISS_H     0xB9F

// Machine Performance-monitoring memory counters (class 3) ///////////////////
// <Add your own counters: use addresses hB03..B1F, hB83..hB9F>

// Machine Information Registers //////////////////////////////////////////////

#define VX_CSR_MVENDORID                0xF11
#define VX_CSR_MARCHID                  0xF12
#define VX_CSR_MIMPID                   0xF13
#define VX_CSR_MHARTID                  0xF14

// Vector CSRs

#define VX_CSR_VSTART                   0x008
#define VX_CSR_VXSAT                    0x009
#define VX_CSR_VXRM                     0x00A
#define VX_CSR_VCSR                     0x00F
#define VX_CSR_VL                       0xC20
#define VX_CSR_VTYPE                    0xC21
#define VX_CSR_VLENB                    0xC22
#define VX_CSR_VCYCLE                   0xC00
#define VX_CSR_VTIME                    0xC01
#define VX_CSR_VINSTRET                 0xC02

// GPGU CSRs

#define VX_CSR_THREAD_ID                0xCC0
#define VX_CSR_WARP_ID                  0xCC1
#define VX_CSR_CORE_ID                  0xCC2
#define VX_CSR_ACTIVE_WARPS             0xCC3
#define VX_CSR_ACTIVE_THREADS           0xCC4     // warning! this value is also used in LLVM

#define VX_CSR_NUM_THREADS              0xFC0
#define VX_CSR_NUM_WARPS                0xFC1
#define VX_CSR_NUM_CORES                0xFC2
#define VX_CSR_LOCAL_MEM_BASE           0xFC3

#define VX_MAT_MUL_SIZE                 0xFC4     // VX_MAT_MUL_SIZE = Matrix Size / TC Size
#define VX_TC_NUM                       0xFC5
#define VX_TC_SIZE                      0xFC6



// --- End of content from sim/include/VX_types.h ---

// --- Start of content from sim/include/VX_config.h ---
// Original include guard: VX_CONFIG_VH
// auto-generated by gen_config.py. DO NOT EDIT
// Generated at 2025-05-05 15:38:08.378583

// Translated from /vortex/hw/rtl/VX_config.vh:

// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


#ifndef MIN
#define MIN(x, y)   (((x) < (y)) ? (x) : (y))

#ifndef MAX
#define MAX(x, y)   (((x) > (y)) ? (x) : (y))

#ifndef CLAMP
#define CLAMP(x, lo, hi)   (((x) > (hi)) ? (hi) : (((x) < (lo)) ? (lo) : (x)))

#ifndef UP
#define UP(x)   (((x) != 0) ? (x) : 1)

///////////////////////////////////////////////////////////////////////////////
#ifndef EXT_M_DISABLE
#define EXT_M_ENABLE

#ifndef EXT_F_DISABLE
#define EXT_F_ENABLE

#ifdef XLEN_64
#ifndef FPU_DSP
#ifndef EXT_D_DISABLE
#define EXT_D_ENABLE

#ifndef EXT_ZICOND_DISABLE
#define EXT_ZICOND_ENABLE

#ifndef XLEN_32
#ifndef XLEN_64
#define XLEN_32

#ifdef XLEN_64
#define XLEN 64

#ifdef XLEN_32
#define XLEN 32

#ifdef EXT_D_ENABLE
#define FLEN_64
#else
#define FLEN_32

#ifdef FLEN_64
#define FLEN 64

#ifdef FLEN_32
#define FLEN 32

#ifdef XLEN_64
#ifdef FLEN_32
    #define FPU_RV64F

#ifndef VLEN
#define VLEN 256

#ifndef NUM_CLUSTERS
#define NUM_CLUSTERS 1

#ifndef NUM_CORES
#define NUM_CORES 1

#ifndef NUM_WARPS
#define NUM_WARPS 4

#ifndef NUM_THREADS
#define NUM_THREADS 4

#ifndef NUM_BARRIERS
#define NUM_BARRIERS UP(NUM_WARPS/2)

#ifndef SOCKET_SIZE
#define SOCKET_SIZE MIN(4, NUM_CORES)

// Size of Tensor Core
#ifndef TC_SIZE
#define TC_SIZE 8

// Number of TCs per Warp
#ifndef TC_NUM
#define TC_NUM 4

#ifndef NUM_TCU_LANES
#define NUM_TCU_LANES   TC_NUM

#ifndef NUM_TCU_BLOCKS
#define NUM_TCU_BLOCKS  ISSUE_WIDTH

#ifdef L2_ENABLE
    #define L2_ENABLED   1
#else
    #define L2_ENABLED   0

#ifdef L3_ENABLE
    #define L3_ENABLED   1
#else
    #define L3_ENABLED   0

#ifdef L1_DISABLE
    #define ICACHE_DISABLE
    #define DCACHE_DISABLE

#ifndef MEM_BLOCK_SIZE
#define MEM_BLOCK_SIZE 64

#ifndef MEM_ADDR_WIDTH
#ifdef XLEN_64
#define MEM_ADDR_WIDTH 48
#else
#define MEM_ADDR_WIDTH 32

#ifndef L1_LINE_SIZE
#define L1_LINE_SIZE MEM_BLOCK_SIZE

#ifndef L2_LINE_SIZE
#define L2_LINE_SIZE MEM_BLOCK_SIZE

#ifndef L3_LINE_SIZE
#define L3_LINE_SIZE MEM_BLOCK_SIZE

// Platform memory parameters

#ifndef PLATFORM_MEMORY_NUM_BANKS
#define PLATFORM_MEMORY_NUM_BANKS 2

#ifndef PLATFORM_MEMORY_ADDR_WIDTH
#ifdef XLEN_64
    #define PLATFORM_MEMORY_ADDR_WIDTH 48
#else
    #define PLATFORM_MEMORY_ADDR_WIDTH 32

#ifndef PLATFORM_MEMORY_DATA_SIZE
#define PLATFORM_MEMORY_DATA_SIZE 64

#ifndef PLATFORM_MEMORY_INTERLEAVE
#define PLATFORM_MEMORY_INTERLEAVE 1

#ifdef XLEN_64

#ifndef STACK_BASE_ADDR
#define STACK_BASE_ADDR 0x1FFFF0000

#ifndef STARTUP_ADDR
#define STARTUP_ADDR    0x080000000

#ifndef USER_BASE_ADDR
#define USER_BASE_ADDR  0x000010000

#ifndef IO_BASE_ADDR
#define IO_BASE_ADDR    0x000000040

#ifdef VM_ENABLE
#ifndef PAGE_TABLE_BASE_ADDR
#define PAGE_TABLE_BASE_ADDR 0x0F0000000


#else // XLEN_32

#ifndef STACK_BASE_ADDR
#define STACK_BASE_ADDR 0xFFFF0000

#ifndef STARTUP_ADDR
#define STARTUP_ADDR    0x80000000

#ifndef USER_BASE_ADDR
#define USER_BASE_ADDR  0x00010000

#ifndef IO_BASE_ADDR
#define IO_BASE_ADDR    0x00000040

#ifdef VM_ENABLE
#ifndef PAGE_TABLE_BASE_ADDR
#define PAGE_TABLE_BASE_ADDR 0xF0000000



#define IO_END_ADDR     USER_BASE_ADDR

#ifndef LMEM_LOG_SIZE
#define LMEM_LOG_SIZE   14

#ifndef LMEM_BASE_ADDR
#define LMEM_BASE_ADDR  STACK_BASE_ADDR

#ifndef IO_COUT_ADDR
#define IO_COUT_ADDR    IO_BASE_ADDR
#define IO_COUT_SIZE    64

#ifndef IO_MPM_ADDR
#define IO_MPM_ADDR     (IO_COUT_ADDR + IO_COUT_SIZE)
#define IO_MPM_SIZE     (8 * 32 * NUM_CORES * NUM_CLUSTERS)

#ifndef STACK_LOG2_SIZE
#define STACK_LOG2_SIZE 13
#define STACK_SIZE      (1 << STACK_LOG2_SIZE)

#define RESET_DELAY     8

#ifndef STALL_TIMEOUT
#define STALL_TIMEOUT   (100000 * (1 ** (L2_ENABLED + L3_ENABLED)))

#ifndef SV_DPI
#ifndef DPI_DISABLE
#define DPI_DISABLE

#ifndef FPU_FPNEW
#ifndef FPU_DSP
#ifndef FPU_DPI
#ifndef SYNTHESIS
#ifndef DPI_DISABLE
#define FPU_DPI
#else
#define FPU_DSP
#else
#define FPU_DSP

#ifndef SYNTHESIS
#ifndef DPI_DISABLE
#define IMUL_DPI
#define IDIV_DPI

#ifndef DEBUG_LEVEL
#define DEBUG_LEVEL 3

#ifndef MEM_PAGE_SIZE
#define MEM_PAGE_SIZE (4096)
#ifndef MEM_PAGE_LOG2_SIZE
#define MEM_PAGE_LOG2_SIZE (12)

// Virtual Memory Configuration ///////////////////////////////////////////////////////
#ifdef VM_ENABLE
    #ifdef XLEN_32
        #ifndef VM_ADDR_MODE
        #define VM_ADDR_MODE SV32  //or BARE
        #ifndef PT_LEVEL
        #define PT_LEVEL (2)
        #ifndef PTE_SIZE
        #define PTE_SIZE (4)
        #ifndef NUM_PTE_ENTRY
        #define NUM_PTE_ENTRY (1024)
        #ifndef PT_SIZE_LIMIT
        #define PT_SIZE_LIMIT (1<<23)
    #else
        #ifndef VM_ADDR_MODE
        #define VM_ADDR_MODE SV39 //or BARE
        #ifndef PT_LEVEL
        #define PT_LEVEL (3)
        #ifndef PTE_SIZE
        #define PTE_SIZE (8)
        #ifndef NUM_PTE_ENTRY
        #define NUM_PTE_ENTRY (512)
        #ifndef PT_SIZE_LIMIT
        #define PT_SIZE_LIMIT (1<<25)

    #ifndef PT_SIZE
    #define PT_SIZE MEM_PAGE_SIZE

    #ifndef TLB_SIZE
    #define TLB_SIZE (32)


// Pipeline Configuration /////////////////////////////////////////////////////

// Issue width
#ifndef ISSUE_WIDTH
#define ISSUE_WIDTH     UP(NUM_WARPS / 8)

// Number of ALU units
#ifndef NUM_ALU_LANES
#define NUM_ALU_LANES   NUM_THREADS
#ifndef NUM_ALU_BLOCKS
#define NUM_ALU_BLOCKS  ISSUE_WIDTH

// Number of FPU units
#ifndef NUM_FPU_LANES
#define NUM_FPU_LANES   NUM_THREADS
#ifndef NUM_FPU_BLOCKS
#define NUM_FPU_BLOCKS  ISSUE_WIDTH

// Number of LSU units
#ifndef NUM_LSU_LANES
#define NUM_LSU_LANES   NUM_THREADS
#ifndef NUM_LSU_BLOCKS
#define NUM_LSU_BLOCKS  1

// Number of SFU units
#ifndef NUM_SFU_LANES
#define NUM_SFU_LANES   NUM_THREADS
#ifndef NUM_SFU_BLOCKS
#define NUM_SFU_BLOCKS  1

// Size of Instruction Buffer
#ifndef IBUF_SIZE
#define IBUF_SIZE   4

// LSU line size
#ifndef LSU_LINE_SIZE
#define LSU_LINE_SIZE   MIN(NUM_LSU_LANES * (XLEN / 8), L1_LINE_SIZE)

// Size of LSU Core Request Queue
#ifndef LSUQ_IN_SIZE
#define LSUQ_IN_SIZE    (2 * (NUM_THREADS / NUM_LSU_LANES))

// Size of LSU Memory Request Queue
#ifndef LSUQ_OUT_SIZE
#define LSUQ_OUT_SIZE   MAX(LSUQ_IN_SIZE, LSU_LINE_SIZE / (XLEN / 8))

#ifdef GBAR_ENABLE
#define GBAR_ENABLED 1
#else
#define GBAR_ENABLED 0

#ifndef LATENCY_IMUL
#ifdef VIVADO
#define LATENCY_IMUL 4
#ifdef QUARTUS
#define LATENCY_IMUL 3
#ifndef LATENCY_IMUL
#define LATENCY_IMUL 4

// Floating-Point Units ///////////////////////////////////////////////////////

// Size of FPU Request Queue
#ifndef FPUQ_SIZE
#define FPUQ_SIZE (2 * (NUM_THREADS / NUM_FPU_LANES))

// FNCP Latency
#ifndef LATENCY_FNCP
#define LATENCY_FNCP 2

// FMA Latency
#ifndef LATENCY_FMA
#ifdef FPU_DPI
#define LATENCY_FMA 4
#ifdef FPU_FPNEW
#define LATENCY_FMA 4
#ifdef FPU_DSP
#ifdef QUARTUS
#define LATENCY_FMA 4
#ifdef VIVADO
#define LATENCY_FMA 16
#ifndef LATENCY_FMA
#define LATENCY_FMA 4

// FDIV Latency
#ifndef LATENCY_FDIV
#ifdef FPU_DPI
#define LATENCY_FDIV 15
#ifdef FPU_FPNEW
#define LATENCY_FDIV 16
#ifdef FPU_DSP
#ifdef QUARTUS
#define LATENCY_FDIV 15
#ifdef VIVADO
#define LATENCY_FDIV 28
#ifndef LATENCY_FDIV
#define LATENCY_FDIV 16

// FSQRT Latency
#ifndef LATENCY_FSQRT
#ifdef FPU_DPI
#define LATENCY_FSQRT 10
#ifdef FPU_FPNEW
#define LATENCY_FSQRT 16
#ifdef FPU_DSP
#ifdef QUARTUS
#define LATENCY_FSQRT 10
#ifdef VIVADO
#define LATENCY_FSQRT 28
#ifndef LATENCY_FSQRT
#define LATENCY_FSQRT 16

// FCVT Latency
#ifndef LATENCY_FCVT
#define LATENCY_FCVT 5

// FMA Bandwidth ratio
#ifndef FMA_PE_RATIO
#define FMA_PE_RATIO 1

// FDIV Bandwidth ratio
#ifndef FDIV_PE_RATIO
#define FDIV_PE_RATIO 8

// FSQRT Bandwidth ratio
#ifndef FSQRT_PE_RATIO
#define FSQRT_PE_RATIO 8

// FCVT Bandwidth ratio
#ifndef FCVT_PE_RATIO
#define FCVT_PE_RATIO 8

// FNCP Bandwidth ratio
#ifndef FNCP_PE_RATIO
#define FNCP_PE_RATIO 2

// Icache Configurable Knobs //////////////////////////////////////////////////

// Cache Enable
#ifndef ICACHE_DISABLE
#define ICACHE_ENABLE
#ifdef ICACHE_ENABLE
    #define ICACHE_ENABLED 1
#else
    #define ICACHE_ENABLED 0
    #define NUM_ICACHES 0

// Number of Cache Units
#ifndef NUM_ICACHES
#define NUM_ICACHES UP(SOCKET_SIZE / 4)

// Cache Size
#ifndef ICACHE_SIZE
#define ICACHE_SIZE 16384

// Core Response Queue Size
#ifndef ICACHE_CRSQ_SIZE
#define ICACHE_CRSQ_SIZE 2

// Miss Handling Register Size
#ifndef ICACHE_MSHR_SIZE
#define ICACHE_MSHR_SIZE 16

// Memory Request Queue Size
#ifndef ICACHE_MREQ_SIZE
#define ICACHE_MREQ_SIZE 4

// Memory Response Queue Size
#ifndef ICACHE_MRSQ_SIZE
#define ICACHE_MRSQ_SIZE 0

// Number of Associative Ways
#ifndef ICACHE_NUM_WAYS
#define ICACHE_NUM_WAYS 4

// Replacement Policy
#ifndef ICACHE_REPL_POLICY
#define ICACHE_REPL_POLICY 1

#ifndef ICACHE_MEM_PORTS
#define ICACHE_MEM_PORTS 1

// Dcache Configurable Knobs //////////////////////////////////////////////////

// Cache Enable
#ifndef DCACHE_DISABLE
#define DCACHE_ENABLE
#ifdef DCACHE_ENABLE
    #define DCACHE_ENABLED 1
#else
    #define DCACHE_ENABLED 0
    #define NUM_DCACHES 0
    #define DCACHE_NUM_BANKS 1

// Number of Cache Units
#ifndef NUM_DCACHES
#define NUM_DCACHES UP(SOCKET_SIZE / 4)

// Cache Size
#ifndef DCACHE_SIZE
#define DCACHE_SIZE 16384

// Number of Banks
#ifndef DCACHE_NUM_BANKS
#define DCACHE_NUM_BANKS MIN(DCACHE_NUM_REQS, 16)

// Core Response Queue Size
#ifndef DCACHE_CRSQ_SIZE
#define DCACHE_CRSQ_SIZE 2

// Miss Handling Register Size
#ifndef DCACHE_MSHR_SIZE
#define DCACHE_MSHR_SIZE 16

// Memory Request Queue Size
#ifndef DCACHE_MREQ_SIZE
#define DCACHE_MREQ_SIZE 4

// Memory Response Queue Size
#ifndef DCACHE_MRSQ_SIZE
#define DCACHE_MRSQ_SIZE 4

// Number of Associative Ways
#ifndef DCACHE_NUM_WAYS
#define DCACHE_NUM_WAYS 4

// Enable Cache Writeback
#ifndef DCACHE_WRITEBACK
#define DCACHE_WRITEBACK 0

// Enable Cache Dirty bytes
#ifndef DCACHE_DIRTYBYTES
#define DCACHE_DIRTYBYTES DCACHE_WRITEBACK

// Replacement Policy
#ifndef DCACHE_REPL_POLICY
#define DCACHE_REPL_POLICY 1

// Number of Memory Ports
#ifndef L1_MEM_PORTS
#ifdef L1_DISABLE
#define L1_MEM_PORTS MIN(DCACHE_NUM_REQS, PLATFORM_MEMORY_NUM_BANKS)
#else
#define L1_MEM_PORTS MIN(DCACHE_NUM_BANKS, PLATFORM_MEMORY_NUM_BANKS)

// LMEM Configurable Knobs ////////////////////////////////////////////////////

#ifndef LMEM_DISABLE
#define LMEM_ENABLE

#ifdef LMEM_ENABLE
    #define LMEM_ENABLED   1
#else
    #define LMEM_ENABLED   0
    #define LMEM_NUM_BANKS 1

// Number of Banks
#ifndef LMEM_NUM_BANKS
#define LMEM_NUM_BANKS NUM_LSU_LANES

// L2cache Configurable Knobs /////////////////////////////////////////////////

// Cache Size
#ifndef L2_CACHE_SIZE
#define L2_CACHE_SIZE 1048576

// Number of Banks
#ifndef L2_NUM_BANKS
#define L2_NUM_BANKS MIN(L2_NUM_REQS, 16)

// Core Response Queue Size
#ifndef L2_CRSQ_SIZE
#define L2_CRSQ_SIZE 2

// Miss Handling Register Size
#ifndef L2_MSHR_SIZE
#define L2_MSHR_SIZE 16

// Memory Request Queue Size
#ifndef L2_MREQ_SIZE
#define L2_MREQ_SIZE 4

// Memory Response Queue Size
#ifndef L2_MRSQ_SIZE
#define L2_MRSQ_SIZE 4

// Number of Associative Ways
#ifndef L2_NUM_WAYS
#define L2_NUM_WAYS 8

// Enable Cache Writeback
#ifndef L2_WRITEBACK
#define L2_WRITEBACK 0

// Enable Cache Dirty bytes
#ifndef L2_DIRTYBYTES
#define L2_DIRTYBYTES L2_WRITEBACK

// Replacement Policy
#ifndef L2_REPL_POLICY
#define L2_REPL_POLICY 1

// Number of Memory Ports
#ifndef L2_MEM_PORTS
#ifdef L2_ENABLE
#define L2_MEM_PORTS MIN(L2_NUM_BANKS, PLATFORM_MEMORY_NUM_BANKS)
#else
#define L2_MEM_PORTS MIN(L2_NUM_REQS, PLATFORM_MEMORY_NUM_BANKS)

// L3cache Configurable Knobs /////////////////////////////////////////////////

// Cache Size
#ifndef L3_CACHE_SIZE
#define L3_CACHE_SIZE 2097152

// Number of Banks
#ifndef L3_NUM_BANKS
#define L3_NUM_BANKS MIN(L3_NUM_REQS, 16)

// Core Response Queue Size
#ifndef L3_CRSQ_SIZE
#define L3_CRSQ_SIZE 2

// Miss Handling Register Size
#ifndef L3_MSHR_SIZE
#define L3_MSHR_SIZE 16

// Memory Request Queue Size
#ifndef L3_MREQ_SIZE
#define L3_MREQ_SIZE 4

// Memory Response Queue Size
#ifndef L3_MRSQ_SIZE
#define L3_MRSQ_SIZE 4

// Number of Associative Ways
#ifndef L3_NUM_WAYS
#define L3_NUM_WAYS 8

// Enable Cache Writeback
#ifndef L3_WRITEBACK
#define L3_WRITEBACK 0

// Enable Cache Dirty bytes
#ifndef L3_DIRTYBYTES
#define L3_DIRTYBYTES L3_WRITEBACK

// Replacement Policy
#ifndef L3_REPL_POLICY
#define L3_REPL_POLICY 1

// Number of Memory Ports
#ifndef L3_MEM_PORTS
#ifdef L3_ENABLE
#define L3_MEM_PORTS MIN(L3_NUM_BANKS, PLATFORM_MEMORY_NUM_BANKS)
#else
#define L3_MEM_PORTS MIN(L3_NUM_REQS, PLATFORM_MEMORY_NUM_BANKS)

// ISA Extensions /////////////////////////////////////////////////////////////

#ifdef EXT_A_ENABLE
    #define EXT_A_ENABLED   1
#else
    #define EXT_A_ENABLED   0

#ifdef EXT_C_ENABLE
    #define EXT_C_ENABLED   1
#else
    #define EXT_C_ENABLED   0

#ifdef EXT_D_ENABLE
    #define EXT_D_ENABLED   1
#else
    #define EXT_D_ENABLED   0

#ifdef EXT_F_ENABLE
    #define EXT_F_ENABLED   1
#else
    #define EXT_F_ENABLED   0

#ifdef EXT_M_ENABLE
    #define EXT_M_ENABLED   1
#else
    #define EXT_M_ENABLED   0

#ifdef EXT_V_ENABLE
    #define EXT_V_ENABLED   1
#else
    #define EXT_V_ENABLED   0

#ifdef EXT_ZICOND_ENABLE
    #define EXT_ZICOND_ENABLED 1
#else
    #define EXT_ZICOND_ENABLED 0

#define ISA_STD_A           0
#define ISA_STD_C           2
#define ISA_STD_D           3
#define ISA_STD_E           4
#define ISA_STD_F           5
#define ISA_STD_H           7
#define ISA_STD_I           8
#define ISA_STD_N           13
#define ISA_STD_Q           16
#define ISA_STD_S           18
#define ISA_STD_V           21

#define ISA_EXT_ICACHE      0
#define ISA_EXT_DCACHE      1
#define ISA_EXT_L2CACHE     2
#define ISA_EXT_L3CACHE     3
#define ISA_EXT_LMEM        4
#define ISA_EXT_ZICOND      5

#define MISA_EXT  (ICACHE_ENABLED  << ISA_EXT_ICACHE) \
                | (DCACHE_ENABLED  << ISA_EXT_DCACHE) \
                | (L2_ENABLED      << ISA_EXT_L2CACHE) \
                | (L3_ENABLED      << ISA_EXT_L3CACHE) \
                | (LMEM_ENABLED    << ISA_EXT_LMEM) \
                | (EXT_ZICOND_ENABLED << ISA_EXT_ZICOND)

#define MISA_STD  (EXT_A_ENABLED <<  0) /* A - Atomic Instructions extension */ \
                | (0 <<  1) /* B - Tentatively reserved for Bit operations extension */ \
                | (EXT_C_ENABLED <<  2) /* C - Compressed extension */ \
                | (EXT_D_ENABLED <<  3) /* D - Double precsision floating-point extension */ \
                | (0 <<  4) /* E - RV32E base ISA */ \
                | (EXT_F_ENABLED << 5) /* F - Single precsision floating-point extension */ \
                | (0 <<  6) /* G - Additional standard extensions present */ \
                | (0 <<  7) /* H - Hypervisor mode implemented */ \
                | (1 <<  8) /* I - RV32I/64I/128I base ISA */ \
                | (0 <<  9) /* J - Reserved */ \
                | (0 << 10) /* K - Reserved */ \
                | (0 << 11) /* L - Tentatively reserved for Bit operations extension */ \
                | (EXT_M_ENABLED << 12) /* M - Integer Multiply/Divide extension */ \
                | (0 << 13) /* N - User level interrupts supported */ \
                | (0 << 14) /* O - Reserved */ \
                | (0 << 15) /* P - Tentatively reserved for Packed-SIMD extension */ \
                | (0 << 16) /* Q - Quad-precision floating-point extension */ \
                | (0 << 17) /* R - Reserved */ \
                | (0 << 18) /* S - Supervisor mode implemented */ \
                | (0 << 19) /* T - Tentatively reserved for Transactional Memory extension */ \
                | (1 << 20) /* U - User mode implemented */ \
                | (EXT_V_ENABLED << 21) /* V - Tentatively reserved for Vector extension */ \
                | (0 << 22) /* W - Reserved */ \
                | (1 << 23) /* X - Non-standard extensions present */ \
                | (0 << 24) /* Y - Reserved */ \
                | (0 << 25) /* Z - Reserved */

// Device identification //////////////////////////////////////////////////////

#define VENDOR_ID           0
#define ARCHITECTURE_ID     0
#define IMPLEMENTATION_ID   0

#endif // VX_CONFIG_VH
// --- End of content from sim/include/VX_config.h ---

// --- Start of content from sim/common/softfloat_ext.h ---
#include <stdint.h>
#include <softfloat_types.h>

#ifdef __cplusplus
extern "C" {
#endif

uint_fast16_t f16_classify(float16_t);
float16_t f16_rsqrte7(float16_t);
float16_t f16_recip7(float16_t);

uint_fast16_t f32_classify(float32_t);
float32_t f32_rsqrte7(float32_t);
float32_t f32_recip7(float32_t);

uint_fast16_t f64_classify(float64_t);
float64_t f64_rsqrte7(float64_t);
float64_t f64_recip7(float64_t);

#ifdef __cplusplus
}
#endif
// --- End of content from sim/common/softfloat_ext.h ---

// --- Start of content from sim/common/simobject.h ---
// Original pragma: #pragma once
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


#include <functional>
#include <iostream>
#include <memory>
#include <vector>
#include <list>
#include <queue>
#include <assert.h>
// MERGED_LOCALLY: #include "mempool.h"

class SimObjectBase;

///////////////////////////////////////////////////////////////////////////////

class SimPortBase {
public:
  virtual ~SimPortBase() {}

  SimObjectBase* module() const {
    return module_;
  }

protected:
  SimPortBase(SimObjectBase* module)
    : module_(module)
  {}

  SimPortBase& operator=(const SimPortBase&) = delete;

  SimObjectBase* module_;
};

///////////////////////////////////////////////////////////////////////////////

template <typename Pkt>
class SimPort : public SimPortBase {
public:
  typedef std::function<void (const Pkt&, uint64_t)> TxCallback;

  SimPort(SimObjectBase* module)
    : SimPortBase(module)
    , sink_(nullptr)
    , tx_cb_(nullptr)
  {}

  void bind(SimPort<Pkt>* sink) {
    assert(sink_ == nullptr);
    sink_ = sink;
  }

  void unbind() {
    sink_ = nullptr;
  }

  bool connected() const {
    return (sink_ != nullptr);
  }

  SimPort* sink() const {
    return sink_;
  }

  bool empty() const {
    return queue_.empty();
  }

  const Pkt& front() const {
    return queue_.front();
  }

  Pkt& front() {
    return queue_.front().pkt;
  }

  void push(const Pkt& pkt, uint64_t delay = 1) const;

  uint64_t pop() {
    auto cycles = queue_.front().cycles;
    queue_.pop();
    return cycles;
  }

  void tx_callback(const TxCallback& callback) {
    tx_cb_ = callback;
  }

  uint64_t arrival_time() const {
    if (queue_.empty())
      return 0;
    return queue_.front().cycles;
  }

protected:
  struct timed_pkt_t {
    Pkt      pkt;
    uint64_t cycles;
  };

  std::queue<timed_pkt_t> queue_;
  SimPort*   sink_;
  TxCallback tx_cb_;

  void transfer(const Pkt& data, uint64_t cycles) {
    if (tx_cb_) {
      tx_cb_(data, cycles);
    }
    if (sink_) {
      sink_->transfer(data, cycles);
    } else {
      queue_.push({data, cycles});
    }
  }

  SimPort& operator=(const SimPort&) = delete;

  template <typename U> friend class SimPortEvent;
};

///////////////////////////////////////////////////////////////////////////////

class SimEventBase {
public:
  typedef std::shared_ptr<SimEventBase> Ptr;

  virtual ~SimEventBase() {}

  virtual void fire() const = 0;

  uint64_t cycles() const {
    return cycles_;
  }

protected:
  SimEventBase(uint64_t cycles) : cycles_(cycles) {}

  uint64_t cycles_;
};

///////////////////////////////////////////////////////////////////////////////

template <typename Pkt>
class SimCallEvent : public SimEventBase {
public:
  void fire() const override {
    func_(pkt_);
  }

  typedef std::function<void (const Pkt&)> Func;

  SimCallEvent(const Func& func, const Pkt& pkt, uint64_t cycles)
    : SimEventBase(cycles)
    , func_(func)
    , pkt_(pkt)
  {}

  void* operator new(size_t /*size*/) {
    return allocator_.allocate();
  }

  void operator delete(void* ptr) {
    allocator_.deallocate(ptr);
  }

protected:
  Func func_;
  Pkt  pkt_;

  static MemoryPool<SimCallEvent<Pkt>> allocator_;
};

template <typename Pkt>
MemoryPool<SimCallEvent<Pkt>> SimCallEvent<Pkt>::allocator_(64);

///////////////////////////////////////////////////////////////////////////////

template <typename Pkt>
class SimPortEvent : public SimEventBase {
public:
  void fire() const override {
    const_cast<SimPort<Pkt>*>(port_)->transfer(pkt_, cycles_);
  }

  SimPortEvent(const SimPort<Pkt>* port, const Pkt& pkt, uint64_t cycles)
    : SimEventBase(cycles)
    , port_(port)
    , pkt_(pkt)
  {}

  void* operator new(size_t /*size*/) {
    return allocator_.allocate();
  }

  void operator delete(void* ptr) {
    allocator_.deallocate(ptr);
  }

protected:
  const SimPort<Pkt>* port_;
  Pkt pkt_;

  static MemoryPool<SimPortEvent<Pkt>> allocator_;
};

template <typename Pkt>
MemoryPool<SimPortEvent<Pkt>> SimPortEvent<Pkt>::allocator_(64);

///////////////////////////////////////////////////////////////////////////////

class SimContext;

class SimObjectBase {
public:
  typedef std::shared_ptr<SimObjectBase> Ptr;

  virtual ~SimObjectBase() {}

  const std::string& name() const {
    return name_;
  }

protected:

  SimObjectBase(const SimContext& ctx, const std::string& name);

private:

  virtual void do_reset() = 0;

  virtual void do_tick() = 0;

  std::string name_;

  friend class SimPlatform;
};

///////////////////////////////////////////////////////////////////////////////

template <typename Impl>
class SimObject : public SimObjectBase {
public:
  typedef std::shared_ptr<Impl> Ptr;

  template <typename... Args>
  static Ptr Create(Args&&... args);

protected:

  SimObject(const SimContext& ctx, const std::string& name)
    : SimObjectBase(ctx, name)
  {}

private:

  const Impl* impl() const {
    return static_cast<const Impl*>(this);
  }

  Impl* impl() {
    return static_cast<Impl*>(this);
  }

  void do_reset() override {
    this->impl()->reset();
  }

  void do_tick() override {
    this->impl()->tick();
  }
};

class SimContext {
private:
  SimContext() {}

  friend class SimPlatform;
};

///////////////////////////////////////////////////////////////////////////////

class SimPlatform {
public:
  static SimPlatform& instance() {
    static SimPlatform s_inst;
    return s_inst;
  }

  bool initialize() {
    //--
    return true;
  }

  void finalize() {
    instance().clear();
  }

  template <typename Impl, typename... Args>
  typename SimObject<Impl>::Ptr create_object(Args&&... args) {
    auto obj = std::make_shared<Impl>(SimContext{}, std::forward<Args>(args)...);
    objects_.push_back(obj);
    return obj;
  }

  void release_object(const SimObjectBase::Ptr& object) {
    objects_.remove(object);
  }

  template <typename Pkt>
  void schedule(const typename SimCallEvent<Pkt>::Func& callback,
                const Pkt& pkt,
                uint64_t delay) {
    assert(delay != 0);
    auto evt = std::make_shared<SimCallEvent<Pkt>>(callback, pkt, cycles_ + delay);
    events_.emplace_back(evt);
  }

  void reset() {
    events_.clear();
    for (auto& object : objects_) {
      object->do_reset();
    }
    cycles_ = 0;
  }

  void tick() {
    // evaluate events
    auto evt_it = events_.begin();
    auto evt_it_end = events_.end();
    while (evt_it != evt_it_end) {
      auto& event = *evt_it;
      if (cycles_ >= event->cycles()) {
        event->fire();
        evt_it = events_.erase(evt_it);
      } else {
        ++evt_it;
      }
    }
    // evaluate components
    for (auto& object : objects_) {
      object->do_tick();
    }
    // advance clock
    ++cycles_;
  }

  uint64_t cycles() const {
    return cycles_;
  }

private:

  SimPlatform() : cycles_(0) {}

  virtual ~SimPlatform() {
    this->clear();
  }

  void clear() {
    objects_.clear();
    events_.clear();
  }

  template <typename Pkt>
  void schedule(const SimPort<Pkt>* port, const Pkt& pkt, uint64_t delay) {
    assert(delay != 0);
    auto evt = SimEventBase::Ptr(new SimPortEvent<Pkt>(port, pkt, cycles_ + delay));
    events_.emplace_back(evt);
  }

  std::list<SimObjectBase::Ptr> objects_;
  std::list<SimEventBase::Ptr> events_;
  uint64_t cycles_;

  template <typename U> friend class SimPort;
  friend class SimObjectBase;
};

///////////////////////////////////////////////////////////////////////////////

inline SimObjectBase::SimObjectBase(const SimContext&, const std::string& name)
  : name_(name)
{}

template <typename Impl>
template <typename... Args>
typename SimObject<Impl>::Ptr SimObject<Impl>::Create(Args&&... args) {
  return SimPlatform::instance().create_object<Impl>(std::forward<Args>(args)...);
}

template <typename Pkt>
void SimPort<Pkt>::push(const Pkt& pkt, uint64_t delay) const {
  if (sink_ && !tx_cb_) {
    reinterpret_cast<const SimPort<Pkt>*>(sink_)->push(pkt, delay);
  } else {
    SimPlatform::instance().schedule(this, pkt, delay);
  }
}
// --- End of content from sim/common/simobject.h ---

// --- Start of content from sim/common/util.h ---
// Original pragma: #pragma once
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


#include <cstdint>
#include <algorithm>
#include <assert.h>
#include <bitmanip.h>
#include <string>

template <typename... Args>
void unused(Args&&...) {}

#define __unused(...) unused(__VA_ARGS__)

// return file extension
const char* fileExtension(const char* filepath);

#if defined(_MSC_VER)
#define DISABLE_WARNING_PUSH __pragma(warning(push))
#define DISABLE_WARNING_POP __pragma(warning(pop))
#define DISABLE_WARNING_UNUSED_PARAMETER \
  __pragma(warning(disable : 4100))
#define DISABLE_WARNING_UNREFERENCED_FUNCTION __pragma(warning(disable : 4505))
#define DISABLE_WARNING_ANONYMOUS_STRUCT __pragma(warning(disable : 4201))
#define DISABLE_WARNING_UNUSED_VARIABLE __pragma(warning(disable : 4189))
#define DISABLE_WARNING_MISSING_FIELD_INITIALIZERS __pragma(warning(disable : 4351))
#elif defined(__GNUC__)
#define DISABLE_WARNING_PUSH _Pragma("GCC diagnostic push")
#define DISABLE_WARNING_POP _Pragma("GCC diagnostic pop")
#define DISABLE_WARNING_UNUSED_PARAMETER \
  _Pragma("GCC diagnostic ignored \"-Wunused-parameter\"")
#define DISABLE_WARNING_UNREFERENCED_FUNCTION \
  _Pragma("GCC diagnostic ignored \"-Wunused-function\"")
#define DISABLE_WARNING_ANONYMOUS_STRUCT \
  _Pragma("GCC diagnostic ignored \"-Wpedantic\"")
#define DISABLE_WARNING_UNUSED_VARIABLE \
  _Pragma("GCC diagnostic ignored \"-Wunused-but-set-variable\"")
#define DISABLE_WARNING_MISSING_FIELD_INITIALIZERS \
  _Pragma("GCC diagnostic ignored \"-Wmissing-field-initializers\"")
#elif defined(__clang__)
#define DISABLE_WARNING_PUSH _Pragma("clang diagnostic push")
#define DISABLE_WARNING_POP _Pragma("clang diagnostic pop")
#define DISABLE_WARNING_UNUSED_PARAMETER \
  _Pragma("clang diagnostic ignored \"-Wunused-parameter\"")
#define DISABLE_WARNING_UNREFERENCED_FUNCTION \
  _Pragma("clang diagnostic ignored \"-Wunused-function\"")
#define DISABLE_WARNING_ANONYMOUS_STRUCT \
  _Pragma("clang diagnostic ignored \"-Wgnu-anonymous-struct\"")
#define DISABLE_WARNING_UNUSED_VARIABLE \
  _Pragma("clang diagnostic ignored \"-Wunused-but-set-variable\"")
#define DISABLE_WARNING_MISSING_FIELD_INITIALIZERS \
  _Pragma("clang diagnostic ignored \"-Wmissing-field-initializers\"")
#else
#define DISABLE_WARNING_PUSH
#define DISABLE_WARNING_POP
#define DISABLE_WARNING_UNUSED_PARAMETER
#define DISABLE_WARNING_UNREFERENCED_FUNCTION
#define DISABLE_WARNING_ANONYMOUS_STRUCT
#endif

void *aligned_malloc(size_t size, size_t alignment);
void aligned_free(void *ptr);

namespace vortex {

// Verilator data type casting
template <typename R, size_t W, typename Enable = void>
class VDataCast;
template <typename R, size_t W>
class VDataCast<R, W, typename std::enable_if<(W > 8)>::type> {
public:
  template <typename T>
  static R get(T& obj) {
    return reinterpret_cast<R>(obj.data());
  }
};
template <typename R, size_t W>
class VDataCast<R, W, typename std::enable_if<(W <= 8)>::type> {
public:
  template <typename T>
  static R get(T& obj) {
    return reinterpret_cast<R>(&obj);
  }
};

std::string resolve_file_path(const std::string& filename, const std::string& searchPaths);

}
// --- End of content from sim/common/util.h ---

// --- Start of content from sim/common/mem_alloc.h ---
// Original pragma: #pragma once
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


#include <cstdint>
#include <assert.h>
#include <stdio.h>

namespace vortex {

class MemoryAllocator {
public:
  MemoryAllocator(
    uint64_t baseAddress,
    uint64_t capacity,
    uint32_t pageAlign,
    uint32_t blockAlign)
    : baseAddress_(baseAddress)
    , capacity_(capacity)
    , pageAlign_(pageAlign)
    , blockAlign_(blockAlign)
    , pages_(nullptr)
    , allocated_(0)
  {}

  ~MemoryAllocator() {
    // Free allocated pages
    page_t* currPage = pages_;
    while (currPage) {
      auto nextPage = currPage->next;
      #ifdef VM_ENABLE
      block_t* currblock = currPage->findfirstUsedBlock();
      block_t* nextblock;
      while (currblock) {
        nextblock= currblock->nextUsed;
        currPage->release(currblock);
        currblock = nextblock;
      }
      #endif
      delete currPage;
      currPage = nextPage;
    }
  }

  uint32_t baseAddress() const {
    return baseAddress_;
  }

  uint32_t capacity() const {
    return capacity_;
  }

  uint64_t free() const {
    return (capacity_ - allocated_);
  }

  uint64_t allocated() const {
    return allocated_;
  }

  int reserve(uint64_t addr, uint64_t size) {
    if (size == 0) {
      printf("error: invalid arguments\n");
      return -1;
    }

    // Align allocation size
    size = alignSize(size, pageAlign_);

    // Check if the reservation is within memory capacity bounds
    if (addr + size > baseAddress_ + capacity_) {
      printf("error: address range out of bounds - requested=0x%lx, base+capacity=0x%lx\n", (addr + size), (baseAddress_ +capacity_));
      return -1;
    }

    // Ensure the reservation does not overlap with existing pages
    uint64_t overlapStart, overlapEnd;
    if (hasPageOverlap(addr, size, &overlapStart, &overlapEnd)) {
      printf("error: address range overlaps with existing allocation - requested=[0x%lx-0x%lx], existing=[0x%lx, 0x%lx]\n", addr, addr+size, overlapStart, overlapEnd);
      return -1;
    }

    // allocate a new page for segment
    auto newPage = this->createPage(addr, size);

    // allocate space on free block
    auto freeBlock = newPage->findFreeBlock(size);
    newPage->allocate(size, freeBlock);

    // Update allocated size
    allocated_ += size;

    return 0;
  }

  int allocate(uint64_t size, uint64_t* addr) {
    if (size == 0 || addr == nullptr) {
      printf("error: invalid arguments\n");
      return -1;
    }

    // Align allocation size
    size = alignSize(size, blockAlign_);

    // Walk thru all pages to find a free block
    block_t* freeBlock = nullptr;
    auto currPage = pages_;
    while (currPage) {
      freeBlock = currPage->findFreeBlock(size);
      if (freeBlock != nullptr)
        break;
      currPage = currPage->next;
    }

    // Allocate a new page if no free block is found
    if (freeBlock == nullptr) {
      auto pageSize = alignSize(size, pageAlign_);
      uint64_t pageAddr;
      if (!this->findNextAddress(pageSize, &pageAddr)) {
        printf("error: out of memory (Can't find next address)\n");
        return -1;
      }
      currPage = this->createPage(pageAddr, pageSize);
      if (nullptr == currPage) {
        printf("error: out of memory (Can't create a page)\n");
        return -1;
      }
      freeBlock = currPage->findFreeBlock(size);
    }

    // allocate space on free block
    currPage->allocate(size, freeBlock);

    // Return the free block address
    *addr = freeBlock->addr;

    // Update allocated size
    allocated_ += size;

    return 0;
  }

  int release(uint64_t addr) {
    // Walk all pages to find the pointer
    block_t* usedBlock = nullptr;
    auto currPage = pages_;
    while (currPage) {
      usedBlock = currPage->findUsedBlock(addr);
      if (usedBlock != nullptr)
        break;
      currPage = currPage->next;
    }

    // found the corresponding block?
    if (nullptr == usedBlock) {
      printf("warning: release address not found: 0x%lx\n", addr);
      return -1;
    }

    auto size = usedBlock->size;

    // release the used block
    currPage->release(usedBlock);

    // Free the page if empty
    if (currPage->empty()) {
      this->deletePage(currPage);
    }

    // update allocated size
    allocated_ -= size;

    return 0;
  }

private:

  struct block_t {
    block_t* nextFreeS;
    block_t* prevFreeS;

    block_t* nextFreeM;
    block_t* prevFreeM;

    block_t* nextUsed;
    block_t* prevUsed;

    uint64_t addr;
    uint64_t size;

    block_t(uint64_t addr, uint64_t size)
      : nextFreeS(nullptr)
      , prevFreeS(nullptr)
      , nextFreeM(nullptr)
      , prevFreeM(nullptr)
      , nextUsed(nullptr)
      , prevUsed(nullptr)
      , addr(addr)
      , size(size)
    {}
  };

  struct page_t {
    page_t*  next;
    uint64_t addr;
    uint64_t size;

    page_t(uint64_t addr, uint64_t size, uint32_t blockAlign) :
      next(nullptr),
      addr(addr),
      size(size),
      blockAlign_(blockAlign),
      usedList_(nullptr) {
      freeSList_ = freeMList_ = new block_t(addr, size);
    }

    ~page_t() {
      // The page should be empty
      assert(nullptr == usedList_);
      assert(freeMList_
          && (nullptr == freeMList_->nextFreeM)
          && (nullptr == freeMList_->prevFreeM));
      delete freeMList_;
    }

    bool empty() const {
      return (usedList_ == nullptr);
    }

    void allocate(uint64_t size, block_t* freeBlock) {
      // Remove the block from the free lists
      this->removeFreeMList(freeBlock);
      this->removeFreeSList(freeBlock);

      // If the free block we have found is larger than what we are looking for,
      // we may be able to split our free block in two.
      uint64_t extraBytes = freeBlock->size - size;
      if (extraBytes >= blockAlign_) {
        // Reduce the free block size to the requested value
        freeBlock->size = size;

        // Allocate a new block to contain the extra buffer
        auto nextAddr = freeBlock->addr + size;
        auto newBlock = new block_t(nextAddr, extraBytes);

        // Add the new block to the free lists
        this->insertFreeMList(newBlock);
        this->insertFreeSList(newBlock);
      }

      // Insert the free block into the used list
      this->insertUsedList(freeBlock);
    }

    void release(block_t* usedBlock) {
      // Remove the block from the used list
      this->removeUsedList(usedBlock);

      // Insert the block into the free M-list.
      this->insertFreeMList(usedBlock);

      // Check if we can merge adjacent free blocks from the left.
      if (usedBlock->prevFreeM) {
        // Calculate the previous address
        auto prevAddr = usedBlock->prevFreeM->addr + usedBlock->prevFreeM->size;
        if (usedBlock->addr == prevAddr) {
          auto prevBlock = usedBlock->prevFreeM;

          // Merge the blocks to the left
          prevBlock->size += usedBlock->size;
          prevBlock->nextFreeM = usedBlock->nextFreeM;
          if (prevBlock->nextFreeM) {
            prevBlock->nextFreeM->prevFreeM = prevBlock;
          }

          // Detach previous block from the free S-list since size increased
          this->removeFreeSList(prevBlock);

          // reset usedBlock
          delete usedBlock;
          usedBlock = prevBlock;
        }
      }

      // Check if we can merge adjacent free blocks from the right.
      if (usedBlock->nextFreeM) {
        // Calculate the next allocation start address
        auto nextAddr = usedBlock->addr + usedBlock->size;
        if (usedBlock->nextFreeM->addr == nextAddr) {
          auto nextBlock = usedBlock->nextFreeM;

          // Merge the blocks to the right
          usedBlock->size += nextBlock->size;
          usedBlock->nextFreeM = nextBlock->nextFreeM;
          if (usedBlock->nextFreeM) {
            usedBlock->nextFreeM->prevFreeM = usedBlock;
          }

          // Delete next block
          this->removeFreeSList(nextBlock);
          delete nextBlock;
        }
      }

      // Insert the block into the free S-list.
      this->insertFreeSList(usedBlock);
    }

    block_t* findFreeBlock(uint64_t size) {
      auto freeBlock = freeSList_;
      if (freeBlock) {
        // The free S-list is already sorted with the largest block first
        // Quick check if the head block has enough space.
        if (freeBlock->size >= size) {
          // Find the smallest matching block in the S-list
          while (freeBlock->nextFreeS && (freeBlock->nextFreeS->size >= size)) {
            freeBlock = freeBlock->nextFreeS;
          }
          // Return the free block
          return freeBlock;
        }
      }
      return nullptr;
    }

    block_t* findUsedBlock(uint64_t addr) {
      if (addr >= this->addr && addr < (this->addr + this->size)) {
        auto useBlock = usedList_;
        while (useBlock) {
          if (useBlock->addr == addr)
            return useBlock;
          useBlock = useBlock->nextUsed;
        }
      }
      return nullptr;
    }
#ifdef VM_ENABLE 
    block_t* findfirstUsedBlock() {
      return usedList_;
    }
#endif

  private:

    void insertUsedList(block_t* block) {
      block->nextUsed = usedList_;
      if (usedList_) {
        usedList_->prevUsed = block;
      }
      usedList_ = block;
    }

    void removeUsedList(block_t* block) {
      if (block->prevUsed) {
        block->prevUsed->nextUsed = block->nextUsed;
      } else {
        usedList_ = block->nextUsed;
      }
      if (block->nextUsed) {
        block->nextUsed->prevUsed = block->prevUsed;
      }
      block->nextUsed = nullptr;
      block->prevUsed = nullptr;
    }

    void insertFreeMList(block_t* block) {
      block_t* currBlock = freeMList_;
      block_t* prevBlock = nullptr;
      while (currBlock && (currBlock->addr < block->addr)) {
        prevBlock = currBlock;
        currBlock = currBlock->nextFreeM;
      }
      block->nextFreeM = currBlock;
      block->prevFreeM = prevBlock;
      if (prevBlock) {
        prevBlock->nextFreeM = block;
      } else {
        freeMList_ = block;
      }
      if (currBlock) {
        currBlock->prevFreeM = block;
      }
    }

    void removeFreeMList(block_t* block) {
      if (block->prevFreeM) {
        block->prevFreeM->nextFreeM = block->nextFreeM;
      } else {
        freeMList_ = block->nextFreeM;
      }
      if (block->nextFreeM) {
        block->nextFreeM->prevFreeM = block->prevFreeM;
      }
      block->nextFreeM = nullptr;
      block->prevFreeM = nullptr;
    }

    void insertFreeSList(block_t* block) {
      block_t* currBlock = freeSList_;
      block_t* prevBlock = nullptr;
      while (currBlock && (currBlock->size > block->size)) {
        prevBlock = currBlock;
        currBlock = currBlock->nextFreeS;
      }
      block->nextFreeS = currBlock;
      block->prevFreeS = prevBlock;
      if (prevBlock) {
        prevBlock->nextFreeS = block;
      } else {
        freeSList_ = block;
      }
      if (currBlock) {
        currBlock->prevFreeS = block;
      }
    }

    void removeFreeSList(block_t* block) {
      if (block->prevFreeS) {
        block->prevFreeS->nextFreeS = block->nextFreeS;
      } else {
        freeSList_ = block->nextFreeS;
      }
      if (block->nextFreeS) {
        block->nextFreeS->prevFreeS = block->prevFreeS;
      }
      block->nextFreeS = nullptr;
      block->prevFreeS = nullptr;
    }

    // block alignment
    uint32_t blockAlign_;

    // List of used blocks
    block_t* usedList_;

    // List with blocks sorted by decreasing sizes
    // Used for block lookup during memory allocation.
    block_t* freeSList_;

    // List with blocks sorted by increasing memory addresses
    // Used for block merging during memory release.
    block_t* freeMList_;
  };

  page_t* createPage(uint64_t addr, uint64_t size) {
    // Allocate object
    auto newPage = new page_t(addr, size, blockAlign_);

    // Insert the new page into the list in address sorted order
    if (pages_ == nullptr || pages_->addr > newPage->addr) {
      newPage->next = pages_;
      pages_ = newPage;
    } else {
      page_t* current = pages_;
      while (current->next != nullptr && current->next->addr < newPage->addr) {
        current = current->next;
      }
      newPage->next = current->next;
      current->next = newPage;
    }

    return newPage;
  }

  void deletePage(page_t* page) {
    // Remove the page from the list
    page_t* prevPage = nullptr;
    auto currPage = pages_;
    while (currPage) {
      if (currPage == page) {
        if (prevPage) {
          prevPage->next = currPage->next;
        } else {
          pages_ = currPage->next;
        }
        break;
      }
      prevPage = currPage;
      currPage = currPage->next;
    }
    // Delete the page
    delete page;
  }

  bool findNextAddress(uint64_t size, uint64_t* addr) {
    if (pages_ == nullptr) {
      *addr = baseAddress_; 
      return true;
    }

    page_t* current = pages_;
    uint64_t endOfLastPage = baseAddress_;

    while (current != nullptr) {
      uint64_t startOfCurrentPage = current->addr;
      if ((endOfLastPage + size) <= startOfCurrentPage) {
        *addr = endOfLastPage;
        return true;
      }
      // Update the end of the last page to the end of the current page
      // Move to the next page in the sorted list
      endOfLastPage = current->addr + current->size;
      current = current->next;
    }
    
    // If no suitable gap is found, place the new page at the end of the last page
    // Check if the allocator has enough capacity
    if ((endOfLastPage + size) <= (baseAddress_ + capacity_)) {
      *addr = endOfLastPage;
      return true;
    }

    return false;
  }

  bool hasPageOverlap(uint64_t start, uint64_t size, uint64_t* overlapStart, uint64_t* overlapEnd) {
    page_t* current = pages_;
    while (current != nullptr) {
      uint64_t pageStart = current->addr;
      uint64_t pageEnd = pageStart + current->size;
      uint64_t end = start + size;
      if ((start <= pageEnd) && (end >= pageStart)) {
        *overlapStart = pageStart;
        *overlapEnd = pageEnd;
        return true;
      }
      current = current->next;
    }
    return false;
  }

  static uint64_t alignSize(uint64_t size, uint64_t alignment) {
    assert(0 == (alignment & (alignment - 1)));
    return (size + alignment - 1) & ~(alignment - 1);
  }

  uint64_t baseAddress_;
  uint64_t capacity_;
  uint32_t pageAlign_;
  uint32_t blockAlign_;
  page_t*  pages_;
  uint64_t nextAddress_;
  uint64_t allocated_;
};

} // namespace vortex
// --- End of content from sim/common/mem_alloc.h ---

// --- Start of content from sim/common/mempool.h ---
// Original pragma: #pragma once
// Copyright © 2019-2023
// 
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
// 
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


#include <stack>

template <typename T>
class MemoryPool {
public:  
  MemoryPool(uint32_t max_size) : max_size_(max_size) {}

  MemoryPool(MemoryPool && other) 
    : free_list_(std::move(other.free_list_)) 
  {}

  ~MemoryPool() {
    this->flush();
  }

  void* allocate() {
    void* mem;
    if (!free_list_.empty()) {
      auto entry = free_list_.top();
      free_list_.pop();
      mem = static_cast<void*>(entry);      
    } else {
      mem = ::operator new(sizeof(T));
    }
    return mem;
  }

  void deallocate(void * object) {
    if (free_list_.size() < max_size_) {
      free_list_.push(static_cast<T*>(object));
    } else {
      ::operator delete(object);
    }
  }

  void flush() {
    while (!free_list_.empty()) {
      auto entry = free_list_.top();
      free_list_.pop();
      ::operator delete(entry);      
    }
  }

private:
  std::stack<T*> free_list_;
  uint32_t max_size_;
};
// --- End of content from sim/common/mempool.h ---

// --- Start of content from sim/common/bitvector.h ---
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#include <vector>
#include <stdexcept>
#include <algorithm>

namespace vortex {

template <typename T = uint32_t>
class BitVector {
private:
  static constexpr size_t BITS_PER_WORD = sizeof(T) * 8;
  std::vector<T> words_;
  size_t size_;
  bool all_zero_;

  constexpr size_t wordIndex(size_t pos) const {
    return pos / BITS_PER_WORD;
  }

  constexpr T bitMask(size_t pos) const {
    return T(1) << (pos % BITS_PER_WORD);
  }

  void updateAllZero() {
    all_zero_ = std::all_of(words_.begin(), words_.end(), [](T word) { return word == 0; });
  }

public:
  explicit BitVector(size_t size = 0)
    : words_((size + (BITS_PER_WORD - 1)) / BITS_PER_WORD)
    , size_(size)
    , all_zero_(true)
  {}

  void set(size_t pos) {
    if (pos >= size_) throw std::out_of_range("Index out of range");
    words_[this->wordIndex(pos)] |= this->bitMask(pos);
    all_zero_ = false;
  }

  void set(size_t pos, bool value) {
    if (value) {
      this->set(pos);
    } else {
      this->reset(pos);
    }
  }

  void reset() {
    std::fill(words_.begin(), words_.end(), 0);
    all_zero_ = true;
  }

  void reset(size_t pos) {
    if (pos >= size_) throw std::out_of_range("Index out of range");
    words_[this->wordIndex(pos)] &= ~this->bitMask(pos);
    this->updateAllZero();
  }

  bool test(size_t pos) const {
    if (pos >= size_) throw std::out_of_range("Index out of range");
    return words_[this->wordIndex(pos)] & this->bitMask(pos);
  }

  size_t size() const {
    return size_;
  }

  void resize(size_t new_size) {
    size_ = new_size;
    words_.resize((new_size + (BITS_PER_WORD - 1)) / BITS_PER_WORD, 0);
    this->updateAllZero();
  }

  bool operator==(const BitVector& other) const {
    return (size_ == other.size_) && (words_ == other.words_);
  }

  bool operator!=(const BitVector& other) const {
    return !(*this == other);
  }

  bool operator[](size_t pos) const {
    return test(pos);
  }

  BitVector& operator&=(const BitVector& other) {
    if (size_ != other.size_) throw std::invalid_argument("Bit sizes must match");
    for (size_t i = 0; i < words_.size(); ++i) {
      words_[i] &= other.words_[i];
    }
    this->updateAllZero();
    return *this;
  }

  BitVector& operator|=(const BitVector& other) {
    if (size_ != other.size_) throw std::invalid_argument("Bit sizes must match");
    for (size_t i = 0; i < words_.size(); ++i) {
      words_[i] |= other.words_[i];
    }
    this->updateAllZero();
    return *this;
  }

  BitVector& operator^=(const BitVector& other) {
    if (size_ != other.size_) throw std::invalid_argument("Bit sizes must match");
    for (size_t i = 0; i < words_.size(); ++i) {
      words_[i] ^= other.words_[i];
    }
    this->updateAllZero();
    return *this;
  }

  BitVector operator~() const {
    BitVector result(size_);
    for (size_t i = 0; i < words_.size(); ++i) {
      result.words_[i] = ~words_[i];
    }
    result.updateAllZero();
    return result;
  }

  void flip() {
    for (auto &word : words_) {
      word = ~word;
    }
    this->updateAllZero();
  }

  void reverse() {
    if (size_ == 0)
      return;
    size_t remaining_bits = size_ % BITS_PER_WORD;
    if (remaining_bits != 0) {
      std::vector<T> reversed_words(words_.size(), 0);
      for (size_t i = 0; i < size_; ++i) {
        size_t reversed_pos = size_ - 1 - i;
        size_t src_word = i / BITS_PER_WORD;
        size_t src_offset = i % BITS_PER_WORD;
        size_t dst_word = reversed_pos / BITS_PER_WORD;
        size_t dst_offset = reversed_pos % BITS_PER_WORD;
        if (words_[src_word] & (T(1) << src_offset)) {
          reversed_words[dst_word] |= (T(1) << dst_offset);
        }
      }
      words_ = std::move(reversed_words);
    } else {
      std::reverse(words_.begin(), words_.end());
      for (auto &word : words_) {
        word = static_cast<T>(bit_reverse(static_cast<uint64_t>(word)));
      }
    }
  }

  size_t count() const {
    size_t count = 0;
    for (const auto &word : words_) {
      count += std::bitset<BITS_PER_WORD>(word).count();
    }
    return count;
  }

  bool none() const {
    return all_zero_;
  }

  bool any() const {
    return !all_zero_;
  }

  bool all() const {
    size_t full_bits = size_ / BITS_PER_WORD;
    size_t remaining_bits = size_ % BITS_PER_WORD;
    T full_mask = ~T(0);
    for (size_t i = 0; i < full_bits; ++i) {
      if (words_[i] != full_mask)
        return false;
    }
    if (remaining_bits > 0) {
      T partial_mask = (T(1) << remaining_bits) - 1;
      if ((words_[full_bits] & partial_mask) != partial_mask)
        return false;
    }
    return true;
  }

   BitVector& operator<<=(size_t pos) {
    if (pos >= size_) {
      reset();
      return *this;
    }

    size_t word_shift = pos / BITS_PER_WORD;
    size_t bit_shift = pos % BITS_PER_WORD;

    if (word_shift > 0) {
      for (size_t i = words_.size() - 1; i >= word_shift; --i) {
        words_[i] = words_[i - word_shift];
      }
      std::fill(words_.begin(), words_.begin() + word_shift, 0);
    }

    if (bit_shift > 0) {
      for (size_t i = words_.size() - 1; i > 0; --i) {
        words_[i] = (words_[i] << bit_shift) | (words_[i - 1] >> (BITS_PER_WORD - bit_shift));
      }
      words_[0] <<= bit_shift;
    }

    this->updateAllZero();
    return *this;
  }

  BitVector& operator>>=(size_t pos) {
    if (pos >= size_) {
      reset();
      return *this;
    }

    size_t word_shift = pos / BITS_PER_WORD;
    size_t bit_shift = pos % BITS_PER_WORD;

    if (word_shift > 0) {
      for (size_t i = 0; i < words_.size() - word_shift; ++i) {
        words_[i] = words_[i + word_shift];
      }
      std::fill(words_.end() - word_shift, words_.end(), 0);
    }

    if (bit_shift > 0) {
      for (size_t i = 0; i < words_.size() - 1; ++i) {
        words_[i] = (words_[i] >> bit_shift) | (words_[i + 1] << (BITS_PER_WORD - bit_shift));
      }
      words_.back() >>= bit_shift;
    }

    this->updateAllZero();
    return *this;
  }

  std::string to_string() const {
    std::string result;
    for (size_t i = 0; i < size_; ++i) {
      result.push_back(test(i) ? '1' : '0');
    }
    return result;
  }

  unsigned long to_ulong() const {
    if (size_ > sizeof(unsigned long) * 8) {
      throw std::overflow_error("BitVector size exceeds unsigned long capacity");
    }

    unsigned long result = 0;
    for (size_t i = 0; i < size_; ++i) {
      if (test(i)) {
        result |= (1UL << i);
      }
    }
    return result;
  }

  unsigned long long to_ullong() const {
    if (size_ > sizeof(unsigned long long) * 8) {
      throw std::overflow_error("BitVector size exceeds unsigned long long capacity");
    }

    unsigned long long result = 0;
    for (size_t i = 0; i < size_; ++i) {
      if (test(i)) {
        result |= (1ULL << i);
      }
    }
    return result;
  }

  friend std::ostream& operator<<(std::ostream& os, const BitVector& bv) {
    for (size_t i = 0; i < bv.size_; ++i) {
      os << bv.test(i);
    }
    return os;
  }

  friend BitVector operator&(const BitVector& lhs, const BitVector& rhs) {
    BitVector result(lhs);
    result &= rhs;
    return result;
  }

  friend BitVector operator|(const BitVector& lhs, const BitVector& rhs) {
    BitVector result(lhs);
    result |= rhs;
    return result;
  }

  friend BitVector operator^(const BitVector& lhs, const BitVector& rhs) {
    BitVector result(lhs);
    result ^= rhs;
    return result;
  }

  friend BitVector operator<<(const BitVector& lhs, size_t pos) {
    BitVector result(lhs);
    result <<= pos;
    return result;
  }

  friend BitVector operator>>(const BitVector& lhs, size_t pos) {
    BitVector result(lhs);
    result >>= pos;
    return result;
  }
};

}

// std::hash specialization for BitVector
namespace std {

template <typename T>
struct hash<vortex::BitVector<T>> {
  size_t operator()(const vortex::BitVector<T>& bv) const {
    return hash<std::string>()(bv.to_string());
  }
};

}
// --- End of content from sim/common/bitvector.h ---

// --- Start of content from sim/common/mp_macros.h ---
// Original pragma: #pragma once
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


// macro primitives

#define MP_COMMA ,
#define MP_REM(...) __VA_ARGS__
#define MP_EAT(...)

#define MP_STRINGIZE_(x) #x
#define MP_STRINGIZE(x) MP_STRINGIZE_(x)

#define MP_CONCAT_(x, ...) x ## __VA_ARGS__
#define MP_CONCAT(x, ...) MP_CONCAT_(x, __VA_ARGS__)

#define MP_COUNTOF(arr) (sizeof(arr) / sizeof(arr[0]))

// conditional macro

#define MP_IIF_0(x, y) y
#define MP_IIF_1(x, y) x
#define MP_IIF(c) MP_CONCAT(MP_IIF_, c)

#define MP_PAIR_FIRST(a, b) a
#define MP_PAIR_SECOND(a, b) b

// pair macros

#define MP_PAIR(x) MP_REM x
#define MP_PAIR_HEAD_(x, ...) MP_PAIR(x)
#define MP_PAIR_PROBE_(...) (__VA_ARGS__),
#define MP_PAIR_L_(...) MP_PAIR_HEAD_(__VA_ARGS__)
#define MP_PAIR_L(x) MP_PAIR_L_(MP_PAIR_PROBE_ x,)
#define MP_PAIR_R(x) MP_EAT x

// separator macros

#define MP_SEP_COMMA() ,
#define MP_SEP_SEMICOLON() ;
#define MP_SEP_PLUS() +
#define MP_SEP_AND() &
#define MP_SEP_OR() |
#define MP_SEP_COLON() :
#define MP_SEP_SPACE() /**/
#define MP_SEP_LESS() <
#define MP_SEP_GREATER() >
#define MP_SEP_ANDL() &&
#define MP_SEP_ORL() ||

// MAKE_UNIQUE macro

#define MP_MAKE_UNIQUE(x) MP_CONCAT(x, __COUNTER__)

// increment macro

#define MP_INC(x) MP_INC_ ## x
#define MP_INC_0 1
#define MP_INC_1 2
#define MP_INC_2 3
#define MP_INC_3 4
#define MP_INC_4 5
#define MP_INC_5 6
#define MP_INC_6 7
#define MP_INC_7 8
#define MP_INC_8 9
#define MP_INC_9 10
#define MP_INC_10 11
#define MP_INC_11 12
#define MP_INC_12 13
#define MP_INC_13 14
#define MP_INC_14 15
#define MP_INC_15 16
#define MP_INC_16 17
#define MP_INC_17 18
#define MP_INC_18 19
#define MP_INC_19 20
#define MP_INC_20 21
#define MP_INC_21 22
#define MP_INC_22 23
#define MP_INC_23 24
#define MP_INC_24 25
#define MP_INC_25 26
#define MP_INC_26 27
#define MP_INC_27 28
#define MP_INC_28 29
#define MP_INC_29 30
#define MP_INC_30 31
#define MP_INC_31 32
#define MP_INC_32 33
#define MP_INC_33 34
#define MP_INC_34 35
#define MP_INC_35 36
#define MP_INC_36 37
#define MP_INC_37 38
#define MP_INC_38 39
#define MP_INC_39 40
#define MP_INC_40 41
#define MP_INC_41 42
#define MP_INC_42 43
#define MP_INC_43 44
#define MP_INC_44 45
#define MP_INC_45 46
#define MP_INC_46 47
#define MP_INC_47 48
#define MP_INC_48 49
#define MP_INC_49 50
#define MP_INC_50 51
#define MP_INC_51 52
#define MP_INC_52 53
#define MP_INC_53 54
#define MP_INC_54 55
#define MP_INC_55 56
#define MP_INC_56 57
#define MP_INC_57 58
#define MP_INC_58 59
#define MP_INC_59 60
#define MP_INC_60 61
#define MP_INC_61 62
#define MP_INC_62 63
#define MP_INC_63 64

// NARG macro

#define MP_NARG_N(_1, _2, _3, _4, _5, _6, _7, _8, _9, _10,_11,_12,_13,_14,_15,_16, \
                  _17,_18,_19,_20,_21,_22,_23,_24,_25,_26,_27,_28,_29,_30,_31,_32, \
                  _33,_34,_35,_36,_37,_38,_39,_40,_41,_42,_43,_44,_45,_46,_47,_48, \
                  _49,_50,_51,_52,_53,_54,_55,_56,_57,_58,_59,_60,_61,_62,_63, N, ...) N

#define MP_NARG_R() 63,62,61,60,59,58,57,56,55,54,53,52,51,50,49,48, \
                    47,46,45,44,43,42,41,40,39,38,37,36,35,34,33,32, \
                    31,30,29,28,27,26,25,24,23,22,21,20,19,18,17,16, \
                    15,14,13,12,11,10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0

#define MP_NARG_(...) MP_NARG_N(__VA_ARGS__)
#define MP_NARG(...)  MP_NARG_(__VA_ARGS__, MP_NARG_R())

// FOR_EACH macro

#define MP_FOR_EACH_1(idx, func, arg, sep, ...)      func(arg, idx, __VA_ARGS__)
#define MP_FOR_EACH_2(idx, func, arg, sep, x, ...)   func(arg, idx, x) sep() MP_FOR_EACH_1(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_3(idx, func, arg, sep, x, ...)   func(arg, idx, x) sep() MP_FOR_EACH_2(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_4(idx, func, arg, sep, x, ...)   func(arg, idx, x) sep() MP_FOR_EACH_3(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_5(idx, func, arg, sep, x, ...)   func(arg, idx, x) sep() MP_FOR_EACH_4(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_6(idx, func, arg, sep, x, ...)   func(arg, idx, x) sep() MP_FOR_EACH_5(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_7(idx, func, arg, sep, x, ...)   func(arg, idx, x) sep() MP_FOR_EACH_6(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_8(idx, func, arg, sep, x, ...)   func(arg, idx, x) sep() MP_FOR_EACH_7(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_9(idx, func, arg, sep, x, ...)   func(arg, idx, x) sep() MP_FOR_EACH_8(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_10(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_9(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_11(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_10(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_12(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_11(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_13(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_12(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_14(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_13(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_15(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_14(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_16(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_15(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_17(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_16(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_18(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_17(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_19(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_18(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_20(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_19(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_21(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_20(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_22(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_21(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_23(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_22(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_24(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_23(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_25(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_24(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_26(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_25(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_27(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_26(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_28(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_27(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_29(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_28(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_30(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_29(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_31(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_30(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_32(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_31(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_33(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_32(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_34(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_33(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_35(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_34(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_36(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_35(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_37(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_36(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_38(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_37(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_39(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_38(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_40(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_39(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_41(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_40(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_42(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_41(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_43(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_42(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_44(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_43(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_45(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_44(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_46(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_45(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_47(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_46(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_48(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_47(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_49(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_48(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_50(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_49(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_51(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_50(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_52(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_51(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_53(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_52(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_54(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_53(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_55(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_54(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_56(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_55(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_57(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_56(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_58(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_57(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_59(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_58(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_60(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_59(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_61(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_60(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_62(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_61(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_63(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_62(MP_INC(idx), func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH_64(idx, func, arg, sep, x, ...)  func(arg, idx, x) sep() MP_FOR_EACH_63(MP_INC(idx), func, arg, sep, __VA_ARGS__)

#define MP_FOR_EACH_(N, func, arg, sep, ...) MP_CONCAT(MP_FOR_EACH_, N)(0, func, arg, sep, __VA_ARGS__)
#define MP_FOR_EACH(func, arg, sep, ...) MP_FOR_EACH_(MP_NARG(__VA_ARGS__), func, arg, sep, __VA_ARGS__)

// REVERSE_FOR_EACH macro

#define MP_REVERSE_FOR_EACH_1(func, arg, sep, ...)      func(arg, 0, __VA_ARGS__)
#define MP_REVERSE_FOR_EACH_2(func, arg, sep, x, ...)   MP_REVERSE_FOR_EACH_1(func, arg, sep, __VA_ARGS__) sep() func(arg, 1, x)
#define MP_REVERSE_FOR_EACH_3(func, arg, sep, x, ...)   MP_REVERSE_FOR_EACH_2(func, arg, sep, __VA_ARGS__) sep() func(arg, 2, x)
#define MP_REVERSE_FOR_EACH_4(func, arg, sep, x, ...)   MP_REVERSE_FOR_EACH_3(func, arg, sep, __VA_ARGS__) sep() func(arg, 3, x)
#define MP_REVERSE_FOR_EACH_5(func, arg, sep, x, ...)   MP_REVERSE_FOR_EACH_4(func, arg, sep, __VA_ARGS__) sep() func(arg, 4, x)
#define MP_REVERSE_FOR_EACH_6(func, arg, sep, x, ...)   MP_REVERSE_FOR_EACH_5(func, arg, sep, __VA_ARGS__) sep() func(arg, 5, x)
#define MP_REVERSE_FOR_EACH_7(func, arg, sep, x, ...)   MP_REVERSE_FOR_EACH_6(func, arg, sep, __VA_ARGS__) sep() func(arg, 6, x)
#define MP_REVERSE_FOR_EACH_8(func, arg, sep, x, ...)   MP_REVERSE_FOR_EACH_7(func, arg, sep, __VA_ARGS__) sep() func(arg, 7, x)
#define MP_REVERSE_FOR_EACH_9(func, arg, sep, x, ...)   MP_REVERSE_FOR_EACH_8(func, arg, sep, __VA_ARGS__) sep() func(arg, 8, x)
#define MP_REVERSE_FOR_EACH_10(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_9(func, arg, sep, __VA_ARGS__) sep() func(arg, 9, x)
#define MP_REVERSE_FOR_EACH_11(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_10(func, arg, sep, __VA_ARGS__) sep() func(arg, 10, x)
#define MP_REVERSE_FOR_EACH_12(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_11(func, arg, sep, __VA_ARGS__) sep() func(arg, 11, x)
#define MP_REVERSE_FOR_EACH_13(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_12(func, arg, sep, __VA_ARGS__) sep() func(arg, 12, x)
#define MP_REVERSE_FOR_EACH_14(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_13(func, arg, sep, __VA_ARGS__) sep() func(arg, 13, x)
#define MP_REVERSE_FOR_EACH_15(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_14(func, arg, sep, __VA_ARGS__) sep() func(arg, 14, x)
#define MP_REVERSE_FOR_EACH_16(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_15(func, arg, sep, __VA_ARGS__) sep() func(arg, 15, x)
#define MP_REVERSE_FOR_EACH_17(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_16(func, arg, sep, __VA_ARGS__) sep() func(arg, 16, x)
#define MP_REVERSE_FOR_EACH_18(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_17(func, arg, sep, __VA_ARGS__) sep() func(arg, 17, x)
#define MP_REVERSE_FOR_EACH_19(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_18(func, arg, sep, __VA_ARGS__) sep() func(arg, 18, x)
#define MP_REVERSE_FOR_EACH_20(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_19(func, arg, sep, __VA_ARGS__) sep() func(arg, 19, x)
#define MP_REVERSE_FOR_EACH_21(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_20(func, arg, sep, __VA_ARGS__) sep() func(arg, 20, x)
#define MP_REVERSE_FOR_EACH_22(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_21(func, arg, sep, __VA_ARGS__) sep() func(arg, 21, x)
#define MP_REVERSE_FOR_EACH_23(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_22(func, arg, sep, __VA_ARGS__) sep() func(arg, 22, x)
#define MP_REVERSE_FOR_EACH_24(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_23(func, arg, sep, __VA_ARGS__) sep() func(arg, 23, x)
#define MP_REVERSE_FOR_EACH_25(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_24(func, arg, sep, __VA_ARGS__) sep() func(arg, 24, x)
#define MP_REVERSE_FOR_EACH_26(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_25(func, arg, sep, __VA_ARGS__) sep() func(arg, 25, x)
#define MP_REVERSE_FOR_EACH_27(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_26(func, arg, sep, __VA_ARGS__) sep() func(arg, 26, x)
#define MP_REVERSE_FOR_EACH_28(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_27(func, arg, sep, __VA_ARGS__) sep() func(arg, 27, x)
#define MP_REVERSE_FOR_EACH_29(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_28(func, arg, sep, __VA_ARGS__) sep() func(arg, 28, x)
#define MP_REVERSE_FOR_EACH_30(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_29(func, arg, sep, __VA_ARGS__) sep() func(arg, 29, x)
#define MP_REVERSE_FOR_EACH_31(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_30(func, arg, sep, __VA_ARGS__) sep() func(arg, 30, x)
#define MP_REVERSE_FOR_EACH_32(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_31(func, arg, sep, __VA_ARGS__) sep() func(arg, 31, x)
#define MP_REVERSE_FOR_EACH_33(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_32(func, arg, sep, __VA_ARGS__) sep() func(arg, 32, x)
#define MP_REVERSE_FOR_EACH_34(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_33(func, arg, sep, __VA_ARGS__) sep() func(arg, 33, x)
#define MP_REVERSE_FOR_EACH_35(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_34(func, arg, sep, __VA_ARGS__) sep() func(arg, 34, x)
#define MP_REVERSE_FOR_EACH_36(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_35(func, arg, sep, __VA_ARGS__) sep() func(arg, 35, x)
#define MP_REVERSE_FOR_EACH_37(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_36(func, arg, sep, __VA_ARGS__) sep() func(arg, 36, x)
#define MP_REVERSE_FOR_EACH_38(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_37(func, arg, sep, __VA_ARGS__) sep() func(arg, 37, x)
#define MP_REVERSE_FOR_EACH_39(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_38(func, arg, sep, __VA_ARGS__) sep() func(arg, 38, x)
#define MP_REVERSE_FOR_EACH_40(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_39(func, arg, sep, __VA_ARGS__) sep() func(arg, 39, x)
#define MP_REVERSE_FOR_EACH_41(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_40(func, arg, sep, __VA_ARGS__) sep() func(arg, 40, x)
#define MP_REVERSE_FOR_EACH_42(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_41(func, arg, sep, __VA_ARGS__) sep() func(arg, 41, x)
#define MP_REVERSE_FOR_EACH_43(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_42(func, arg, sep, __VA_ARGS__) sep() func(arg, 42, x)
#define MP_REVERSE_FOR_EACH_44(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_43(func, arg, sep, __VA_ARGS__) sep() func(arg, 43, x)
#define MP_REVERSE_FOR_EACH_45(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_44(func, arg, sep, __VA_ARGS__) sep() func(arg, 44, x)
#define MP_REVERSE_FOR_EACH_46(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_45(func, arg, sep, __VA_ARGS__) sep() func(arg, 45, x)
#define MP_REVERSE_FOR_EACH_47(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_46(func, arg, sep, __VA_ARGS__) sep() func(arg, 46, x)
#define MP_REVERSE_FOR_EACH_48(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_47(func, arg, sep, __VA_ARGS__) sep() func(arg, 47, x)
#define MP_REVERSE_FOR_EACH_49(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_48(func, arg, sep, __VA_ARGS__) sep() func(arg, 48, x)
#define MP_REVERSE_FOR_EACH_50(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_49(func, arg, sep, __VA_ARGS__) sep() func(arg, 49, x)
#define MP_REVERSE_FOR_EACH_51(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_50(func, arg, sep, __VA_ARGS__) sep() func(arg, 50, x)
#define MP_REVERSE_FOR_EACH_52(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_51(func, arg, sep, __VA_ARGS__) sep() func(arg, 51, x)
#define MP_REVERSE_FOR_EACH_53(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_52(func, arg, sep, __VA_ARGS__) sep() func(arg, 52, x)
#define MP_REVERSE_FOR_EACH_54(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_53(func, arg, sep, __VA_ARGS__) sep() func(arg, 53, x)
#define MP_REVERSE_FOR_EACH_55(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_54(func, arg, sep, __VA_ARGS__) sep() func(arg, 54, x)
#define MP_REVERSE_FOR_EACH_56(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_55(func, arg, sep, __VA_ARGS__) sep() func(arg, 55, x)
#define MP_REVERSE_FOR_EACH_57(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_56(func, arg, sep, __VA_ARGS__) sep() func(arg, 56, x)
#define MP_REVERSE_FOR_EACH_58(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_57(func, arg, sep, __VA_ARGS__) sep() func(arg, 57, x)
#define MP_REVERSE_FOR_EACH_59(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_58(func, arg, sep, __VA_ARGS__) sep() func(arg, 58, x)
#define MP_REVERSE_FOR_EACH_60(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_59(func, arg, sep, __VA_ARGS__) sep() func(arg, 59, x)
#define MP_REVERSE_FOR_EACH_61(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_60(func, arg, sep, __VA_ARGS__) sep() func(arg, 60, x)
#define MP_REVERSE_FOR_EACH_62(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_61(func, arg, sep, __VA_ARGS__) sep() func(arg, 61, x)
#define MP_REVERSE_FOR_EACH_63(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_62(func, arg, sep, __VA_ARGS__) sep() func(arg, 62, x)
#define MP_REVERSE_FOR_EACH_64(func, arg, sep, x, ...)  MP_REVERSE_FOR_EACH_63(func, arg, sep, __VA_ARGS__) sep() func(arg, 63, x)

#define MP_REVERSE_FOR_EACH_(N, func, arg, sep, ...) MP_CONCAT(MP_REVERSE_FOR_EACH_, N)(func, arg, sep, __VA_ARGS__)
#define MP_REVERSE_FOR_EACH(func, arg, sep, ...) MP_REVERSE_FOR_EACH_(MP_NARG(__VA_ARGS__), func, arg, sep, __VA_ARGS__)

#define MP_FIRST_ARG_(N, ...) N
#define MP_FIRST_ARG(...) MP_FIRST_ARG_(__VA_ARGS__, ignore)

// MP_REPEAT macro

#define MP_REPEAT_0(func, sep)
#define MP_REPEAT_1(func, sep) func(0)
#define MP_REPEAT_2(func, sep) MP_REPEAT_1(func, sep) sep func(1)
#define MP_REPEAT_3(func, sep) MP_REPEAT_2(func, sep) sep func(2)
#define MP_REPEAT_4(func, sep) MP_REPEAT_3(func, sep) sep func(3)
#define MP_REPEAT_5(func, sep) MP_REPEAT_4(func, sep) sep func(4)
#define MP_REPEAT_6(func, sep) MP_REPEAT_5(func, sep) sep func(5)
#define MP_REPEAT_7(func, sep) MP_REPEAT_6(func, sep) sep func(6)
#define MP_REPEAT_8(func, sep) MP_REPEAT_7(func, sep) sep func(7)
#define MP_REPEAT_9(func, sep) MP_REPEAT_8(func, sep) sep func(8)
#define MP_REPEAT_10(func, sep) MP_REPEAT_9(func, sep) sep func(9)
#define MP_REPEAT_11(func, sep) MP_REPEAT_10(func, sep) sep func(10)
#define MP_REPEAT_12(func, sep) MP_REPEAT_11(func, sep) sep func(11)
#define MP_REPEAT_13(func, sep) MP_REPEAT_12(func, sep) sep func(12)
#define MP_REPEAT_14(func, sep) MP_REPEAT_13(func, sep) sep func(13)
#define MP_REPEAT_15(func, sep) MP_REPEAT_14(func, sep) sep func(14)
#define MP_REPEAT_16(func, sep) MP_REPEAT_15(func, sep) sep func(15)
#define MP_REPEAT_17(func, sep) MP_REPEAT_16(func, sep) sep func(16)
#define MP_REPEAT_18(func, sep) MP_REPEAT_17(func, sep) sep func(17)
#define MP_REPEAT_19(func, sep) MP_REPEAT_18(func, sep) sep func(18)
#define MP_REPEAT_20(func, sep) MP_REPEAT_19(func, sep) sep func(19)
#define MP_REPEAT_21(func, sep) MP_REPEAT_20(func, sep) sep func(20)
#define MP_REPEAT_22(func, sep) MP_REPEAT_21(func, sep) sep func(21)
#define MP_REPEAT_23(func, sep) MP_REPEAT_22(func, sep) sep func(22)
#define MP_REPEAT_24(func, sep) MP_REPEAT_23(func, sep) sep func(23)
#define MP_REPEAT_25(func, sep) MP_REPEAT_24(func, sep) sep func(24)
#define MP_REPEAT_26(func, sep) MP_REPEAT_25(func, sep) sep func(25)
#define MP_REPEAT_27(func, sep) MP_REPEAT_26(func, sep) sep func(26)
#define MP_REPEAT_28(func, sep) MP_REPEAT_27(func, sep) sep func(27)
#define MP_REPEAT_29(func, sep) MP_REPEAT_28(func, sep) sep func(28)
#define MP_REPEAT_30(func, sep) MP_REPEAT_29(func, sep) sep func(29)
#define MP_REPEAT_31(func, sep) MP_REPEAT_30(func, sep) sep func(30)
#define MP_REPEAT_32(func, sep) MP_REPEAT_31(func, sep) sep func(31)
#define MP_REPEAT(N, func, sep) MP_CONCAT(MP_REPEAT_, N)(func, sep)
// --- End of content from sim/common/mp_macros.h ---

// --- Start of content from sim/common/stringutil.h ---
// Original pragma: #pragma once
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


#include <iostream>
#include  <iomanip>

class ByteStream : public std::istream {
public:
  ByteStream(const void *buf, std::size_t size) : buf_(buf), size_(size) {}

  friend std::ostream& operator<<(std::ostream& os, const ByteStream& obj) {
    auto oldflags = os.flags();
    auto oldwidth = os.width();
    auto oldfill  = os.fill();
    for (std::size_t i = 0, n = obj.size_; i < n; ++i) {
      int byte = *((uint8_t*)obj.buf_ + (n - 1 - i));
      os << std::hex << std::setw(2) << std::setfill('0') << byte;
    }
    os.fill(oldfill);
    os.width(oldwidth);
    os.flags(oldflags);
    return os;
  }

private:
  const void *buf_;
  std::size_t size_;
};

class IndentStream : public std::streambuf {
public:
  explicit IndentStream(std::streambuf* dest, int indent = 4)
    : dest_(dest)
    , isBeginLine_(true)
    , indent_(indent, ' ')
    , owner_(nullptr)
  {}

  explicit IndentStream(std::ostream& dest, int indent = 4)
    : dest_(dest.rdbuf())
    , isBeginLine_(true)
    , indent_(indent, ' ')
    , owner_(&dest) {
      owner_->rdbuf(this);
  }

  virtual ~IndentStream() {
    if (owner_)
        owner_->rdbuf(dest_);
  }

protected:
  virtual int overflow(int ch) {
    if (isBeginLine_ && ch != '\n') {
      dest_->sputn(indent_.data(), indent_.size());
    }
    isBeginLine_ = ch == '\n';
    return dest_->sputc(ch);
  }

private:
  std::streambuf* dest_;
  bool            isBeginLine_;
  std::string     indent_;
  std::ostream*   owner_;
};

template <typename... Args>
std::string StrFormat(const std::string& fmt, Args... args) {
  auto size = std::snprintf(nullptr, 0, fmt.c_str(), args...) + 1;
  if (size <= 0) {
    throw std::runtime_error("Error during formatting.");
  }
  std::vector<char> buf(size);
  std::snprintf(buf.data(), size, fmt.c_str(), args...);
  return std::string(buf.data(), buf.data() + size - 1);
}
// --- End of content from sim/common/stringutil.h ---

// --- Start of content from sim/common/mem.h ---
// Original pragma: #pragma once
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


#include <cstdint>
#include <vector>
#include <map>
#include <unordered_map>
#include <cstdint>
#include <unordered_set>
#include <stdexcept>
// MERGED_LOCALLY: #include "VX_config.h"
#ifdef VM_ENABLE
#include <unordered_set>
#include <stdexcept>
#include <cassert>
#endif


namespace vortex {


#ifdef VM_ENABLE

// VA MODE
#define BARE 0x0
#define SV32 0x1
#define SV39 0x8

enum ACCESS_TYPE {
  LOAD,
  STORE,
  FETCH
};
class SATP_t
{
  private:
    uint64_t address;
    uint16_t asid;
    uint8_t  mode;
    uint64_t ppn;
    uint64_t satp;

    uint64_t bits(uint64_t input, uint8_t s_idx, uint8_t e_idx)
    {
        return (input>> s_idx) & (((uint64_t)1 << (e_idx - s_idx + 1)) - 1);
    }
    bool bit(uint64_t input , uint8_t idx)
    {
        return (input ) & ((uint64_t)1 << idx);
    }

  public:
    SATP_t(uint64_t satp) : satp(satp)
    {
#ifdef XLEN_32 
      mode = bit(satp, 31);
      asid = bits(satp, 22, 30);
      ppn  = bits(satp, 0,21);
#else
      mode = bits(satp, 60,63);
      asid = bits(satp, 44, 59);
      ppn  = bits(satp, 0,43);
#endif 
      address = ppn << MEM_PAGE_LOG2_SIZE;
    }

    SATP_t(uint64_t address, uint16_t asid) : address(address), asid(asid)
    { 
#ifdef XLEN_32 
      assert((address >> 32) == 0 && "Upper 32 bits are not zero!");
#endif
      mode= VM_ADDR_MODE;
      // asid = 0 ; 
      ppn = address >> MEM_PAGE_LOG2_SIZE;
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wshift-count-overflow"
#ifdef XLEN_32 
      satp = (((uint64_t)mode << 31) | ((uint64_t)asid << 22) | ppn);
#else
      satp = (((uint64_t)mode << 60) | ((uint64_t)asid << 44) | ppn);
#endif
#pragma GCC diagnostic pop
    }
    uint8_t get_mode()
    {
      return mode;
    } 
    uint16_t get_asid()
    {
      return asid;
    } 
    uint64_t get_base_ppn()
    {
      return ppn;
    } 
    uint64_t get_satp()
    {
      return satp;
    } 
};


class Page_Fault_Exception : public std::runtime_error /* or logic_error */
{
public:
    Page_Fault_Exception(const std::string& what = "") : std::runtime_error(what) {}
    uint64_t addr;
    ACCESS_TYPE type;
};
#endif
struct BadAddress {};
struct OutOfRange {};

class MemDevice {
public:
  virtual ~MemDevice() {}
  virtual uint64_t size() const = 0;
  virtual void read(void* data, uint64_t addr, uint64_t size) = 0;
  virtual void write(const void* data, uint64_t addr, uint64_t size) = 0;
};

///////////////////////////////////////////////////////////////////////////////

class RamMemDevice : public MemDevice {
public:
  RamMemDevice(uint64_t size, uint32_t wordSize);
  RamMemDevice(const char* filename, uint32_t wordSize);
  ~RamMemDevice() {}

  void read(void* data, uint64_t addr, uint64_t size) override;
  void write(const void* data, uint64_t addr, uint64_t size) override;

  virtual uint64_t size() const {
    return contents_.size();
  };

protected:
  std::vector<uint8_t> contents_;
  uint32_t wordSize_;
};

///////////////////////////////////////////////////////////////////////////////

class RomMemDevice : public RamMemDevice {
public:
  RomMemDevice(const char *filename, uint32_t wordSize)
    : RamMemDevice(filename, wordSize)
  {}

  RomMemDevice(uint64_t size, uint32_t wordSize)
    : RamMemDevice(size, wordSize)
  {}

  ~RomMemDevice();

  void write(const void* data, uint64_t addr, uint64_t size) override;
};

///////////////////////////////////////////////////////////////////////////////

class MemoryUnit {
public:

// HW: Expand PageFault struct to contain access_type info for debug purposes
  struct PageFault {
    PageFault(uint64_t a, bool nf)
      : faultAddr(a)
      , notFound(nf)
      // , access_type(ACCESS_TYPE::LOAD)
    {}
    uint64_t    faultAddr;
    bool        notFound;
    // ACCESS_TYPE access_type;
  };

#ifdef VM_ENABLE
  MemoryUnit(uint64_t pageSize = MEM_PAGE_SIZE);
  ~MemoryUnit(){
    if ( this->satp_ != NULL) 
      delete this->satp_;
  };
#else
  MemoryUnit(uint64_t pageSize = 0);
#endif

  void attach(MemDevice &m, uint64_t start, uint64_t end);


#ifdef VM_ENABLE
  void read(void* data, uint64_t addr, uint32_t size, ACCESS_TYPE type = ACCESS_TYPE::LOAD);
  void write(const void* data, uint64_t addr, uint32_t size, ACCESS_TYPE type = ACCESS_TYPE::STORE);
#else
  void read(void* data, uint64_t addr, uint32_t size, bool sup);
  void write(const void* data, uint64_t addr, uint32_t size, bool sup);
#endif

  void amo_reserve(uint64_t addr);
  bool amo_check(uint64_t addr);

#ifdef VM_ENABLE
  void tlbAdd(uint64_t virt, uint64_t phys, uint32_t flags, uint64_t size_bits);
  uint8_t is_satp_unset();
  uint64_t get_satp();
  uint8_t get_mode();
  uint64_t get_base_ppn();
  void set_satp(uint64_t satp);
#else
  void tlbAdd(uint64_t virt, uint64_t phys, uint32_t flags);
#endif

  void tlbRm(uint64_t vaddr);
  void tlbFlush() {
    tlb_.clear();
  }

private:

  struct amo_reservation_t {
    uint64_t addr;
    bool     valid;
  };

  class ADecoder {
  public:
    ADecoder() {}

    void read(void* data, uint64_t addr, uint64_t size);
    void write(const void* data, uint64_t addr, uint64_t size);

    void map(uint64_t start, uint64_t end, MemDevice &md);

  private:

    struct mem_accessor_t {
      MemDevice*  md;
      uint64_t    addr;
    };

    struct entry_t {
      MemDevice*  md;
      uint64_t    start;
      uint64_t    end;
    };

    bool lookup(uint64_t addr, uint32_t wordSize, mem_accessor_t*);

    std::vector<entry_t> entries_;
  };

  struct TLBEntry {
    TLBEntry() {}
  #ifdef VM_ENABLE
    TLBEntry(uint32_t pfn, uint32_t flags, uint64_t size_bits)
      : pfn(pfn)
      , flags(flags)
      , mru_bit(true)
      , size_bits (size_bits)
    {
      d = bit(7);
      a = bit(6);
      g = bit(5);
      u = bit(4);
      x = bit(3);
      w = bit(2);
      r = bit(1);
      v = bit(0);
    }
    bool bit(uint8_t idx)
    {
        return (flags) & (1 << idx);
    }

    uint32_t pfn;
    uint32_t flags;
    bool mru_bit;
    uint64_t size_bits;
    bool d, a, g, u, x, w, r, v;
  #else
    TLBEntry(uint32_t pfn, uint32_t flags)
      : pfn(pfn)
      , flags(flags) 
    {}
    uint32_t pfn;
    uint32_t flags;
  #endif
  };

#ifdef VM_ENABLE
  std::pair<bool, uint64_t> tlbLookup(uint64_t vAddr, ACCESS_TYPE type, uint64_t* size_bits);

  bool need_trans(uint64_t dev_pAddr);
  uint64_t vAddr_to_pAddr(uint64_t vAddr, ACCESS_TYPE type);

  uint64_t get_pte_address(uint64_t base_ppn, uint64_t vpn);
  std::pair<uint64_t, uint8_t> page_table_walk(uint64_t vAddr_bits, ACCESS_TYPE type, uint64_t* size_bits);
#else 
  uint64_t toPhyAddr(uint64_t vAddr, uint32_t flagMask);
  TLBEntry tlbLookup(uint64_t vAddr, uint32_t flagMask);
#endif



  std::unordered_map<uint64_t, TLBEntry> tlb_;
  uint64_t  pageSize_;
  ADecoder  decoder_;
#ifndef VM_ENABLE
  bool      enableVM_;
#endif

  amo_reservation_t amo_reservation_;
#ifdef VM_ENABLE
  std::unordered_set<uint64_t> unique_translations;
  uint64_t TLB_HIT, TLB_MISS, TLB_EVICT, PTW, PERF_UNIQUE_PTW;
  SATP_t *satp_;
#endif

};

///////////////////////////////////////////////////////////////////////////////

class ACLManager {
public:

    void set(uint64_t addr, uint64_t size, int flags);

    bool check(uint64_t addr, uint64_t size, int flags) const;

private:

  struct acl_entry_t {
    uint64_t end;
    int32_t flags;
  };

  std::map<uint64_t, acl_entry_t> acl_map_;
};

///////////////////////////////////////////////////////////////////////////////

class RAM : public MemDevice {
public:

  RAM(uint64_t capacity, uint32_t page_size);
  RAM(uint64_t capacity) : RAM(capacity, capacity) {}
  ~RAM();

  void clear();

  uint64_t size() const override;

  void read(void* data, uint64_t addr, uint64_t size) override;
  void write(const void* data, uint64_t addr, uint64_t size) override;

  void loadBinImage(const char* filename, uint64_t destination);
  void loadHexImage(const char* filename);

  uint8_t& operator[](uint64_t address) {
    return *this->get(address);
  }

  const uint8_t& operator[](uint64_t address) const {
    return *this->get(address);
  }

  void set_acl(uint64_t addr, uint64_t size, int flags);

  void enable_acl(bool enable) {
    check_acl_ = enable;
  }

private:

  uint8_t *get(uint64_t address) const;

  uint64_t capacity_;
  uint32_t page_bits_;
  mutable std::unordered_map<uint64_t, uint8_t*> pages_;
  mutable uint8_t* last_page_;
  mutable uint64_t last_page_index_;
  ACLManager acl_mngr_;
  bool check_acl_;
};

#ifdef VM_ENABLE
class PTE_t 
{

  private:
    uint64_t address;
    uint64_t bits(uint64_t input, uint8_t s_idx, uint8_t e_idx)
    {
        return (input>> s_idx) & (((uint64_t)1 << (e_idx - s_idx + 1)) - 1);
    }
    bool bit(uint64_t input, uint8_t idx)
    {
        return (input) & ((uint64_t)1 << idx);
    }

  public:
#if VM_ADDR_MODE == SV39
    bool N;
    uint8_t PBMT;
#endif
    uint64_t ppn;
    uint32_t rsw;
    uint32_t flags;
    uint8_t level;
    bool d, a, g, u, x, w, r, v;
    uint64_t pte_bytes;

    void set_flags (uint32_t flag)
    {
      this->flags = flag;
      d = bit(flags,7);
      a = bit(flags,6);
      g = bit(flags,5);
      u = bit(flags,4);
      x = bit(flags,3);
      w = bit(flags,2);
      r = bit(flags,1);
      v = bit(flags,0);
    }

    PTE_t(uint64_t address, uint32_t flags) : address(address)
    {
#if VM_ADDR_MODE == SV39
      N = 0;
      PBMT = 0;
      level = 3;
      ppn = address >> MEM_PAGE_LOG2_SIZE;
      // Reserve for Super page support
      // ppn = new uint32_t [level];
      // ppn[2]=bits(address,28,53);
      // ppn[1]=bits(address,19,27);
      // ppn[0]=bits(address,10,18);
      set_flags(flags);
      // pte_bytes = (N  << 63) | (PBMT  << 61) | (ppn <<10) | flags ;
      pte_bytes = (ppn <<10) | flags ;
#else // if VM_ADDR_MODE == SV32
      assert((address>> 32) == 0 && "Upper 32 bits are not zero!");
      level = 2;
      ppn = address >> MEM_PAGE_LOG2_SIZE;
      // Reserve for Super page support
      // ppn = new uint32_t[level];
      // ppn[1]=bits(address,20,31);
      // ppn[0]=bits(address,10,19);
      set_flags(flags);
      pte_bytes = ppn <<10 | flags ;
#endif
    }

    PTE_t(uint64_t pte_bytes) : pte_bytes(pte_bytes)
    { 
#if VM_ADDR_MODE == SV39
      N = bit(pte_bytes,63);
      PBMT = bits(pte_bytes,61,62);
      level = 3;
      ppn=bits(pte_bytes,10,53);
      address = ppn << MEM_PAGE_LOG2_SIZE; 
      // Reserve for Super page support
      // ppn = new uint32_t [level];
      // ppn[2]=bits(pte_bytes,28,53);
      // ppn[1]=bits(pte_bytes,19,27);
      // ppn[0]=bits(pte_bytes,10,18);
#else //#if VM_ADDR_MODE == SV32
      assert((pte_bytes >> 32) == 0 && "Upper 32 bits are not zero!");
      level = 2;
      ppn=bits(pte_bytes,10, 31);
      address = ppn << MEM_PAGE_LOG2_SIZE; 
      // Reserve for Super page support
      // ppn = new uint32_t[level];
      // ppn[1]=bits(address, 20,31);
      // ppn[0]=bits(address, 10,19);
#endif
      rsw = bits(pte_bytes,8,9);
      set_flags((uint32_t)(bits(pte_bytes,0,7)));
    }
    ~PTE_t()
    {
      // Reserve for Super page support
      // delete ppn;
    }
};

class vAddr_t 
{

  private:
    uint64_t address;
    uint64_t bits(uint8_t s_idx, uint8_t e_idx)
    {
        return (address>> s_idx) & (((uint64_t)1 << (e_idx - s_idx + 1)) - 1);
    }
    bool bit( uint8_t idx)
    {
        return (address) & ((uint64_t)1 << idx);
    }

  public:
    uint64_t *vpn;
    uint64_t pgoff;
    uint8_t level;
    vAddr_t(uint64_t address) : address(address)
    {
#if VM_ADDR_MODE == SV39
      level = 3;
      vpn = new uint64_t [level];
      vpn[2] = bits(30,38);
      vpn[1] = bits(21,29);
      vpn[0] = bits(12,20);
      pgoff = bits(0,11);
#else //#if VM_ADDR_MODE == SV32
      assert((address>> 32) == 0 && "Upper 32 bits are not zero!");
      level = 2;
      vpn = new uint64_t [level];
      vpn[1] = bits(22,31);
      vpn[0] = bits(12,21);
      pgoff = bits(0,11);
#endif
    }

    ~vAddr_t()
    {
      delete vpn;
    }
};
#endif

} // namespace vortex
// --- End of content from sim/common/mem.h ---

// --- Start of content from sim/common/bitmanip.h ---
// Original pragma: #pragma once
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


#include <cstdint>
#include <assert.h>

template <typename T>
constexpr uint32_t count_leading_zeros(T value) {
  static_assert(std::is_integral<T>::value, "invalid data type");
  if constexpr (sizeof(T) > 4) {
    return value ? __builtin_clzll(value) - (64 - sizeof(T) * 8) : sizeof(T) * 8;
  } else {
    return value ? __builtin_clz(value) - (32 - sizeof(T) * 8) : sizeof(T) * 8;
  }
}

template <typename T>
constexpr uint32_t count_trailing_zeros(T value) {
  static_assert(std::is_integral<T>::value, "invalid data type");
  if constexpr (sizeof(T) > 4) {
    return value ? __builtin_ctzll(value) : (sizeof(T) * 8);
  } else {
    return value ? __builtin_ctz(value) : (sizeof(T) * 8);
  }
}

template <typename T>
constexpr bool ispow2(T value) {
  static_assert(std::is_integral<T>::value, "invalid data type");
  return value && !(value & (value - 1));
}

template <typename T>
constexpr uint32_t log2ceil(T value) {
  static_assert(std::is_integral<T>::value, "invalid data type");
    return (sizeof(T) * 8) - count_leading_zeros<T>(value - 1);
}

template <typename T>
inline unsigned log2up(T value) {
  static_assert(std::is_integral<T>::value, "invalid data type");
  return std::max<uint32_t>(1, log2ceil(value));
}

template <typename T>
constexpr unsigned log2floor(T value) {
  static_assert(std::is_integral<T>::value, "invalid data type");
  return (sizeof(T) * 8 - 1) - count_leading_zeros<T>(value);
}

template <typename T>
constexpr unsigned ceil2(T value) {
  static_assert(std::is_integral<T>::value, "invalid data type");
  return (sizeof(T) * 8) - count_leading_zeros<T>(value);
}

inline uint64_t bit_clr(uint64_t bits, uint32_t index) {
    assert(index <= 63);
    return bits & ~(1ull << index);
}

inline uint64_t bit_set(uint64_t bits, uint32_t index) {
    assert(index <= 63);
    return bits | (1ull << index);
}

inline bool bit_get(uint64_t bits, uint32_t index) {
    assert(index <= 63);
    return (bits >> index) & 0x1;
}

inline uint64_t bit_clrw(uint64_t bits, uint32_t start, uint32_t end) {
    assert(end >= start);
    assert(end <= 63);
    uint32_t shift = 63 - end;
    uint64_t mask = (0xffffffffffffffff << (shift + start)) >> shift;
    return bits & ~mask;
}

inline uint64_t bit_setw(uint64_t bits, uint32_t start, uint32_t end, uint64_t value) {
    assert(end >= start);
    assert(end <= 63);
    uint32_t shift = 63 - end;
    uint64_t dirty = (value << (shift + start)) >> shift;
    return bit_clrw(bits, start, end) | dirty;
}

inline uint64_t bit_getw(uint64_t bits, uint32_t start, uint32_t end) {
    assert(end >= start);
    assert(end <= 63);
    uint32_t shift = 63 - end;
    return (bits << shift) >> (shift + start);
}

inline uint64_t bit_reverse(uint64_t bits) {
  bits = ((bits & 0xAAAAAAAAAAAAAAAA) >>  1) | ((bits & 0x5555555555555555) <<  1);
  bits = ((bits & 0xCCCCCCCCCCCCCCCC) >>  2) | ((bits & 0x3333333333333333) <<  2);
  bits = ((bits & 0xF0F0F0F0F0F0F0F0) >>  4) | ((bits & 0x0F0F0F0F0F0F0F0F) <<  4);
  bits = ((bits & 0xFF00FF00FF00FF00) >>  8) | ((bits & 0x00FF00FF00FF00FF) <<  8);
  bits = ((bits & 0xFFFF0000FFFF0000) >> 16) | ((bits & 0x0000FFFF0000FFFF) << 16);
  bits = (bits >> 32) | (bits << 32);
  return bits;
}

inline uint64_t bit_reverse(uint64_t bits, uint32_t width) {
  assert(width <= 64);
  uint64_t reversed(0);
  for (uint32_t i = 0; i < width; ++i) {
    if (bits & (1ULL << i)) {
      reversed |= (1ULL << (width - 1 - i));
    }
  }
  return reversed;
}

template <typename T = uint32_t>
T sext(const T& word, uint32_t width) {
  assert(width > 1);
  assert(width <= (sizeof(T) * 8));
  if (width == (sizeof(T) * 8))
    return word;
  T mask((static_cast<T>(1) << width) - 1);
  return ((word >> (width - 1)) & 0x1) ? (word | ~mask) : (word & mask);
}

template <typename T = uint32_t>
T zext(const T& word, uint32_t width) {
  assert(width > 1);
  assert(width <= (sizeof(T) * 8));
  if (width == (sizeof(T) * 8))
    return word;
  T mask((static_cast<T>(1) << width) - 1);
  return word & mask;
}
// --- End of content from sim/common/bitmanip.h ---

// --- Start of content from sim/common/dram_sim.h ---
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#include <stdint.h>

namespace vortex {

class DramSim {
public:
  typedef void (*ResponseCallback)(void *arg);

  DramSim(uint32_t num_channels, uint32_t channel_size, float clock_ratio);
  ~DramSim();

  void reset();

  void tick();

  // addr: per-channel block address
  void send_request(uint64_t addr, bool is_write, ResponseCallback response_cb, void* arg);

private:
	class Impl;
	Impl* impl_;
};

}
// --- End of content from sim/common/dram_sim.h ---

// --- Start of content from sim/common/rvfloats.h ---
// Original pragma: #pragma once
// Copyright © 2019-2023
// 
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
// 
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


#include <cstdint>

#ifdef __cplusplus
extern "C" {
#endif

uint32_t rv_fadd_s(uint32_t a, uint32_t b, uint32_t frm, uint32_t* fflags);
uint32_t rv_fsub_s(uint32_t a, uint32_t b, uint32_t frm, uint32_t* fflags);
uint32_t rv_fmul_s(uint32_t a, uint32_t b, uint32_t frm, uint32_t* fflags);
uint32_t rv_fmadd_s(uint32_t a, uint32_t b, uint32_t c, uint32_t frm, uint32_t* fflags);
uint32_t rv_fmsub_s(uint32_t a, uint32_t b, uint32_t c, uint32_t frm, uint32_t* fflags);
uint32_t rv_fnmadd_s(uint32_t a, uint32_t b, uint32_t c, uint32_t frm, uint32_t* fflags);
uint32_t rv_fnmsub_s(uint32_t a, uint32_t b, uint32_t c, uint32_t frm, uint32_t* fflags);
uint32_t rv_fdiv_s(uint32_t a, uint32_t b, uint32_t frm, uint32_t* fflags);
uint32_t rv_fsqrt_s(uint32_t a, uint32_t frm, uint32_t* fflags);
uint32_t rv_frecip7_s(uint32_t a, uint32_t frm, uint32_t* fflags);
uint32_t rv_frsqrt7_s(uint32_t a, uint32_t frm, uint32_t* fflags);

uint32_t rv_ftoi_s(uint32_t a, uint32_t frm, uint32_t* fflags);
uint32_t rv_ftou_s(uint32_t a, uint32_t frm, uint32_t* fflags);
uint32_t rv_itof_s(uint32_t a, uint32_t frm, uint32_t* fflags);
uint32_t rv_utof_s(uint32_t a, uint32_t frm, uint32_t* fflags);

uint64_t rv_ftol_s(uint32_t a, uint32_t frm, uint32_t* fflags);
uint64_t rv_ftolu_s(uint32_t a, uint32_t frm, uint32_t* fflags);
uint32_t rv_ltof_s(uint64_t a, uint32_t frm, uint32_t* fflags);
uint32_t rv_lutof_s(uint64_t a, uint32_t frm, uint32_t* fflags);

uint32_t rv_fclss_s(uint32_t a);

uint32_t rv_fsgnj_s(uint32_t a, uint32_t b);
uint32_t rv_fsgnjn_s(uint32_t a, uint32_t b);
uint32_t rv_fsgnjx_s(uint32_t a, uint32_t b);

bool rv_flt_s(uint32_t a, uint32_t b, uint32_t* fflags);
bool rv_fle_s(uint32_t a, uint32_t b, uint32_t* fflags);
bool rv_feq_s(uint32_t a, uint32_t b, uint32_t* fflags);
uint32_t rv_fmin_s(uint32_t a, uint32_t b, uint32_t* fflags);
uint32_t rv_fmax_s(uint32_t a, uint32_t b, uint32_t* fflags);

///////////////////////////////////////////////////////////////////////////////

uint64_t rv_fadd_d(uint64_t a, uint64_t b, uint32_t frm, uint32_t* fflags);
uint64_t rv_fsub_d(uint64_t a, uint64_t b, uint32_t frm, uint32_t* fflags);
uint64_t rv_fmul_d(uint64_t a, uint64_t b, uint32_t frm, uint32_t* fflags);
uint64_t rv_fdiv_d(uint64_t a, uint64_t b, uint32_t frm, uint32_t* fflags);
uint64_t rv_fsqrt_d(uint64_t a, uint32_t frm, uint32_t* fflags);
uint64_t rv_frecip7_d(uint64_t a, uint32_t frm, uint32_t* fflags);
uint64_t rv_frsqrt7_d(uint64_t a, uint32_t frm, uint32_t* fflags);

uint64_t rv_fmadd_d(uint64_t a, uint64_t b, uint64_t c, uint32_t frm, uint32_t* fflags);
uint64_t rv_fmsub_d(uint64_t a, uint64_t b, uint64_t c, uint32_t frm, uint32_t* fflags);
uint64_t rv_fnmadd_d(uint64_t a, uint64_t b, uint64_t c, uint32_t frm, uint32_t* fflags);
uint64_t rv_fnmsub_d(uint64_t a, uint64_t b, uint64_t c, uint32_t frm, uint32_t* fflags);

uint32_t rv_ftoi_d(uint64_t a, uint32_t frm, uint32_t* fflags);
uint32_t rv_ftou_d(uint64_t a, uint32_t frm, uint32_t* fflags);
uint64_t rv_ftol_d(uint64_t a, uint32_t frm, uint32_t* fflags);
uint64_t rv_ftolu_d(uint64_t a, uint32_t frm, uint32_t* fflags);
uint64_t rv_itof_d(uint32_t a, uint32_t frm, uint32_t* fflags);
uint64_t rv_utof_d(uint32_t a, uint32_t frm, uint32_t* fflags);
uint64_t rv_ltof_d(uint64_t a, uint32_t frm, uint32_t* fflags);
uint64_t rv_lutof_d(uint64_t a, uint32_t frm, uint32_t* fflags);

uint32_t rv_fclss_d(uint64_t a);
uint64_t rv_fsgnj_d(uint64_t a, uint64_t b);
uint64_t rv_fsgnjn_d(uint64_t a, uint64_t b);
uint64_t rv_fsgnjx_d(uint64_t a, uint64_t b);

bool rv_flt_d(uint64_t a, uint64_t b, uint32_t* fflags);
bool rv_fle_d(uint64_t a, uint64_t b, uint32_t* fflags);
bool rv_feq_d(uint64_t a, uint64_t b, uint32_t* fflags);
uint64_t rv_fmin_d(uint64_t a, uint64_t b, uint32_t* fflags);
uint64_t rv_fmax_d(uint64_t a, uint64_t b, uint32_t* fflags);

uint32_t rv_dtof(uint64_t a);
uint32_t rv_dtof_r(uint64_t a, uint32_t frm);
uint64_t rv_ftod(uint32_t a);

#ifdef __cplusplus
}
#endif
// --- End of content from sim/common/rvfloats.h ---

// --- Start of content from sim/simx/local_mem.h ---
// Original pragma: #pragma once
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


#include <simobject.h>
// MERGED_LOCALLY: #include "types.h"

namespace vortex {

class LocalMem : public SimObject<LocalMem> {
public:
  struct Config {
    uint32_t capacity;
    uint32_t line_size;
    uint32_t num_reqs;
    uint32_t B; // log2 number of banks
    bool write_reponse;
  };

  struct PerfStats {
    uint64_t reads;
    uint64_t writes;
    uint64_t bank_stalls;

    PerfStats()
      : reads(0)
      , writes(0)
      , bank_stalls(0)
    {}

    PerfStats& operator+=(const PerfStats& rhs) {
      this->reads += rhs.reads;
      this->writes += rhs.writes;
      this->bank_stalls += rhs.bank_stalls;
      return *this;
    }
  };

  std::vector<SimPort<MemReq>> Inputs;
  std::vector<SimPort<MemRsp>> Outputs;

  LocalMem(const SimContext& ctx, const char* name, const Config& config);
  virtual ~LocalMem();

  void reset();

  void read(void* data, uint64_t addr, uint32_t size);

  void write(const void* data, uint64_t addr, uint32_t size);

  void tick();

  const PerfStats& perf_stats() const;

protected:

  class Impl;
  Impl* impl_;
};

}
// --- End of content from sim/simx/local_mem.h ---

// --- Start of content from sim/simx/mem_sim.h ---
// Original pragma: #pragma once
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


#include <simobject.h>
// MERGED_LOCALLY: #include "types.h"

namespace vortex {

class MemSim : public SimObject<MemSim>{
public:
	struct Config {
		uint32_t num_banks;
		uint32_t num_ports;
		uint32_t block_size;
		float clock_ratio;
	};

	struct PerfStats {
		uint64_t bank_stalls;

		PerfStats()
			: bank_stalls(0)
		{}

		PerfStats& operator+=(const PerfStats& rhs) {
			this->bank_stalls += rhs.bank_stalls;
			return *this;
		}
	};

	std::vector<SimPort<MemReq>> MemReqPorts;
	std::vector<SimPort<MemRsp>> MemRspPorts;

	MemSim(const SimContext& ctx, const char* name, const Config& config);
	~MemSim();

	void reset();

	void tick();

	const PerfStats& perf_stats() const;

private:
	class Impl;
	Impl* impl_;
};

};
// --- End of content from sim/simx/mem_sim.h ---

// --- Start of content from sim/simx/arch.h ---
// Original pragma: #pragma once
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


#include <string>
#include <sstream>

#include <cstdlib>
#include <stdio.h>
// MERGED_LOCALLY: #include "types.h"

namespace vortex {

class Arch {
private:
  uint16_t num_threads_;
  uint16_t num_warps_;
  uint16_t num_cores_;
  uint16_t num_clusters_;
  uint16_t socket_size_;
  uint16_t num_barriers_;
  uint64_t local_mem_base_;

public:
  Arch(uint16_t num_threads, uint16_t num_warps, uint16_t num_cores)   
    : num_threads_(num_threads)
    , num_warps_(num_warps)
    , num_cores_(num_cores)
    , num_clusters_(NUM_CLUSTERS)
    , socket_size_(SOCKET_SIZE)
    , num_barriers_(NUM_BARRIERS)
    , local_mem_base_(LMEM_BASE_ADDR)
  {}

  uint16_t num_barriers() const {
    return num_barriers_;
  }

  uint64_t local_mem_base() const {
    return local_mem_base_;
  }

  uint16_t num_threads() const {
    return num_threads_;
  }

  uint16_t num_warps() const {
    return num_warps_;
  }

  uint16_t num_cores() const {
    return num_cores_;
  }

  uint16_t num_clusters() const {
    return num_clusters_;
  }

  uint16_t socket_size() const {
    return socket_size_;
  }

};

}
// --- End of content from sim/simx/arch.h ---

// --- Start of content from sim/simx/types.h ---
// Original pragma: #pragma once
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


#include <stdint.h>
#include <bitset>
#include <queue>
#include <vector>
#include <unordered_map>
#include <util.h>
#include <stringutil.h>
#include <VX_config.h>
#include <VX_types.h>
#include <simobject.h>
#include <bitvector.h>
// MERGED_LOCALLY: #include "debug.h"
#include <iostream>

namespace vortex {

typedef uint8_t Byte;
#if (XLEN == 32)
typedef uint32_t Word;
typedef int32_t  WordI;
typedef uint64_t DWord;
typedef int64_t  DWordI;
typedef uint32_t WordF;
#elif (XLEN == 64)
typedef uint64_t Word;
typedef int64_t  WordI;
typedef __uint128_t DWord;
typedef __int128_t DWordI;
typedef uint64_t WordF;
#else
#error unsupported XLEN
#endif

#define MAX_NUM_CORES   1024
#define MAX_NUM_THREADS 32
#define MAX_NUM_WARPS   32
#define MAX_NUM_REGS    32
#define NUM_SRC_REGS    3

typedef std::bitset<MAX_NUM_CORES>   CoreMask;
typedef std::bitset<MAX_NUM_REGS>    RegMask;
typedef std::bitset<MAX_NUM_THREADS> ThreadMask;
typedef std::bitset<MAX_NUM_WARPS>   WarpMask;

///////////////////////////////////////////////////////////////////////////////

class ThreadMaskOS {
public:
  ThreadMaskOS(const ThreadMask& mask, int size)
    : mask_(mask)
    , size_(size)
  {}

  friend std::ostream& operator<<(std::ostream& os, const ThreadMaskOS& wrapper) {
    for (int i = 0; i < wrapper.size_; ++i) {
      os << wrapper.mask_[i];
    }
    return os;
  }

private:
  const ThreadMask& mask_;
  int size_;
};

///////////////////////////////////////////////////////////////////////////////

enum class RegType {
  None,
  Integer,
  Float,
  Count,
  Vector
};

inline std::ostream &operator<<(std::ostream &os, const RegType& type) {
  switch (type) {
  case RegType::None: break;
  case RegType::Integer: os << "x"; break;
  case RegType::Float:   os << "f"; break;
  case RegType::Vector:  os << "v"; break;
  default: assert(false);
  }
  return os;
}

///////////////////////////////////////////////////////////////////////////////

enum class FUType {
  ALU,
  LSU,
  FPU,
  SFU,
  TCU,
  Count
};

inline std::ostream &operator<<(std::ostream &os, const FUType& type) {
  switch (type) {
  case FUType::ALU: os << "ALU"; break;
  case FUType::LSU: os << "LSU"; break;
  case FUType::FPU: os << "FPU"; break;
  case FUType::SFU: os << "SFU"; break;
  case FUType::TCU: os << "TCU"; break;
  default: assert(false);
  }
  return os;
}

///////////////////////////////////////////////////////////////////////////////

enum class AluType {
  ARITH,
  BRANCH,
  SYSCALL,
  IMUL,
  IDIV
};

inline std::ostream &operator<<(std::ostream &os, const AluType& type) {
  switch (type) {
  case AluType::ARITH:   os << "ARITH"; break;
  case AluType::BRANCH:  os << "BRANCH"; break;
  case AluType::SYSCALL: os << "SYSCALL"; break;
  case AluType::IMUL:    os << "IMUL"; break;
  case AluType::IDIV:    os << "IDIV"; break;
  default: assert(false);
  }
  return os;
}

///////////////////////////////////////////////////////////////////////////////

enum class LsuType {
  LOAD,
  TCU_LOAD,
  STORE,
  TCU_STORE,
  FENCE
};

enum class TCUType {
  TCU_MUL
};

inline std::ostream &operator<<(std::ostream &os, const TCUType& type) {
  switch (type) {
  case TCUType::TCU_MUL: os << "TCU MUL"; break;
  default: assert(false);
  }
  return os;
}

inline std::ostream &operator<<(std::ostream &os, const LsuType& type) {
  switch (type) {
  case LsuType::LOAD:  os << "LOAD"; break;
  case LsuType::TCU_LOAD: os << "TCU_LOAD"; break;
  case LsuType::STORE: os << "STORE"; break;
  case LsuType::TCU_STORE: os << "TCU_STORE"; break;
  case LsuType::FENCE: os << "FENCE"; break;
  default: assert(false);
  }
  return os;
}

///////////////////////////////////////////////////////////////////////////////

enum class AddrType {
  Global,
  Shared,
  IO
};

inline AddrType get_addr_type(uint64_t addr) {
  if (addr >= IO_BASE_ADDR && addr < IO_END_ADDR) {
     return AddrType::IO;
  }
  if (LMEM_ENABLED) {
    if (addr >= LMEM_BASE_ADDR && (addr-LMEM_BASE_ADDR) < (1 << LMEM_LOG_SIZE)) {
        return AddrType::Shared;
    }
  }
  return AddrType::Global;
}

inline std::ostream &operator<<(std::ostream &os, const AddrType& type) {
  switch (type) {
  case AddrType::Global: os << "Global"; break;
  case AddrType::Shared: os << "Shared"; break;
  case AddrType::IO:     os << "IO"; break;
  default: assert(false);
  }
  return os;
}

///////////////////////////////////////////////////////////////////////////////

struct mem_addr_size_t {
  uint64_t addr;
  uint32_t size;
};

///////////////////////////////////////////////////////////////////////////////

enum class FpuType {
  FNCP,
  FMA,
  FDIV,
  FSQRT,
  FCVT
};

inline std::ostream &operator<<(std::ostream &os, const FpuType& type) {
  switch (type) {
  case FpuType::FNCP:  os << "FNCP"; break;
  case FpuType::FMA:   os << "FMA"; break;
  case FpuType::FDIV:  os << "FDIV"; break;
  case FpuType::FSQRT: os << "FSQRT"; break;
  case FpuType::FCVT:  os << "FCVT"; break;
  default: assert(false);
  }
  return os;
}

///////////////////////////////////////////////////////////////////////////////

enum class SfuType {
  TMC,
  WSPAWN,
  SPLIT,
  JOIN,
  BAR,
  PRED,
  CSRRW,
  CSRRS,
  CSRRC
};

inline std::ostream &operator<<(std::ostream &os, const SfuType& type) {
  switch (type) {
  case SfuType::TMC:    os << "TMC"; break;
  case SfuType::WSPAWN: os << "WSPAWN"; break;
  case SfuType::SPLIT:  os << "SPLIT"; break;
  case SfuType::JOIN:   os << "JOIN"; break;
  case SfuType::BAR:    os << "BAR"; break;
  case SfuType::PRED:   os << "PRED"; break;
  case SfuType::CSRRW:  os << "CSRRW"; break;
  case SfuType::CSRRS:  os << "CSRRS"; break;
  case SfuType::CSRRC:  os << "CSRRC"; break;
  default: assert(false);
  }
  return os;
}

///////////////////////////////////////////////////////////////////////////////

enum class ArbiterType {
  Priority,
  RoundRobin
};

inline std::ostream &operator<<(std::ostream &os, const ArbiterType& type) {
  switch (type) {
  case ArbiterType::Priority:   os << "Priority"; break;
  case ArbiterType::RoundRobin: os << "RoundRobin"; break;
  default: assert(false);
  }
  return os;
}///////////////////////////////////////////////////////////////////////////////

struct LsuReq {
  BitVector<> mask;
  std::vector<uint64_t> addrs;
  bool     write;
  uint32_t tag;
  uint32_t cid;
  uint64_t uuid;

  LsuReq(uint32_t size)
    : mask(size)
    , addrs(size, 0)
    , write(false)
    , tag(0)
    , cid(0)
    , uuid(0)
  {}
};

inline std::ostream &operator<<(std::ostream &os, const LsuReq& req) {
  os << "rw=" << req.write << ", mask=" << req.mask << ", addr={";
  bool first_addr = true;
  for (size_t i = 0; i < req.mask.size(); ++i) {
    if (!first_addr) os << ", ";
    first_addr = false;
    if (req.mask.test(i)) {
      os << "0x" << std::hex << req.addrs.at(i) << std::dec;
    } else {
      os << "-";
    }
  }
  os << "}, tag=0x" << std::hex << req.tag << std::dec << ", cid=" << req.cid;
  os << " (#" << req.uuid << ")";
  return os;
}

///////////////////////////////////////////////////////////////////////////////

struct LsuRsp {
  BitVector<> mask;
  uint64_t tag;
  uint32_t cid;
  uint64_t uuid;

 LsuRsp(uint32_t size)
    : mask(size)
    , tag (0)
    , cid(0)
    , uuid(0)
  {}
};

inline std::ostream &operator<<(std::ostream &os, const LsuRsp& rsp) {
  os << "mask=" << rsp.mask << ", tag=0x" << std::hex << rsp.tag << std::dec << ", cid=" << rsp.cid;
  os << " (#" << rsp.uuid << ")";
  return os;
}

///////////////////////////////////////////////////////////////////////////////

struct MemReq {
  uint64_t addr;
  bool     write;
  AddrType type;
  uint32_t tag;
  uint32_t cid;
  uint64_t uuid;

  MemReq(uint64_t _addr = 0,
          bool _write = false,
          AddrType _type = AddrType::Global,
          uint64_t _tag = 0,
          uint32_t _cid = 0,
          uint64_t _uuid = 0
  ) : addr(_addr)
    , write(_write)
    , type(_type)
    , tag(_tag)
    , cid(_cid)
    , uuid(_uuid)
  {}
};

inline std::ostream &operator<<(std::ostream &os, const MemReq& req) {
  os << "rw=" << req.write << ", ";
  os << "addr=0x" << std::hex << req.addr << std::dec << ", type=" << req.type;
  os << ", tag=0x" << std::hex << req.tag << std::dec << ", cid=" << req.cid;
  os << " (#" << req.uuid << ")";
  return os;
}

///////////////////////////////////////////////////////////////////////////////

struct MemRsp {
  uint64_t tag;
  uint32_t cid;
  uint64_t uuid;

  MemRsp(uint64_t _tag = 0, uint32_t _cid = 0, uint64_t _uuid = 0)
    : tag (_tag)
    , cid(_cid)
    , uuid(_uuid)
  {}
};

inline std::ostream &operator<<(std::ostream &os, const MemRsp& rsp) {
  os << "tag=0x" << std::hex << rsp.tag << std::dec << ", cid=" << rsp.cid;
  os << " (#" << rsp.uuid << ")";
  return os;
}

///////////////////////////////////////////////////////////////////////////////

template <typename T>
class HashTable {
public:
  typedef T DataType;

  HashTable(uint32_t capacity)
    : entries_(capacity)
    , size_(0)
  {}

  bool empty() const {
    return (0 == size_);
  }

  bool full() const {
    return (size_ == entries_.size());
  }

  uint32_t size() const {
    return size_;
  }

  bool contains(uint32_t index) const {
    return entries_.at(index).first;
  }

  const T& at(uint32_t index) const {
    auto& entry = entries_.at(index);
    assert(entry.first);
    return entry.second;
  }

  T& at(uint32_t index) {
    auto& entry = entries_.at(index);
    assert(entry.first);
    return entry.second;
  }

  uint32_t allocate(const T& value) {
    for (uint32_t i = 0, n = entries_.size(); i < n; ++i) {
      auto& entry = entries_.at(i);
      if (!entry.first) {
        entry.first = true;
        entry.second = value;
        ++size_;
        return i;
      }
    }
    assert(false);
    return -1;
  }

  void release(uint32_t index) {
    auto& entry = entries_.at(index);
    assert(entry.first);
    entry.first = false;
    --size_;
  }

  void clear() {
    for (uint32_t i = 0, n = entries_.size(); i < n; ++i) {
      auto& entry = entries_.at(i);
      entry.first = false;
    }
    size_ = 0;
  }

private:
  std::vector<std::pair<bool, T>> entries_;
  uint32_t size_;
};

///////////////////////////////////////////////////////////////////////////////

template <typename Type>
class Arbiter : public SimObject<Arbiter<Type>> {
public:
  typedef Type ReqType;

  std::vector<SimPort<Type>> Inputs;
  std::vector<SimPort<Type>> Outputs;

  Arbiter(
    const SimContext& ctx,
    const char* name,
    ArbiterType type,
    uint32_t num_inputs,
    uint32_t num_outputs = 1,
    uint32_t delay = 1
  ) : SimObject<Arbiter<Type>>(ctx, name)
    , Inputs(num_inputs, this)
    , Outputs(num_outputs, this)
    , type_(type)
    , delay_(delay)
    , grants_(num_outputs, 0)
    , lg2_num_reqs_(log2ceil(num_inputs / num_outputs))
  {
    assert(delay != 0);
    assert(num_inputs <= 64);
    assert(num_outputs <= 64);
    assert(num_inputs >= num_outputs);

    // bypass mode
    if (num_inputs == num_outputs) {
      for (uint32_t i = 0; i < num_inputs; ++i) {
        Inputs.at(i).bind(&Outputs.at(i));
      }
    }
  }

  void reset() {
    for (auto& grant : grants_) {
      grant = 0;
    }
  }

  void tick() {
    uint32_t I = Inputs.size();
    uint32_t O = Outputs.size();
    uint32_t R = 1 << lg2_num_reqs_;

    // skip bypass mode
    if (I == O)
      return;

    // process inputs
    for (uint32_t o = 0; o < O; ++o) {
      for (uint32_t r = 0; r < R; ++r) {
        uint32_t g = (grants_.at(o) + r) & (R-1);
        uint32_t j = o * R + g;
        if (j >= I)
          continue;

        auto& req_in = Inputs.at(j);
        if (!req_in.empty()) {
          auto& req = req_in.front();
          DT(4, this->name() << "-req" << o << ": " << req);
          Outputs.at(o).push(req, delay_);
          req_in.pop();
          this->update_grant(o, g);
          break;
        }
      }
    }
  }

protected:

  void update_grant(uint32_t index, uint32_t grant) {
    if (type_ == ArbiterType::RoundRobin) {
      grants_.at(index) = grant + 1;
    }
  }

  ArbiterType type_;
  uint32_t delay_;
  std::vector<uint32_t> grants_;
  uint32_t lg2_num_reqs_;
};

///////////////////////////////////////////////////////////////////////////////

template <typename Type>
class CrossBar : public SimObject<CrossBar<Type>> {
public:
  typedef Type ReqType;

  std::vector<SimPort<Type>> Inputs;
  std::vector<SimPort<Type>> Outputs;

  CrossBar(
    const SimContext& ctx,
    const char* name,
    ArbiterType type,
    uint32_t num_inputs,
    uint32_t num_outputs = 1,
    uint32_t delay = 1,
    std::function<uint32_t(const Type& req)> output_sel = nullptr
  )
    : SimObject<CrossBar<Type>>(ctx, name)
    , Inputs(num_inputs, this)
    , Outputs(num_outputs, this)
    , type_(type)
    , delay_(delay)
    , grants_(num_outputs, 0)
    , lg2_inputs_(log2ceil(num_inputs))
    , lg2_outputs_(log2ceil(num_outputs))
    , collisions_(0) {
    assert(delay != 0);
    assert(num_inputs <= 64);
    assert(num_outputs <= 64);
    assert(ispow2(num_outputs));
    if (output_sel != nullptr) {
      output_sel_ = output_sel;
    } else {
      output_sel_ = [this](const Type& req) {
        return (uint32_t)bit_getw(req.addr, 0, (lg2_outputs_-1));
      };
    }
  }

  void reset() {
    for (auto& grant : grants_) {
      grant = 0;
    }
  }

  void tick() {
    uint32_t I = Inputs.size();
    uint32_t O = Outputs.size();
    uint32_t R = 1 << lg2_inputs_;

    // process incoming requests
    for (uint32_t o = 0; o < O; ++o) {
      int32_t input_idx = -1;
      bool has_collision = false;
      for (uint32_t r = 0; r < R; ++r) {
        uint32_t i = (grants_.at(o) + r) & (R-1);
        if (i >= I)
          continue;
        auto& req_in = Inputs.at(i);
        if (req_in.empty())
          continue;
        auto& req = req_in.front();
        uint32_t output_idx = 0;
        if (lg2_outputs_ != 0) {
          // select output index
          output_idx = output_sel_(req);
          // skip if input is not going to current output
          if (output_idx != o)
            continue;
        }
        if (input_idx != -1) {
          has_collision = true;
          continue;
        }
        input_idx = i;
      }
      if (input_idx != -1) {
        auto& req_in = Inputs.at(input_idx);
        auto& req = req_in.front();
        DT(4, this->name() << "-req" << o << ": " << req);
        Outputs.at(o).push(req, delay_);
        req_in.pop();
        this->update_grant(o, input_idx);
        collisions_ += has_collision;
      }
    }
  }

  uint64_t collisions() const {
    return collisions_;
  }

protected:

  void update_grant(uint32_t index, uint32_t grant) {
    if (type_ == ArbiterType::RoundRobin) {
      grants_.at(index) = grant + 1;
    }
  }

  ArbiterType type_;
  uint32_t delay_;
  std::vector<uint32_t> grants_;
  uint32_t lg2_inputs_;
  uint32_t lg2_outputs_;
  std::function<uint32_t(const Type& req)> output_sel_;
  uint64_t collisions_;
};

///////////////////////////////////////////////////////////////////////////////

template <typename Req, typename Rsp>
class TxArbiter : public SimObject<TxArbiter<Req, Rsp>> {
public:
  typedef Req ReqType;
  typedef Rsp RspType;

  std::vector<SimPort<Req>>  ReqIn;
  std::vector<SimPort<Rsp>>  RspIn;

  std::vector<SimPort<Req>>  ReqOut;
  std::vector<SimPort<Rsp>>  RspOut;

  TxArbiter(
    const SimContext& ctx,
    const char* name,
    ArbiterType type,
    uint32_t num_inputs,
    uint32_t num_outputs = 1,
    uint32_t delay = 1
  )
    : SimObject<TxArbiter<Req, Rsp>>(ctx, name)
    , ReqIn(num_inputs, this)
    , RspIn(num_inputs, this)
    , ReqOut(num_outputs, this)
    , RspOut(num_outputs, this)
    , type_(type)
    , delay_(delay)
    , grants_(num_outputs, 0)
    , lg2_num_reqs_(log2ceil(num_inputs / num_outputs))
  {
    assert(delay != 0);
    assert(num_inputs <= 64);
    assert(num_outputs <= 64);
    assert(num_inputs >= num_outputs);

    // bypass mode
    if (num_inputs == num_outputs) {
      for (uint32_t i = 0; i < num_inputs; ++i) {
        ReqIn.at(i).bind(&ReqOut.at(i));
        RspOut.at(i).bind(&RspIn.at(i));
      }
    }
  }

  void reset() {
    for (auto& grant : grants_) {
      grant = 0;
    }
  }

  void tick() {
    uint32_t I = ReqIn.size();
    uint32_t O = ReqOut.size();
    uint32_t R = 1 << lg2_num_reqs_;

    // skip bypass mode
    if (I == O)
      return;

    // process outgoing responses
    for (uint32_t o = 0; o < O; ++o) {
      auto& rsp_out = RspOut.at(o);
      if (!rsp_out.empty()) {
        auto& rsp = rsp_out.front();
        uint32_t g = 0;
        if (lg2_num_reqs_ != 0) {
          g = rsp.tag & (R-1);
          rsp.tag >>= lg2_num_reqs_;
        }
        uint32_t j = o * R + g;
        DT(4, this->name() << "-rsp" << j << ": " << rsp);
        RspIn.at(j).push(rsp, 1);
        rsp_out.pop();
      }
    }

    // process incoming requests
    for (uint32_t o = 0; o < O; ++o) {
      for (uint32_t r = 0; r < R; ++r) {
        uint32_t g = (grants_.at(o) + r) & (R-1);
        uint32_t j = o * R + g;
        if (j >= I)
          continue;

        auto& req_in = ReqIn.at(j);
        if (!req_in.empty()) {
          auto& req = req_in.front();
          if (lg2_num_reqs_ != 0) {
            req.tag = (req.tag << lg2_num_reqs_) | g;
          }
          DT(4, this->name() << "-req" << o << ": " << req);
          ReqOut.at(o).push(req, delay_);
          req_in.pop();
          this->update_grant(o, g);
          break;
        }
      }
    }
  }

protected:

  void update_grant(uint32_t index, uint32_t grant) {
    if (type_ == ArbiterType::RoundRobin) {
      grants_.at(index) = grant + 1;
    }
  }

  ArbiterType type_;
  uint32_t delay_;
  std::vector<uint32_t> grants_;
  uint32_t lg2_num_reqs_;
};

///////////////////////////////////////////////////////////////////////////////

template <typename Req, typename Rsp>
class TxCrossBar : public SimObject<TxCrossBar<Req, Rsp>> {
public:
  typedef Req ReqType;
  typedef Rsp RspType;

  std::vector<SimPort<Req>> ReqIn;
  std::vector<SimPort<Rsp>> RspIn;

  std::vector<SimPort<Req>> ReqOut;
  std::vector<SimPort<Rsp>> RspOut;

  TxCrossBar(
    const SimContext& ctx,
    const char* name,
    ArbiterType type,
    uint32_t num_inputs,
    uint32_t num_outputs = 1,
    uint32_t delay = 1,
    std::function<uint32_t(const Req& req)> output_sel = nullptr
  )
    : SimObject<TxCrossBar<Req, Rsp>>(ctx, name)
    , ReqIn(num_inputs, this)
    , RspIn(num_inputs, this)
    , ReqOut(num_outputs, this)
    , RspOut(num_outputs, this)
    , type_(type)
    , delay_(delay)
    , req_grants_(num_outputs, 0)
    , rsp_grants_(num_inputs, 0)
    , lg2_inputs_(log2ceil(num_inputs))
    , lg2_outputs_(log2ceil(num_outputs))
    , req_collisions_(0)
    , rsp_collisions_(0) {
    assert(delay != 0);
    assert(num_inputs <= 64);
    assert(num_outputs <= 64);
    assert(ispow2(num_inputs));
    assert(ispow2(num_outputs));
    if (output_sel != nullptr) {
      output_sel_ = output_sel;
    } else {
      output_sel_ = [this](const Req& req) {
        return (uint32_t)bit_getw(req.addr, 0, (lg2_outputs_-1));
      };
    }
  }

  void reset() {
    for (auto& grant : req_grants_) {
      grant = 0;
    }
    for (auto& grant : rsp_grants_) {
      grant = 0;
    }
  }

  void tick() {
    uint32_t I = ReqIn.size();
    uint32_t O = ReqOut.size();
    uint32_t R = 1 << lg2_inputs_;
    uint32_t T = 1 << lg2_outputs_;

    // process outgoing responses
    for (uint32_t i = 0; i < I; ++i) {
      int32_t output_idx = -1;
      bool has_collision = false;
      for (uint32_t t = 0; t < T; ++t) {
        uint32_t o = (rsp_grants_.at(i) + t) & (T-1);
        if (o >= O)
          continue;
        auto& rsp_out = RspOut.at(o);
        if (rsp_out.empty())
          continue;
        auto& rsp = rsp_out.front();
        uint32_t input_idx = 0;
        if (lg2_inputs_ != 0) {
          input_idx = rsp.tag & (R-1);
          // skip if response is not going to current input
          if (input_idx != i)
            continue;
        }
        if (output_idx != -1) {
          has_collision = true;
          continue;
        }
        output_idx = o;
      }
      if (output_idx != -1) {
        auto& rsp_out = RspOut.at(output_idx);
        auto& rsp = rsp_out.front();
        if (lg2_inputs_ != 0) {
          rsp.tag >>= lg2_inputs_;
        }
        DT(4, this->name() << "-rsp" << i << ": " << rsp);
        RspIn.at(i).push(rsp, 1);
        rsp_out.pop();
        this->update_rsp_grant(i, output_idx);
        rsp_collisions_ += has_collision;
      }
    }

    // process incoming requests
    for (uint32_t o = 0; o < O; ++o) {
      int32_t input_idx = -1;
      bool has_collision = false;
      for (uint32_t r = 0; r < R; ++r) {
        uint32_t i = (req_grants_.at(o) + r) & (R-1);
        if (i >= I)
          continue;
        auto& req_in = ReqIn.at(i);
        if (req_in.empty())
          continue;
        auto& req = req_in.front();
        uint32_t output_idx = 0;
        if (lg2_outputs_ != 0) {
          // select output index
          output_idx = output_sel_(req);
          // skip if request is not going to current output
          if (output_idx != o)
            continue;
        }
        if (input_idx != -1) {
          has_collision = true;
          continue;
        }
        input_idx = i;
      }
      if (input_idx != -1) {
        auto& req_in = ReqIn.at(input_idx);
        auto& req = req_in.front();
        if (lg2_inputs_ != 0) {
          req.tag = (req.tag << lg2_inputs_) | input_idx;
        }
        DT(4, this->name() << "-req" << o << ": " << req);
        ReqOut.at(o).push(req, delay_);
        req_in.pop();
        this->update_req_grant(o, input_idx);
        req_collisions_ += has_collision;
      }
    }
  }

  uint64_t req_collisions() const {
    return req_collisions_;
  }

  uint64_t rsp_collisions() const {
    return rsp_collisions_;
  }

protected:

  void update_req_grant(uint32_t index, uint32_t grant) {
    if (type_ == ArbiterType::RoundRobin) {
      req_grants_.at(index) = grant + 1;
    }
  }

  void update_rsp_grant(uint32_t index, uint32_t grant) {
    if (type_ == ArbiterType::RoundRobin) {
      rsp_grants_.at(index) = grant + 1;
    }
  }

  ArbiterType type_;
  uint32_t delay_;
  std::vector<uint32_t> req_grants_;
  std::vector<uint32_t> rsp_grants_;
  uint32_t lg2_inputs_;
  uint32_t lg2_outputs_;
  std::function<uint32_t(const Req& req)> output_sel_;
  uint64_t req_collisions_;
  uint64_t rsp_collisions_;
};

///////////////////////////////////////////////////////////////////////////////

class LocalMemSwitch : public SimObject<LocalMemSwitch> {
public:
  SimPort<LsuReq> ReqIn;
  SimPort<LsuRsp> RspIn;

  SimPort<LsuReq> ReqLmem;
  SimPort<LsuRsp> RspLmem;

  SimPort<LsuReq> ReqDC;
  SimPort<LsuRsp> RspDC;

  LocalMemSwitch(
    const SimContext& ctx,
    const char* name,
    uint32_t delay
  );

  void reset();

  void tick();

private:
  uint32_t delay_;
};

///////////////////////////////////////////////////////////////////////////////

class LsuMemAdapter : public SimObject<LsuMemAdapter> {
public:
  SimPort<LsuReq> ReqIn;
  SimPort<LsuRsp> RspIn;

  std::vector<SimPort<MemReq>> ReqOut;
  std::vector<SimPort<MemRsp>> RspOut;

  LsuMemAdapter(
    const SimContext& ctx,
    const char* name,
    uint32_t num_inputs,
    uint32_t delay
  );

  void reset();

  void tick();

private:
  uint32_t delay_;
};

using LsuArbiter  = TxArbiter<LsuReq, LsuRsp>;
using MemArbiter  = TxArbiter<MemReq, MemRsp>;
using MemCrossBar = TxCrossBar<MemReq, MemRsp>;

}
// --- End of content from sim/simx/types.h ---

// --- Start of content from sim/simx/dispatcher.h ---
// Original pragma: #pragma once
// Copyright © 2019-2023
// 
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
// 
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


// MERGED_LOCALLY: #include "instr_trace.h"
#include <queue>
#include <vector>

namespace vortex {

class Dispatcher : public SimObject<Dispatcher> {
public:
	std::vector<SimPort<instr_trace_t*>> Outputs;

	Dispatcher(const SimContext& ctx, const Arch& arch, uint32_t buf_size, uint32_t block_size, uint32_t num_lanes) 
		: SimObject<Dispatcher>(ctx, "Dispatcher") 
		, Outputs(ISSUE_WIDTH, this)
		, Inputs_(ISSUE_WIDTH, this)
		, arch_(arch)
		, queues_(ISSUE_WIDTH, std::queue<instr_trace_t*>())
		, buf_size_(buf_size)
		, block_size_(block_size)
		, num_lanes_(num_lanes)
		, batch_count_(ISSUE_WIDTH / block_size)
		, pid_count_(arch.num_threads() / num_lanes)
		, batch_idx_(0)
		, start_p_(block_size, 0)
	{}
	
	virtual ~Dispatcher() {}

	virtual void reset() {
		batch_idx_ = 0;
		for (uint32_t b = 0; b < block_size_; ++b) {
			start_p_.at(b) = 0;
		}
	}

	virtual void tick() {
		for (uint32_t i = 0; i < ISSUE_WIDTH; ++i) {
			auto& queue = queues_.at(i);
			if (queue.empty())
				continue;
			auto trace = queue.front();
			Inputs_.at(i).push(trace, 1);
			queue.pop();
		}

		uint32_t block_sent = 0;
		for (uint32_t b = 0; b < block_size_; ++b) {
			uint32_t i = batch_idx_ * block_size_ + b;
			auto& input = Inputs_.at(i);
			if (input.empty()) {
				++block_sent;
				continue;
			}
			auto& output = Outputs.at(i);
			auto trace = input.front();
			auto new_trace = trace;
			if (pid_count_ != 1) {
				auto start_p = start_p_.at(b);
				if (start_p == -1) {
					++block_sent;
					continue; 
				} 
				int start(-1), end(-1);
				for (uint32_t j = start_p * num_lanes_, n = arch_.num_threads(); j < n; ++j) {
					if (!trace->tmask.test(j))
						continue;
					if (start == -1)
						start = j;
					end = j;
				}
				start /= num_lanes_;
				end /= num_lanes_;
				if (start != end) {
					new_trace = new instr_trace_t(*trace);
					new_trace->eop = false;
					start_p_.at(b) = start + 1;
				} else {
					start_p_.at(b) = -1;
					input.pop();
					++block_sent;
				}
				new_trace->pid = start;
				new_trace->sop = (0 == start_p);
				ThreadMask tmask;
				for (int j = start * num_lanes_, n = j + num_lanes_; j < n; ++j) {
					tmask[j] = trace->tmask[j];
				}
				new_trace->tmask = tmask;
			} else {
				new_trace->pid = 0;
				input.pop();
				++block_sent;
			}
			DT(3, "pipeline-dispatch: " << *new_trace);
			output.push(new_trace, 1);
		}
		if (block_sent == block_size_) {
			batch_idx_ = (batch_idx_ + 1) % batch_count_;
			for (uint32_t b = 0; b < block_size_; ++b) {
				start_p_.at(b) = 0;
			}
		}
	};

	bool push(uint32_t issue_index, instr_trace_t* trace) {
		auto& queue = queues_.at(issue_index);
		if (queue.size() >= buf_size_)
			return false;
		queue.push(trace);
		return true;
	}

private:
	std::vector<SimPort<instr_trace_t*>> Inputs_;
	const Arch& arch_;
	std::vector<std::queue<instr_trace_t*>> queues_;
	uint32_t buf_size_;
	uint32_t block_size_;
	uint32_t num_lanes_;
	uint32_t batch_count_;
	uint32_t pid_count_;
	uint32_t batch_idx_;
	std::vector<int> start_p_;
};

}
// --- End of content from sim/simx/dispatcher.h ---

// --- Start of content from sim/simx/socket.h ---
// Original pragma: #pragma once
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


#include <simobject.h>
// MERGED_LOCALLY: #include "dcrs.h"
// MERGED_LOCALLY: #include "arch.h"
// MERGED_LOCALLY: #include "cache_cluster.h"
// MERGED_LOCALLY: #include "local_mem.h"
// MERGED_LOCALLY: #include "core.h"
// MERGED_LOCALLY: #include "constants.h"

namespace vortex {

class Cluster;

class Socket : public SimObject<Socket> {
public:
  struct PerfStats {
    CacheSim::PerfStats icache;
    CacheSim::PerfStats dcache;
  };

  std::vector<SimPort<MemReq>> mem_req_ports;
  std::vector<SimPort<MemRsp>> mem_rsp_ports;

  Socket(const SimContext& ctx,
         uint32_t socket_id,
         Cluster* cluster,
         const Arch &arch,
         const DCRS &dcrs);

  ~Socket();

  uint32_t id() const {
    return socket_id_;
  }

  Cluster* cluster() const {
    return cluster_;
  }

  void reset();

  void tick();

  void attach_ram(RAM* ram);

#ifdef VM_ENABLE
  void set_satp(uint64_t satp);
#endif

  bool running() const;

  int get_exitcode() const;

  void barrier(uint32_t bar_id, uint32_t count, uint32_t core_id);

  void resume(uint32_t core_id);

  PerfStats perf_stats() const;

private:
  uint32_t                socket_id_;
  Cluster*                cluster_;
  std::vector<Core::Ptr>  cores_;
  CacheCluster::Ptr       icaches_;
  CacheCluster::Ptr       dcaches_;
};

} // namespace vortex
// --- End of content from sim/simx/socket.h ---

// --- Start of content from sim/simx/func_unit.h ---
// Original pragma: #pragma once
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


#include <simobject.h>
#include <array>
// MERGED_LOCALLY: #include "instr_trace.h"

namespace vortex {

class Core;

class FuncUnit : public SimObject<FuncUnit> {
public:
	std::vector<SimPort<instr_trace_t*>> Inputs;
	std::vector<SimPort<instr_trace_t*>> Outputs;

	FuncUnit(const SimContext& ctx, Core* core, const char* name)
		: SimObject<FuncUnit>(ctx, name)
		, Inputs(ISSUE_WIDTH, this)
		, Outputs(ISSUE_WIDTH, this)
		, core_(core)
	{}

	virtual ~FuncUnit() {}

	virtual void reset() {}

	virtual void tick() = 0;

protected:
	Core* core_;
};

///////////////////////////////////////////////////////////////////////////////

class AluUnit : public FuncUnit {
public:
  AluUnit(const SimContext& ctx, Core*);

  void tick();
};

///////////////////////////////////////////////////////////////////////////////

class FpuUnit : public FuncUnit {
public:
  FpuUnit(const SimContext& ctx, Core*);

  void tick();
};

///////////////////////////////////////////////////////////////////////////////

class LsuUnit : public FuncUnit {
public:
	LsuUnit(const SimContext& ctx, Core*);
	~LsuUnit();

	void reset();
	void tick();

private:

 	struct pending_req_t {
		instr_trace_t* trace;
		BitVector<> mask;
	};

	struct lsu_state_t {
		HashTable<pending_req_t> pending_rd_reqs;
		instr_trace_t* fence_trace;
		bool fence_lock;

		lsu_state_t() : pending_rd_reqs(LSUQ_IN_SIZE) {}

		void clear() {
			this->pending_rd_reqs.clear();
			this->fence_trace = nullptr;
			this->fence_lock = false;
		}
	};

	std::array<lsu_state_t, NUM_LSU_BLOCKS> states_;
	uint64_t pending_loads_;
};

///////////////////////////////////////////////////////////////////////////////

class TcuUnit : public FuncUnit {
public:
    TcuUnit(const SimContext& ctx, Core*);
    void tick();
};

///////////////////////////////////////////////////////////////////////////////

class SfuUnit : public FuncUnit {
public:
	SfuUnit(const SimContext& ctx, Core*);

	void tick();
};

}
// --- End of content from sim/simx/func_unit.h ---

// --- Start of content from sim/simx/scoreboard.h ---
// Original pragma: #pragma once
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


// MERGED_LOCALLY: #include "instr_trace.h"
#include <unordered_map>
#include <vector>

namespace vortex {

class Scoreboard {
public:

	struct reg_use_t {
		RegType  reg_type;
		uint32_t reg_id;
		FUType   fu_type;
		SfuType  sfu_type;
		uint64_t uuid;
	};

	Scoreboard(const Arch &arch)
	: in_use_regs_(arch.num_warps()) {
		for (auto& in_use_reg : in_use_regs_) {
			in_use_reg.resize((int)RegType::Count);
		}
		this->clear();
	}

	void clear() {
		for (auto& in_use_reg : in_use_regs_) {
			for (auto& mask : in_use_reg) {
				mask.reset();
			}
		}
		owners_.clear();
	}

	bool in_use(instr_trace_t* trace) const {
		if (trace->wb) {
			assert(trace->dst_reg.type != RegType::None);
			if (in_use_regs_.at(trace->wid).at((int)trace->dst_reg.type).test(trace->dst_reg.idx)) {
				return true;
			}
		}
		for (uint32_t i = 0; i < trace->src_regs.size(); ++i) {
			if (trace->src_regs[i].type != RegType::None) {
				if (in_use_regs_.at(trace->wid).at((int)trace->src_regs[i].type).test(trace->src_regs[i].idx)) {
					return true;
				}
			}
		}
		return false;
	}

	std::vector<reg_use_t> get_uses(instr_trace_t* trace) const {
		std::vector<reg_use_t> out;
		if (trace->wb) {
			assert(trace->dst_reg.type != RegType::None);
			if (in_use_regs_.at(trace->wid).at((int)trace->dst_reg.type).test(trace->dst_reg.idx)) {
				uint32_t tag = (trace->dst_reg.idx << 16) | (trace->wid << 4) | (int)trace->dst_reg.type;
				auto owner = owners_.at(tag);
				out.push_back({trace->dst_reg.type, trace->dst_reg.idx, owner->fu_type, owner->sfu_type, owner->uuid});
			}
		}
		for (uint32_t i = 0; i < trace->src_regs.size(); ++i) {
			if (trace->src_regs[i].type != RegType::None) {
				if (in_use_regs_.at(trace->wid).at((int)trace->src_regs[i].type).test(trace->src_regs[i].idx)) {
					uint32_t tag = (trace->src_regs[i].idx << 16) | (trace->wid << 4) | (int)trace->src_regs[i].type;
					auto owner = owners_.at(tag);
					out.push_back({trace->src_regs[i].type, trace->src_regs[i].idx, owner->fu_type, owner->sfu_type, owner->uuid});
				}
			}
		}
		return out;
	}

	void reserve(instr_trace_t* trace) {
		assert(trace->wb);
		in_use_regs_.at(trace->wid).at((int)trace->dst_reg.type).set(trace->dst_reg.idx);
		uint32_t tag = (trace->dst_reg.idx << 16) | (trace->wid << 4) | (int)trace->dst_reg.type;
		assert(owners_.count(tag) == 0);
		owners_[tag] = trace;
	}

	void release(instr_trace_t* trace) {
		assert(trace->wb);
		in_use_regs_.at(trace->wid).at((int)trace->dst_reg.type).reset(trace->dst_reg.idx);
		uint32_t tag = (trace->dst_reg.idx << 16) | (trace->wid << 4) | (int)trace->dst_reg.type;
		assert(owners_.count(tag) != 0);
		owners_.erase(tag);
	}

private:

	std::vector<std::vector<RegMask>> in_use_regs_;
	std::unordered_map<uint32_t, instr_trace_t*> owners_;
};

}
// --- End of content from sim/simx/scoreboard.h ---

// --- Start of content from sim/simx/mem_coalescer.h ---
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// MERGED_LOCALLY: #include "types.h"

namespace vortex {

class MemCoalescer : public SimObject<MemCoalescer> {
public:
  SimPort<LsuReq> ReqIn;
  SimPort<LsuRsp> RspIn;

  SimPort<LsuReq> ReqOut;
  SimPort<LsuRsp> RspOut;

  struct PerfStats {
    uint64_t misses;

    PerfStats()
      : misses(0)
    {}

    PerfStats& operator+=(const PerfStats& rhs) {
      this->misses += rhs.misses;
      return *this;
    }
  };

  MemCoalescer(
    const SimContext& ctx,
    const char* name,
    uint32_t input_size,
    uint32_t output_size,
    uint32_t line_size,
    uint32_t queue_size,
    uint32_t delay
  );

  void reset();

  void tick();

  const PerfStats& perf_stats() const;

private:

  struct pending_req_t {
    uint32_t tag;
    BitVector<> mask;
  };

  uint32_t input_size_;
  uint32_t output_size_;
  uint32_t output_ratio_;

  HashTable<pending_req_t> pending_rd_reqs_;
  BitVector<> sent_mask_;
  uint32_t line_size_;
  uint32_t delay_;
  PerfStats perf_stats_;
};

}
// --- End of content from sim/simx/mem_coalescer.h ---

// --- Start of content from sim/simx/vpu.h ---
// Original pragma: #pragma once
#ifdef EXT_V_ENABLE

using namespace vortex;

template <typename T, typename R>
class Add {
public:
  static R apply(T first, T second, R) {
    return (R)first + (R)second;
  }
  static std::string name() { return "Add"; }
};

template <typename T, typename R>
class Sub {
public:
  static R apply(T first, T second, R) {
    return (R)second - (R)first;
  }
  static std::string name() { return "Sub"; }
};

template <typename T, typename R>
class Adc {
public:
  static R apply(T first, T second, R third) {
    return (R)first + (R)second + third;
  }
  static std::string name() { return "Adc"; }
};

template <typename T, typename R>
class Madc {
public:
  static R apply(T first, T second, R third) {
    return ((R)first + (R)second + third) > (R)std::numeric_limits<T>::max();
  }
  static std::string name() { return "Madc"; }
};

template <typename T, typename R>
class Sbc {
public:
  static R apply(T first, T second, R third) {
    return (R)second - (R)first - third;
  }
  static std::string name() { return "Sbc"; }
};

template <typename T, typename R>
class Msbc {
public:
  static R apply(T first, T second, R third) {
    return (R)second < ((R)first + third);
  }
  static std::string name() { return "Msbc"; }
};

template <typename T, typename R>
class Ssub {
public:
  static R apply(T first, T second, uint32_t, uint32_t &vxsat_) {
    // rounding mode is not relevant for this operation
    T unclippedResult = second - first;
    R clippedResult = std::clamp(unclippedResult, (T)std::numeric_limits<R>::min(), (T)std::numeric_limits<R>::max());
    vxsat_ |= clippedResult != unclippedResult;
    return clippedResult;
  }
  static std::string name() { return "Ssub"; }
};

template <typename T, typename R>
class Ssubu {
public:
  static R apply(T first, T second, uint32_t, uint32_t &vxsat_) {
    // rounding mode is not relevant for this operation
    if (first > second) {
      vxsat_ = true;
      return 0;
    } else {
      vxsat_ = false;
      return second - first;
    }
  }
  static std::string name() { return "Ssubu"; }
};

template <typename T, typename R>
class Sadd {
public:
  static R apply(T first, T second, uint32_t, uint32_t &vxsat_) {
    // rounding mode is not relevant for this operation
    T unclippedResult = second + first;
    R clippedResult = std::clamp(unclippedResult, (T)std::numeric_limits<R>::min(), (T)std::numeric_limits<R>::max());
    vxsat_ |= clippedResult != unclippedResult;
    return clippedResult;
  }
  static std::string name() { return "Sadd"; }
};

template <typename T, typename R>
class Rsub {
public:
  static R apply(T first, T second, R) {
    return first - second;
  }
  static std::string name() { return "Rsub"; }
};

template <typename T, typename R>
class Div {
public:
  static R apply(T first, T second, R) {
    // logic taken from scalar div
    if (first == 0) {
      return -1;
    } else if (second == std::numeric_limits<T>::min() && first == T(-1)) {
      return second;
    } else {
      return (R)second / (R)first;
    }
  }
  static std::string name() { return "Div"; }
};

template <typename T, typename R>
class Rem {
public:
  static R apply(T first, T second, R) {
    // logic taken from scalar rem
    if (first == 0) {
      return second;
    } else if (second == std::numeric_limits<T>::min() && first == T(-1)) {
      return 0;
    } else {
      return (R)second % (R)first;
    }
  }
  static std::string name() { return "Rem"; }
};

template <typename T, typename R>
class Mul {
public:
  static R apply(T first, T second, R) {
    return (R)first * (R)second;
  }
  static std::string name() { return "Mul"; }
};

template <typename T, typename R>
class Mulsu {
public:
  static R apply(T first, T second, R) {
    R first_ext = zext((R)first, (sizeof(T) * 8));
    return first_ext * (R)second;
  }
  static std::string name() { return "Mulsu"; }
};

template <typename T, typename R>
class Mulh {
public:
  static R apply(T first, T second, R) {
    __int128_t first_ext = sext((__int128_t)first, (sizeof(T) * 8));
    __int128_t second_ext = sext((__int128_t)second, (sizeof(T) * 8));
    return (first_ext * second_ext) >> (sizeof(T) * 8);
  }
  static std::string name() { return "Mulh"; }
};

template <typename T, typename R>
class Mulhsu {
public:
  static R apply(T first, T second, R) {
    __int128_t first_ext = zext((__int128_t)first, (sizeof(T) * 8));
    __int128_t second_ext = sext((__int128_t)second, (sizeof(T) * 8));
    return (first_ext * second_ext) >> (sizeof(T) * 8);
  }
  static std::string name() { return "Mulhsu"; }
};

template <typename T, typename R>
class Mulhu {
public:
  static R apply(T first, T second, R) {
    return ((__uint128_t)first * (__uint128_t)second) >> (sizeof(T) * 8);
  }
  static std::string name() { return "Mulhu"; }
};

template <typename T, typename R>
class Madd {
public:
  static R apply(T first, T second, R third) {
    return ((R)first * third) + (R)second;
  }
  static std::string name() { return "Madd"; }
};

template <typename T, typename R>
class Nmsac {
public:
  static R apply(T first, T second, R third) {
    return -((R)first * (R)second) + third;
  }
  static std::string name() { return "Nmsac"; }
};

template <typename T, typename R>
class Macc {
public:
  static R apply(T first, T second, R third) {
    return ((R)first * (R)second) + third;
  }
  static std::string name() { return "Macc"; }
};

template <typename T, typename R>
class Maccsu {
public:
  static R apply(T first, T second, R third) {
    R first_ext = sext((R)first, (sizeof(T) * 8));
    R second_ext = zext((R)second, (sizeof(T) * 8));
    return (first_ext * second_ext) + third;
  }
  static std::string name() { return "Maccsu"; }
};

template <typename T, typename R>
class Maccus {
public:
  static R apply(T first, T second, R third) {
    R first_ext = zext((R)first, (sizeof(T) * 8));
    R second_ext = sext((R)second, (sizeof(T) * 8));
    return (first_ext * second_ext) + third;
  }
  static std::string name() { return "Maccus"; }
};

template <typename T, typename R>
class Nmsub {
public:
  static R apply(T first, T second, R third) {
    return -((R)first * third) + (R)second;
  }
  static std::string name() { return "Nmsub"; }
};

template <typename T, typename R>
class Min {
public:
  static R apply(T first, T second, R) {
    return std::min(first, second);
  }
  static std::string name() { return "Min"; }
};

template <typename T, typename R>
class Max {
public:
  static R apply(T first, T second, R) {
    return std::max(first, second);
  }
  static std::string name() { return "Max"; }
};

template <typename T, typename R>
class And {
public:
  static R apply(T first, T second, R) {
    return first & second;
  }
  static std::string name() { return "And"; }
};

template <typename T, typename R>
class Or {
public:
  static R apply(T first, T second, R) {
    return first | second;
  }
  static std::string name() { return "Or"; }
};

template <typename T, typename R>
class Xor {
public:
  static R apply(T first, T second, R) {
    return first ^ second;
  }
  static std::string name() { return "Xor"; }
};

template <typename T, typename R>
class Sll {
public:
  static R apply(T first, T second, R) {
    // Only the low lg2(SEW) bits of the shift-amount value are used to control the shift amount.
    return second << (first & (sizeof(T) * 8 - 1));
  }
  static std::string name() { return "Sll"; }
};

template <typename T, typename R>
bool bitAt(T value, R pos, R negOffset) {
  R offsetPos = pos - negOffset;
  return pos >= negOffset && ((value >> offsetPos) & 0x1);
}

template <typename T, typename R>
bool anyBitUpTo(T value, R to, R negOffset) {
  R offsetTo = to - negOffset;
  return to >= negOffset && (value & (((R)1 << (offsetTo + 1)) - 1));
}

template <typename T, typename R>
bool roundBit(T value, R shiftDown, uint32_t vxrm) {
  switch (vxrm) {
  case 0: // round-to-nearest-up
    return bitAt(value, shiftDown, (R)1);
  case 1: // round-to-nearest-even
    return bitAt(value, shiftDown, (R)1) && (anyBitUpTo(value, shiftDown, (R)2) || bitAt(value, shiftDown, (R)0));
  case 2: // round-down (truncate)
    return 0;
  case 3: // round-to-odd
    return !bitAt(value, shiftDown, (R)0) && anyBitUpTo(value, shiftDown, (R)1);
  default:
    std::cout << "Roundoff - invalid value for vxrm: " << vxrm << std::endl;
    std::abort();
  }
}

template <typename T, typename R>
class SrlSra {
public:
  static R apply(T first, T second, R) {
    // Only the low lg2(SEW) bits of the shift-amount value are used to control the shift amount.
    return second >> (first & (sizeof(T) * 8 - 1));
  }
  static R apply(T first, T second, uint32_t vxrm, uint32_t) {
    // Saturation is not relevant for this operation
    // Only the low lg2(SEW) bits of the shift-amount value are used to control the shift amount.
    T firstValid = first & (sizeof(T) * 8 - 1);
    return apply(firstValid, second, 0) + roundBit(second, firstValid, vxrm);
  }
  static std::string name() { return "SrlSra"; }
};

template <typename T, typename R>
class Aadd {
public:
  static R apply(T first, T second, uint32_t vxrm, uint32_t) {
    // Saturation is not relevant for this operation
    T sum = second + first;
    return (sum >> 1) + roundBit(sum, 1, vxrm);
  }
  static std::string name() { return "Aadd"; }
};

template <typename T, typename R>
class Asub {
public:
  static R apply(T first, T second, uint32_t vxrm, uint32_t) {
    // Saturation is not relevant for this operation
    T difference = second - first;
    return (difference >> 1) + roundBit(difference, 1, vxrm);
  }
  static std::string name() { return "Asub"; }
};

template <typename T, typename R>
class Eq {
public:
  static R apply(T first, T second, R) {
    return first == second;
  }
  static std::string name() { return "Eq"; }
};

template <typename T, typename R>
class Ne {
public:
  static R apply(T first, T second, R) {
    return first != second;
  }
  static std::string name() { return "Ne"; }
};

template <typename T, typename R>
class Lt {
public:
  static R apply(T first, T second, R) {
    return first > second;
  }
  static std::string name() { return "Lt"; }
};

template <typename T, typename R>
class Le {
public:
  static R apply(T first, T second, R) {
    return first >= second;
  }
  static std::string name() { return "Le"; }
};

template <typename T, typename R>
class Gt {
public:
  static R apply(T first, T second, R) {
    return first < second;
  }
  static std::string name() { return "Gt"; }
};

template <typename T, typename R>
class AndNot {
public:
  static R apply(T first, T second, R) {
    return second & ~first;
  }
  static std::string name() { return "AndNot"; }
};

template <typename T, typename R>
class OrNot {
public:
  static R apply(T first, T second, R) {
    return second | ~first;
  }
  static std::string name() { return "OrNot"; }
};

template <typename T, typename R>
class Nand {
public:
  static R apply(T first, T second, R) {
    return ~(second & first);
  }
  static std::string name() { return "Nand"; }
};

template <typename T, typename R>
class Mv {
public:
  static R apply(T first, T, R) {
    return first;
  }
  static std::string name() { return "Mv"; }
};

template <typename T, typename R>
class Nor {
public:
  static R apply(T first, T second, R) {
    return ~(second | first);
  }
  static std::string name() { return "Nor"; }
};

template <typename T, typename R>
class Xnor {
public:
  static R apply(T first, T second, R) {
    return ~(second ^ first);
  }
  static std::string name() { return "Xnor"; }
};

template <typename T, typename R>
class Fadd {
public:
  static R apply(T first, T second, R) {
    // ignoring flags for now
    uint32_t fflags = 0;
    // ignoring rounding mode for now
    uint32_t frm = 0;
    if (sizeof(R) == 4) {
      return rv_fadd_s(first, second, frm, &fflags);
    } else if (sizeof(R) == 8) {
      uint64_t first_d = sizeof(T) == 8 ? first : rv_ftod(first);
      uint64_t second_d = sizeof(T) == 8 ? second : rv_ftod(second);
      return rv_fadd_d(first_d, second_d, frm, &fflags);
    } else {
      std::cout << "Fadd only supports f32 and f64" << std::endl;
      std::abort();
    }
  }
  static std::string name() { return "Fadd"; }
};

template <typename T, typename R>
class Fsub {
public:
  static R apply(T first, T second, R) {
    // ignoring flags for now
    uint32_t fflags = 0;
    // ignoring rounding mode for now
    uint32_t frm = 0;
    if (sizeof(R) == 4) {
      return rv_fsub_s(second, first, frm, &fflags);
    } else if (sizeof(R) == 8) {
      uint64_t first_d = sizeof(T) == 8 ? first : rv_ftod(first);
      uint64_t second_d = sizeof(T) == 8 ? second : rv_ftod(second);
      return rv_fsub_d(second_d, first_d, frm, &fflags);
    } else {
      std::cout << "Fsub only supports f32 and f64" << std::endl;
      std::abort();
    }
  }
  static std::string name() { return "Fsub"; }
};

template <typename T, typename R>
class Fmacc {
public:
  static R apply(T first, T second, R third) {
    // ignoring flags for now
    uint32_t fflags = 0;
    // ignoring rounding mode for now
    uint32_t frm = 0;
    if (sizeof(R) == 4) {
      return rv_fmadd_s(first, second, third, frm, &fflags);
    } else if (sizeof(R) == 8) {
      uint64_t first_d = sizeof(T) == 8 ? first : rv_ftod(first);
      uint64_t second_d = sizeof(T) == 8 ? second : rv_ftod(second);
      return rv_fmadd_d(first_d, second_d, third, frm, &fflags);
    } else {
      std::cout << "Fmacc only supports f32 and f64" << std::endl;
      std::abort();
    }
  }
  static std::string name() { return "Fmacc"; }
};

template <typename T, typename R>
class Fnmacc {
public:
  static R apply(T first, T second, R third) {
    // ignoring flags for now
    uint32_t fflags = 0;
    // ignoring rounding mode for now
    uint32_t frm = 0;
    if (sizeof(R) == 4) {
      return rv_fnmadd_s(first, second, third, frm, &fflags);
    } else if (sizeof(R) == 8) {
      uint64_t first_d = sizeof(T) == 8 ? first : rv_ftod(first);
      uint64_t second_d = sizeof(T) == 8 ? second : rv_ftod(second);
      return rv_fnmadd_d(first_d, second_d, third, frm, &fflags);
    } else {
      std::cout << "Fnmacc only supports f32 and f64" << std::endl;
      std::abort();
    }
  }
  static std::string name() { return "Fnmacc"; }
};

template <typename T, typename R>
class Fmsac {
public:
  static R apply(T first, T second, R third) {
    // ignoring flags for now
    uint32_t fflags = 0;
    // ignoring rounding mode for now
    uint32_t frm = 0;
    if (sizeof(R) == 4) {
      return rv_fmadd_s(first, second, rv_fsgnjn_s(third, third), frm, &fflags);
    } else if (sizeof(R) == 8) {
      uint64_t first_d = sizeof(T) == 8 ? first : rv_ftod(first);
      uint64_t second_d = sizeof(T) == 8 ? second : rv_ftod(second);
      return rv_fmadd_d(first_d, second_d, rv_fsgnjn_d(third, third), frm, &fflags);
    } else {
      std::cout << "Fmsac only supports f32 and f64" << std::endl;
      std::abort();
    }
  }
  static std::string name() { return "Fmsac"; }
};

template <typename T, typename R>
class Fnmsac {
public:
  static R apply(T first, T second, R third) {
    // ignoring flags for now
    uint32_t fflags = 0;
    // ignoring rounding mode for now
    uint32_t frm = 0;
    if (sizeof(R) == 4) {
      return rv_fnmadd_s(first, second, rv_fsgnjn_s(third, third), frm, &fflags);
    } else if (sizeof(R) == 8) {
      uint64_t first_d = sizeof(T) == 8 ? first : rv_ftod(first);
      uint64_t second_d = sizeof(T) == 8 ? second : rv_ftod(second);
      return rv_fnmadd_d(first_d, second_d, rv_fsgnjn_d(third, third), frm, &fflags);
    } else {
      std::cout << "Fnmsac only supports f32 and f64" << std::endl;
      std::abort();
    }
  }
  static std::string name() { return "Fnmsac"; }
};

template <typename T, typename R>
class Fmadd {
public:
  static R apply(T first, T second, R third) {
    if (sizeof(T) == 4 || sizeof(T) == 8) {
      return Fmacc<T, R>::apply(first, third, second);
    } else {
      std::cout << "Fmadd only supports f32 and f64" << std::endl;
      std::abort();
    }
  }
  static std::string name() { return "Fmadd"; }
};

template <typename T, typename R>
class Fnmadd {
public:
  static R apply(T first, T second, R third) {
    if (sizeof(T) == 4 || sizeof(T) == 8) {
      return Fnmacc<T, R>::apply(first, third, second);
    } else {
      std::cout << "Fnmadd only supports f32 and f64" << std::endl;
      std::abort();
    }
  }
  static std::string name() { return "Fnmadd"; }
};

template <typename T, typename R>
class Fmsub {
public:
  static R apply(T first, T second, R third) {
    if (sizeof(T) == 4 || sizeof(T) == 8) {
      return Fmsac<T, R>::apply(first, third, second);
    } else {
      std::cout << "Fmsub only supports f32 and f64" << std::endl;
      std::abort();
    }
  }
  static std::string name() { return "Fmsub"; }
};

template <typename T, typename R>
class Fnmsub {
public:
  static R apply(T first, T second, R third) {
    if (sizeof(T) == 4 || sizeof(T) == 8) {
      return Fnmsac<T, R>::apply(first, third, second);
    } else {
      std::cout << "Fnmsub only supports f32 and f64" << std::endl;
      std::abort();
    }
  }
  static std::string name() { return "Fnmsub"; }
};

template <typename T, typename R>
class Fmin {
public:
  static R apply(T first, T second, R) {
    // ignoring rounding modes for now
    uint32_t fflags = 0;
    if (sizeof(T) == 4) {
      return rv_fmin_s(first, second, &fflags);
    } else if (sizeof(T) == 8) {
      return rv_fmin_d(first, second, &fflags);
    } else {
      std::cout << "Fmin only supports f32 and f64" << std::endl;
      std::abort();
    }
  }
  static std::string name() { return "Fmin"; }
};

template <typename T, typename R>
class Fmax {
public:
  static R apply(T first, T second, R) {
    // ignoring rounding modes for now
    uint32_t fflags = 0;
    if (sizeof(T) == 4) {
      return rv_fmax_s(first, second, &fflags);
    } else if (sizeof(T) == 8) {
      return rv_fmax_d(first, second, &fflags);
    } else {
      std::cout << "Fmax only supports f32 and f64" << std::endl;
      std::abort();
    }
  }
  static std::string name() { return "Fmax"; }
};

template <typename T, typename R>
class Fsgnj {
public:
  static R apply(T first, T second, R) {
    if (sizeof(T) == 4) {
      return rv_fsgnj_s(second, first);
    } else if (sizeof(T) == 8) {
      return rv_fsgnj_d(second, first);
    } else {
      std::cout << "Fsgnj only supports f32 and f64" << std::endl;
      std::abort();
    }
  }
  static std::string name() { return "Fsgnj"; }
};

template <typename T, typename R>
class Fsgnjn {
public:
  static R apply(T first, T second, R) {
    if (sizeof(T) == 4) {
      return rv_fsgnjn_s(second, first);
    } else if (sizeof(T) == 8) {
      return rv_fsgnjn_d(second, first);
    } else {
      std::cout << "Fsgnjn only supports f32 and f64" << std::endl;
      std::abort();
    }
  }
  static std::string name() { return "Fsgnjn"; }
};

template <typename T, typename R>
class Fsgnjx {
public:
  static R apply(T first, T second, R) {
    if (sizeof(T) == 4) {
      return rv_fsgnjx_s(second, first);
    } else if (sizeof(T) == 8) {
      return rv_fsgnjx_d(second, first);
    } else {
      std::cout << "Fsgnjx only supports f32 and f64" << std::endl;
      std::abort();
    }
  }
  static std::string name() { return "Fsgnjx"; }
};

template <typename T, typename R>
class Fcvt {
public:
  static R apply(T first, T second, R) {
    // ignoring flags for now
    uint32_t fflags = 0;
    // ignoring rounding mode for now
    uint32_t frm = 0;
    if (sizeof(T) == 4) {
      switch (first) {
      case 0b00000: // vfcvt.xu.f.v
        return rv_ftou_s(second, frm, &fflags);
      case 0b00001: // vfcvt.x.f.v
        return rv_ftoi_s(second, frm, &fflags);
      case 0b00010: // vfcvt.f.xu.v
        return rv_utof_s(second, frm, &fflags);
      case 0b00011: // vfcvt.f.x.v
        return rv_itof_s(second, frm, &fflags);
      case 0b00110: // vfcvt.rtz.xu.f.v
        return rv_ftou_s(second, 1, &fflags);
      case 0b00111: // vfcvt.rtz.x.f.v
        return rv_ftoi_s(second, 1, &fflags);
      case 0b01000: // vfwcvt.xu.f.v
        return rv_ftolu_s(second, frm, &fflags);
      case 0b01001: // vfwcvt.x.f.v
        return rv_ftol_s(second, frm, &fflags);
      case 0b01010: // vfwcvt.f.xu.v
        return rv_utof_d(second, frm, &fflags);
      case 0b01011: // vfwcvt.f.x.v
        return rv_itof_d(second, frm, &fflags);
      case 0b01100: // vfwcvt.f.f.v
        return rv_ftod(second);
      case 0b01110: // vfwcvt.rtz.xu.f.v
        return rv_ftolu_s(second, 1, &fflags);
      case 0b01111: // vfwcvt.rtz.x.f.v
        return rv_ftol_s(second, 1, &fflags);
      default:
        std::cout << "Fcvt has unsupported value for first: " << first << std::endl;
        std::abort();
      }
    } else if (sizeof(T) == 8) {
      switch (first) {
      case 0b00000: // vfcvt.xu.f.v
        return rv_ftolu_d(second, frm, &fflags);
      case 0b00001: // vfcvt.x.f.v
        return rv_ftol_d(second, frm, &fflags);
      case 0b00010: // vfcvt.f.xu.v
        return rv_lutof_d(second, frm, &fflags);
      case 0b00011: // vfcvt.f.x.v
        return rv_ltof_d(second, frm, &fflags);
      case 0b00110: // vfcvt.rtz.xu.f.v
        return rv_ftolu_d(second, 1, &fflags);
      case 0b00111: // vfcvt.rtz.x.f.v
        return rv_ftol_d(second, 1, &fflags);
      case 0b01000: // vfwcvt.xu.f.v
      case 0b01001: // vfwcvt.x.f.v
      case 0b01010: // vfwcvt.f.xu.v
      case 0b01011: // vfwcvt.f.x.v
      case 0b01100: // vfwcvt.f.f.v
      case 0b01110: // vfwcvt.rtz.xu.f.v
      case 0b01111: // vfwcvt.rtz.x.f.v
        std::cout << "Fwcvt only supports f32" << std::endl;
        std::abort();
      default:
        std::cout << "Fcvt has unsupported value for first: " << first << std::endl;
        std::abort();
      }
    } else {
      std::cout << "Fcvt only supports f32 and f64" << std::endl;
      std::abort();
    }
  }
  static R apply(T first, T second, uint32_t vxrm, uint32_t &) { // saturation argument is unused
    // ignoring flags for now
    uint32_t fflags = 0;
    if (sizeof(T) == 8) {
      switch (first) {
      case 0b10000: // vfncvt.xu.f.w
        return rv_ftou_d(second, vxrm, &fflags);
      case 0b10001: // vfncvt.x.f.w
        return rv_ftoi_d(second, vxrm, &fflags);
      case 0b10010: // vfncvt.f.xu.w
        return rv_lutof_s(second, vxrm, &fflags);
      case 0b10011: // vfncvt.f.x.w
        return rv_ltof_s(second, vxrm, &fflags);
      case 0b10100: // vfncvt.f.f.w
        return rv_dtof_r(second, vxrm);
      case 0b10101: // vfncvt.rod.f.f.w
        return rv_dtof_r(second, 6);
      case 0b10110: // vfncvt.rtz.xu.f.w
        return rv_ftou_d(second, 1, &fflags);
      case 0b10111: // vfncvt.rtz.x.f.w
        return rv_ftoi_d(second, 1, &fflags);
      default:
        std::cout << "Fncvt has unsupported value for first: " << first << std::endl;
        std::abort();
      }
    } else {
      std::cout << "Fncvt only supports f64" << std::endl;
      std::abort();
    }
  }
  static std::string name() { return "Fcvt"; }
};

template <typename T, typename R>
class Funary1 {
public:
  static R apply(T first, T second, R) {
    // ignoring flags for now
    uint32_t fflags = 0;
    // ignoring rounding mode for now
    uint32_t frm = 0;
    if (sizeof(T) == 4) {
      switch (first) {
      case 0b00000: // vfsqrt.v
        return rv_fsqrt_s(second, frm, &fflags);
      case 0b00100: // vfrsqrt7.v
        return rv_frsqrt7_s(second, frm, &fflags);
      case 0b00101: // vfrec7.v
        return rv_frecip7_s(second, frm, &fflags);
      case 0b10000: // vfclass.v
        return rv_fclss_s(second);
      default:
        std::cout << "Funary1 has unsupported value for first: " << first << std::endl;
        std::abort();
      }
    } else if (sizeof(T) == 8) {
      switch (first) {
      case 0b00000: // vfsqrt.v
        return rv_fsqrt_d(second, frm, &fflags);
      case 0b00100: // vfrsqrt7.v
        return rv_frsqrt7_d(second, frm, &fflags);
      case 0b00101: // vfrec7.v
        return rv_frecip7_d(second, frm, &fflags);
      case 0b10000: // vfclass.v
        return rv_fclss_d(second);
      default:
        std::cout << "Funary1 has unsupported value for first: " << first << std::endl;
        std::abort();
      }
    } else {
      std::cout << "Funary1 only supports f32 and f64" << std::endl;
      std::abort();
    }
  }
  static std::string name() { return "Funary1"; }
};

template <typename T, typename R>
class Xunary0 {
public:
  static R apply(T, T second, T) {
    return second;
  }
  static std::string name() { return "Xunary0"; }
};

template <typename T, typename R>
class Feq {
public:
  static R apply(T first, T second, R) {
    // ignoring flags for now
    uint32_t fflags = 0;
    if (sizeof(T) == 4) {
      return rv_feq_s(second, first, &fflags);
    } else if (sizeof(T) == 8) {
      return rv_feq_d(second, first, &fflags);
    } else {
      std::cout << "Feq only supports f32 and f64" << std::endl;
      std::abort();
    }
  }
  static std::string name() { return "Feq"; }
};

template <typename T, typename R>
class Fle {
public:
  static R apply(T first, T second, R) {
    // ignoring flags for now
    uint32_t fflags = 0;
    if (sizeof(T) == 4) {
      return rv_fle_s(second, first, &fflags);
    } else if (sizeof(T) == 8) {
      return rv_fle_d(second, first, &fflags);
    } else {
      std::cout << "Fle only supports f32 and f64" << std::endl;
      std::abort();
    }
  }
  static std::string name() { return "Fle"; }
};

template <typename T, typename R>
class Flt {
public:
  static R apply(T first, T second, R) {
    // ignoring flags for now
    uint32_t fflags = 0;
    if (sizeof(T) == 4) {
      return rv_flt_s(second, first, &fflags);
    } else if (sizeof(T) == 8) {
      return rv_flt_d(second, first, &fflags);
    } else {
      std::cout << "Flt only supports f32 and f64" << std::endl;
      std::abort();
    }
  }
  static std::string name() { return "Flt"; }
};

template <typename T, typename R>
class Fne {
public:
  static R apply(T first, T second, R) {
    // ignoring flags for now
    uint32_t fflags = 0;
    if (sizeof(T) == 4) {
      return !rv_feq_s(second, first, &fflags);
    } else if (sizeof(T) == 8) {
      return !rv_feq_d(second, first, &fflags);
    } else {
      std::cout << "Fne only supports f32 and f64" << std::endl;
      std::abort();
    }
  }
  static std::string name() { return "Fne"; }
};

template <typename T, typename R>
class Fgt {
public:
  static R apply(T first, T second, R) {
    // ignoring flags for now
    uint32_t fflags = 0;
    if (sizeof(T) == 4) {
      return rv_flt_s(first, second, &fflags);
    } else if (sizeof(T) == 8) {
      return rv_flt_d(first, second, &fflags);
    } else {
      std::cout << "Fgt only supports f32 and f64" << std::endl;
      std::abort();
    }
  }
  static std::string name() { return "Fgt"; }
};

template <typename T, typename R>
class Fge {
public:
  static R apply(T first, T second, R) {
    // ignoring flags for now
    uint32_t fflags = 0;
    if (sizeof(T) == 4) {
      return rv_fle_s(first, second, &fflags);
    } else if (sizeof(T) == 8) {
      return rv_fle_d(first, second, &fflags);
    } else {
      std::cout << "Fge only supports f32 and f64" << std::endl;
      std::abort();
    }
  }
  static std::string name() { return "Fge"; }
};

template <typename T, typename R>
class Fdiv {
public:
  static R apply(T first, T second, R) {
    // ignoring flags for now
    uint32_t fflags = 0;
    // ignoring rounding mode for now
    uint32_t frm = 0;
    if (sizeof(T) == 4) {
      return rv_fdiv_s(second, first, frm, &fflags);
    } else if (sizeof(T) == 8) {
      return rv_fdiv_d(second, first, frm, &fflags);
    } else {
      std::cout << "Fdiv only supports f32 and f64" << std::endl;
      std::abort();
    }
  }
  static std::string name() { return "Fdiv"; }
};

template <typename T, typename R>
class Frdiv {
public:
  static R apply(T first, T second, R) {
    // ignoring flags for now
    uint32_t fflags = 0;
    // ignoring rounding mode for now
    uint32_t frm = 0;
    if (sizeof(T) == 4) {
      return rv_fdiv_s(first, second, frm, &fflags);
    } else if (sizeof(T) == 8) {
      return rv_fdiv_d(first, second, frm, &fflags);
    } else {
      std::cout << "Frdiv only supports f32 and f64" << std::endl;
      std::abort();
    }
  }
  static std::string name() { return "Frdiv"; }
};

template <typename T, typename R>
class Fmul {
public:
  static R apply(T first, T second, R) {
    // ignoring flags for now
    uint32_t fflags = 0;
    // ignoring rounding mode for now
    uint32_t frm = 0;
    if (sizeof(R) == 4) {
      return rv_fmul_s(first, second, frm, &fflags);
    } else if (sizeof(R) == 8) {
      uint64_t first_d = sizeof(T) == 8 ? first : rv_ftod(first);
      uint64_t second_d = sizeof(T) == 8 ? second : rv_ftod(second);
      return rv_fmul_d(first_d, second_d, frm, &fflags);
    } else {
      std::cout << "Fmul only supports f32 and f64" << std::endl;
      std::abort();
    }
  }
  static std::string name() { return "Fmul"; }
};

template <typename T, typename R>
class Frsub {
public:
  static R apply(T first, T second, R) {
    // ignoring flags for now
    uint32_t fflags = 0;
    // ignoring rounding mode for now
    uint32_t frm = 0;
    if (sizeof(T) == 4) {
      return rv_fsub_s(first, second, frm, &fflags);
    } else if (sizeof(T) == 8) {
      return rv_fsub_d(first, second, frm, &fflags);
    } else {
      std::cout << "Frsub only supports f32 and f64" << std::endl;
      std::abort();
    }
  }
  static std::string name() { return "Frsub"; }
};

template <typename T, typename R>
class Clip {
public:
  static R apply(T first, T second, uint32_t vxrm, uint32_t &vxsat_) {
    // The low lg2(2*SEW) bits of the vector or scalar shift-amount value (e.g., the low 6 bits for a SEW=64-bit to
    // SEW=32-bit narrowing operation) are used to control the right shift amount, which provides the scaling.
    R firstValid = first & (sizeof(T) * 8 - 1);
    T unclippedResult = (second >> firstValid) + roundBit(second, firstValid, vxrm);
    R clippedResult = std::clamp(unclippedResult, (T)std::numeric_limits<R>::min(), (T)std::numeric_limits<R>::max());
    vxsat_ |= clippedResult != unclippedResult;
    return clippedResult;
  }
  static std::string name() { return "Clip"; }
};

template <typename T, typename R>
class Smul {
public:
  static R apply(T first, T second, uint32_t vxrm, uint32_t &vxsat_) {
    R shift = sizeof(R) * 8 - 1;
    T unshiftedResult = first * second;
    T unclippedResult = (unshiftedResult >> shift) + roundBit(unshiftedResult, shift, vxrm);
    R clippedResult = std::clamp(unclippedResult, (T)std::numeric_limits<R>::min(), (T)std::numeric_limits<R>::max());
    vxsat_ |= clippedResult != unclippedResult;
    return clippedResult;
  }
  static std::string name() { return "Smul"; }
};

///////////////////////////////////////////////////////////////////////////////

bool isMasked(std::vector<std::vector<Byte>> &vreg_file, uint32_t maskVreg, uint32_t byteI, bool vmask) {
  auto &mask = vreg_file.at(maskVreg);
  uint8_t emask = *(uint8_t *)(mask.data() + byteI / 8);
  uint8_t value = (emask >> (byteI % 8)) & 0x1;
  DP(4, "Masking enabled: " << +!vmask << " mask element: " << +value);
  return !vmask && value == 0;
}

template <typename DT>
uint32_t getVreg(uint32_t baseVreg, uint32_t byteI) {
  uint32_t vsew = sizeof(DT) * 8;
  return (baseVreg + (byteI / (VLEN / vsew))) % 32;
}

template <typename DT>
DT &getVregData(std::vector<vortex::Byte> &baseVregVec, uint32_t byteI) {
  uint32_t vsew = sizeof(DT) * 8;
  return *(DT *)(baseVregVec.data() + (byteI % (VLEN / vsew)) * vsew / 8);
}

template <typename DT>
DT &getVregData(std::vector<std::vector<vortex::Byte>> &vreg_file, uint32_t baseVreg, uint32_t byteI) {
  auto &vr1 = vreg_file.at(getVreg<DT>(baseVreg, byteI));
  return getVregData<DT>(vr1, byteI);
}

template <typename DT>
void vector_op_vix_load(std::vector<std::vector<Byte>> &vreg_file, vortex::Emulator *emul_, WordI base_addr, uint32_t rdest, uint32_t vl, bool strided, WordI stride, uint32_t nfields, uint32_t lmul, uint32_t vmask) {
  uint32_t vsew = sizeof(DT) * 8;
  uint32_t emul = lmul >> 2 ? 1 : 1 << (lmul & 0b11);
  if (nfields * emul > 8) {
    std::cout << "NFIELDS * EMUL = " << nfields * lmul << " but it should be <= 8" << std::endl;
    std::abort();
  }
  for (uint32_t i = 0; i < vl * nfields; i++) {
    if (isMasked(vreg_file, 0, i / nfields, vmask))
      continue;

    uint32_t nfields_strided = strided ? nfields : 1;
    Word mem_addr = (base_addr & 0xFFFFFFFC) + (i / nfields_strided) * stride + (i % nfields_strided) * sizeof(DT);
    Word mem_data = 0;
    emul_->dcache_read(&mem_data, mem_addr, vsew / 8);
    DP(4, "Loading data " << mem_data << " from: " << mem_addr << " to vec reg: " << getVreg<DT>(rdest + (i % nfields) * emul, i / nfields) << " i: " << i / nfields);
    DT &result = getVregData<DT>(vreg_file, rdest + (i % nfields) * emul, i / nfields);
    DP(4, "Previous data: " << +result);
    result = (DT)mem_data;
  }
}

void vector_op_vix_load(std::vector<std::vector<Byte>> &vreg_file, vortex::Emulator *emul_, WordI base_addr, uint32_t rdest, uint32_t vsew, uint32_t vl, bool strided, WordI stride, uint32_t nfields, uint32_t lmul, uint32_t vmask) {
  switch (vsew) {
  case 8:
    vector_op_vix_load<uint8_t>(vreg_file, emul_, base_addr, rdest, vl, strided, stride, nfields, lmul, vmask);
    break;
  case 16:
    vector_op_vix_load<uint16_t>(vreg_file, emul_, base_addr, rdest, vl, strided, stride, nfields, lmul, vmask);
    break;
  case 32:
    vector_op_vix_load<uint32_t>(vreg_file, emul_, base_addr, rdest, vl, strided, stride, nfields, lmul, vmask);
    break;
  case 64:
    vector_op_vix_load<uint64_t>(vreg_file, emul_, base_addr, rdest, vl, strided, stride, nfields, lmul, vmask);
    break;
  default:
    std::cout << "Failed to execute VLE for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <typename DT>
void vector_op_vv_load(std::vector<std::vector<Byte>> &vreg_file, vortex::Emulator *emul_, WordI base_addr, uint32_t rsrc1, uint32_t rdest, uint32_t iSew, uint32_t vl, uint32_t nfields, uint32_t lmul, uint32_t vmask) {
  uint32_t vsew = sizeof(DT) * 8;
  uint32_t emul = lmul >> 2 ? 1 : 1 << (lmul & 0b11);
  if (nfields * emul > 8) {
    std::cout << "NFIELDS * EMUL = " << nfields * lmul << " but it should be <= 8" << std::endl;
    std::abort();
  }
  for (uint32_t i = 0; i < vl * nfields; i++) {
    if (isMasked(vreg_file, 0, i / nfields, vmask))
      continue;

    Word offset = 0;
    switch (iSew) {
    case 8:
      offset = getVregData<uint8_t>(vreg_file, rsrc1, i / nfields);
      break;
    case 16:
      offset = getVregData<uint16_t>(vreg_file, rsrc1, i / nfields);
      break;
    case 32:
      offset = getVregData<uint32_t>(vreg_file, rsrc1, i / nfields);
      break;
    case 64:
      offset = getVregData<uint64_t>(vreg_file, rsrc1, i / nfields);
      break;
    default:
      std::cout << "Unsupported iSew: " << iSew << std::endl;
      std::abort();
    }

    Word mem_addr = (base_addr & 0xFFFFFFFC) + offset + (i % nfields) * sizeof(DT);
    Word mem_data = 0;
    emul_->dcache_read(&mem_data, mem_addr, vsew / 8);
    DP(4, "VLUX/VLOX - Loading data " << mem_data << " from: " << mem_addr << " with offset: " << std::dec << offset << " to vec reg: " << getVreg<DT>(rdest + (i % nfields) * emul, i / nfields) << " i: " << i / nfields);
    DT &result = getVregData<DT>(vreg_file, rdest + (i % nfields) * emul, i / nfields);
    DP(4, "Previous data: " << +result);
    result = (DT)mem_data;
  }
}

void vector_op_vv_load(std::vector<std::vector<Byte>> &vreg_file, vortex::Emulator *emul_, WordI base_addr, uint32_t rsrc1, uint32_t rdest, uint32_t vsew, uint32_t iSew, uint32_t vl, uint32_t nfields, uint32_t lmul, uint32_t vmask) {
  switch (vsew) {
  case 8:
    vector_op_vv_load<uint8_t>(vreg_file, emul_, base_addr, rsrc1, rdest, iSew, vl, nfields, lmul, vmask);
    break;
  case 16:
    vector_op_vv_load<uint16_t>(vreg_file, emul_, base_addr, rsrc1, rdest, iSew, vl, nfields, lmul, vmask);
    break;
  case 32:
    vector_op_vv_load<uint32_t>(vreg_file, emul_, base_addr, rsrc1, rdest, iSew, vl, nfields, lmul, vmask);
    break;
  case 64:
    vector_op_vv_load<uint64_t>(vreg_file, emul_, base_addr, rsrc1, rdest, iSew, vl, nfields, lmul, vmask);
    break;
  default:
    std::cout << "Failed to execute VLUX/VLOX for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <typename DT>
void vector_op_vix_store(std::vector<std::vector<Byte>> &vreg_file, vortex::Emulator *emul_, WordI base_addr, uint32_t rsrc3, uint32_t vl, bool strided, WordI stride, uint32_t nfields, uint32_t lmul, uint32_t vmask) {
  uint32_t vsew = sizeof(DT) * 8;
  uint32_t emul = lmul >> 2 ? 1 : 1 << (lmul & 0b11);
  for (uint32_t i = 0; i < vl * nfields; i++) {
    if (isMasked(vreg_file, 0, i / nfields, vmask))
      continue;

    uint32_t nfields_strided = strided ? nfields : 1;
    Word mem_addr = base_addr + (i / nfields_strided) * stride + (i % nfields_strided) * sizeof(DT);
    Word mem_data = getVregData<DT>(vreg_file, rsrc3 + (i % nfields) * emul, i / nfields);
    DP(4, "Storing: " << std::hex << mem_data << " at: " << mem_addr << " from vec reg: " << getVreg<DT>(rsrc3 + (i % nfields) * emul, i / nfields) << " i: " << i / nfields);
    emul_->dcache_write(&mem_data, mem_addr, vsew / 8);
  }
}

void vector_op_vix_store(std::vector<std::vector<Byte>> &vreg_file, vortex::Emulator *emul_, WordI base_addr, uint32_t rsrc3, uint32_t vsew, uint32_t vl, bool strided, WordI stride, uint32_t nfields, uint32_t lmul, uint32_t vmask) {
  switch (vsew) {
  case 8:
    vector_op_vix_store<uint8_t>(vreg_file, emul_, base_addr, rsrc3, vl, strided, stride, nfields, lmul, vmask);
    break;
  case 16:
    vector_op_vix_store<uint16_t>(vreg_file, emul_, base_addr, rsrc3, vl, strided, stride, nfields, lmul, vmask);
    break;
  case 32:
    vector_op_vix_store<uint32_t>(vreg_file, emul_, base_addr, rsrc3, vl, strided, stride, nfields, lmul, vmask);
    break;
  case 64:
    vector_op_vix_store<uint64_t>(vreg_file, emul_, base_addr, rsrc3, vl, strided, stride, nfields, lmul, vmask);
    break;
  default:
    std::cout << "Failed to execute VSE for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <typename DT>
void vector_op_vv_store(std::vector<std::vector<Byte>> &vreg_file, vortex::Emulator *emul_, WordI base_addr, uint32_t rsrc1, uint32_t rsrc3, uint32_t iSew, uint32_t vl, uint32_t nfields, uint32_t lmul, uint32_t vmask) {
  uint32_t vsew = sizeof(DT) * 8;
  uint32_t emul = lmul >> 2 ? 1 : 1 << (lmul & 0b11);
  for (uint32_t i = 0; i < vl * nfields; i++) {
    if (isMasked(vreg_file, 0, i / nfields, vmask))
      continue;

    Word offset = 0;
    switch (iSew) {
    case 8:
      offset = getVregData<uint8_t>(vreg_file, rsrc1, i / nfields);
      break;
    case 16:
      offset = getVregData<uint16_t>(vreg_file, rsrc1, i / nfields);
      break;
    case 32:
      offset = getVregData<uint32_t>(vreg_file, rsrc1, i / nfields);
      break;
    case 64:
      offset = getVregData<uint64_t>(vreg_file, rsrc1, i / nfields);
      break;
    default:
      std::cout << "Unsupported iSew: " << iSew << std::endl;
      std::abort();
    }

    Word mem_addr = base_addr + offset + (i % nfields) * sizeof(DT);
    Word mem_data = getVregData<DT>(vreg_file, rsrc3 + (i % nfields) * emul, i / nfields);
    DP(4, "VSUX/VSOX - Storing: " << std::hex << mem_data << " at: " << mem_addr << " with offset: " << std::dec << offset << " from vec reg: " << getVreg<DT>(rsrc3 + (i % nfields) * emul, i / nfields) << " i: " << i / nfields);
    emul_->dcache_write(&mem_data, mem_addr, vsew / 8);
  }
}

void vector_op_vv_store(std::vector<std::vector<Byte>> &vreg_file, vortex::Emulator *emul_, WordI base_addr, uint32_t rsrc1, uint32_t rsrc3, uint32_t vsew, uint32_t iSew, uint32_t vl, uint32_t nfields, uint32_t lmul, uint32_t vmask) {
  switch (vsew) {
  case 8:
    vector_op_vv_store<uint8_t>(vreg_file, emul_, base_addr, rsrc1, rsrc3, iSew, vl, nfields, lmul, vmask);
    break;
  case 16:
    vector_op_vv_store<uint16_t>(vreg_file, emul_, base_addr, rsrc1, rsrc3, iSew, vl, nfields, lmul, vmask);
    break;
  case 32:
    vector_op_vv_store<uint32_t>(vreg_file, emul_, base_addr, rsrc1, rsrc3, iSew, vl, nfields, lmul, vmask);
    break;
  case 64:
    vector_op_vv_store<uint64_t>(vreg_file, emul_, base_addr, rsrc1, rsrc3, iSew, vl, nfields, lmul, vmask);
    break;
  default:
    std::cout << "Failed to execute VSUX/VSOX for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT>
void vector_op_vix(DT first, std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rdest, uint32_t vl, uint32_t vmask) {
  for (uint32_t i = 0; i < vl; i++) {
    if (isMasked(vreg_file, 0, i, vmask))
      continue;

    DT second = getVregData<DT>(vreg_file, rsrc0, i);
    DT third = getVregData<DT>(vreg_file, rdest, i);
    DT result = OP<DT, DT>::apply(first, second, third);
    DP(4, (OP<DT, DT>::name()) << "(" << +first << ", " << +second << ", " << +third << ")" << " = " << +result);
    getVregData<DT>(vreg_file, rdest, i) = result;
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT8, typename DT16, typename DT32, typename DT64>
void vector_op_vix(Word src1, std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rdest, uint32_t vsew, uint32_t vl, uint32_t vmask) {
  switch (vsew) {
  case 8:
    vector_op_vix<OP, DT8>(src1, vreg_file, rsrc0, rdest, vl, vmask);
    break;
  case 16:
    vector_op_vix<OP, DT16>(src1, vreg_file, rsrc0, rdest, vl, vmask);
    break;
  case 32:
    vector_op_vix<OP, DT32>(src1, vreg_file, rsrc0, rdest, vl, vmask);
    break;
  case 64:
    vector_op_vix<OP, DT64>(src1, vreg_file, rsrc0, rdest, vl, vmask);
    break;
  default:
    std::cout << "Failed to execute VI/VX for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT>
void vector_op_vix_carry(DT first, std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rdest, uint32_t vl) {
  for (uint32_t i = 0; i < vl; i++) {
    DT second = getVregData<DT>(vreg_file, rsrc0, i);
    bool third = !isMasked(vreg_file, 0, i, false);
    DT result = OP<DT, DT>::apply(first, second, third);
    DP(4, (OP<DT, DT>::name()) << "(" << +first << ", " << +second << ", " << +third << ")" << " = " << +result);
    getVregData<DT>(vreg_file, rdest, i) = result;
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT8, typename DT16, typename DT32, typename DT64>
void vector_op_vix_carry(Word src1, std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rdest, uint32_t vsew, uint32_t vl) {
  switch (vsew) {
  case 8:
    vector_op_vix_carry<OP, DT8>(src1, vreg_file, rsrc0, rdest, vl);
    break;
  case 16:
    vector_op_vix_carry<OP, DT16>(src1, vreg_file, rsrc0, rdest, vl);
    break;
  case 32:
    vector_op_vix_carry<OP, DT32>(src1, vreg_file, rsrc0, rdest, vl);
    break;
  case 64:
    vector_op_vix_carry<OP, DT64>(src1, vreg_file, rsrc0, rdest, vl);
    break;
  default:
    std::cout << "Failed to execute VI/VX carry for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT, typename DTR>
void vector_op_vix_carry_out(DT first, std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rdest, uint32_t vl, uint32_t vmask) {
  for (uint32_t i = 0; i < vl; i++) {
    DT second = getVregData<DT>(vreg_file, rsrc0, i);
    bool third = !vmask && !isMasked(vreg_file, 0, i, vmask);
    bool result = OP<DT, DTR>::apply(first, second, third);
    DP(4, (OP<DT, DT>::name()) << "(" << +first << ", " << +second << ", " << +third << ")" << " = " << +result);
    if (result) {
      getVregData<uint8_t>(vreg_file, rdest, i / 8) |= 1 << (i % 8);
    } else {
      getVregData<uint8_t>(vreg_file, rdest, i / 8) &= ~(1 << (i % 8));
    }
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT8, typename DT16, typename DT32, typename DT64, typename DT128>
void vector_op_vix_carry_out(Word src1, std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rdest, uint32_t vsew, uint32_t vl, uint32_t vmask) {
  switch (vsew) {
  case 8:
    vector_op_vix_carry_out<OP, DT8, DT16>(src1, vreg_file, rsrc0, rdest, vl, vmask);
    break;
  case 16:
    vector_op_vix_carry_out<OP, DT16, DT32>(src1, vreg_file, rsrc0, rdest, vl, vmask);
    break;
  case 32:
    vector_op_vix_carry_out<OP, DT32, DT64>(src1, vreg_file, rsrc0, rdest, vl, vmask);
    break;
  case 64:
    vector_op_vix_carry_out<OP, DT64, DT128>(src1, vreg_file, rsrc0, rdest, vl, vmask);
    break;
  default:
    std::cout << "Failed to execute VI/VX carry out for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <typename DT>
void vector_op_vix_merge(DT first, std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rdest, uint32_t vl, uint32_t vmask) {
  for (uint32_t i = 0; i < vl; i++) {
    DT result = isMasked(vreg_file, 0, i, vmask) ? getVregData<DT>(vreg_file, rsrc0, i) : first;
    DP(4, "Merge - Choosing result: " << +result);
    getVregData<DT>(vreg_file, rdest, i) = result;
  }
}

template <typename DT8, typename DT16, typename DT32, typename DT64>
void vector_op_vix_merge(Word src1, std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rdest, uint32_t vsew, uint32_t vl, uint32_t vmask) {
  switch (vsew) {
  case 8:
    vector_op_vix_merge<DT8>(src1, vreg_file, rsrc0, rdest, vl, vmask);
    break;
  case 16:
    vector_op_vix_merge<DT16>(src1, vreg_file, rsrc0, rdest, vl, vmask);
    break;
  case 32:
    vector_op_vix_merge<DT32>(src1, vreg_file, rsrc0, rdest, vl, vmask);
    break;
  case 64:
    vector_op_vix_merge<DT64>(src1, vreg_file, rsrc0, rdest, vl, vmask);
    break;
  default:
    std::cout << "Failed to execute VI/VX for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <typename DT>
void vector_op_scalar(DT &dest, std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t vsew) {
  if (rsrc0 != 0) {
    std::cout << "Vwxunary0/Vwfunary0 has unsupported value for vs2: " << rsrc0 << std::endl;
    std::abort();
  }
  switch (vsew) {
  case 8:
    dest = getVregData<uint8_t>(vreg_file, rsrc1, 0);
    break;
  case 16:
    dest = getVregData<uint16_t>(vreg_file, rsrc1, 0);
    break;
  case 32:
    dest = getVregData<uint32_t>(vreg_file, rsrc1, 0);
    break;
  case 64:
    dest = getVregData<uint64_t>(vreg_file, rsrc1, 0);
    break;
  default:
    std::cout << "Failed to execute vmv.x.s/vfmv.f.s for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT, typename DTR>
void vector_op_vix_w(DT first, std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rdest, uint32_t vl, uint32_t vmask) {
  for (uint32_t i = 0; i < vl; i++) {
    if (isMasked(vreg_file, 0, i, vmask))
      continue;

    DT second = getVregData<DT>(vreg_file, rsrc0, i);
    DTR third = getVregData<DTR>(vreg_file, rdest, i);
    DTR result = OP<DT, DTR>::apply(first, second, third);
    DP(4, "Widening " << (OP<DT, DTR>::name()) << "(" << +first << ", " << +second << ", " << +third << ")" << " = " << +result);
    getVregData<DTR>(vreg_file, rdest, i) = result;
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT8, typename DT16, typename DT32, typename DT64>
void vector_op_vix_w(Word src1, std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rdest, uint32_t vsew, uint32_t vl, uint32_t vmask) {
  switch (vsew) {
  case 8:
    vector_op_vix_w<OP, DT8, DT16>(src1, vreg_file, rsrc0, rdest, vl, vmask);
    break;
  case 16:
    vector_op_vix_w<OP, DT16, DT32>(src1, vreg_file, rsrc0, rdest, vl, vmask);
    break;
  case 32:
    vector_op_vix_w<OP, DT32, DT64>(src1, vreg_file, rsrc0, rdest, vl, vmask);
    break;
  default:
    std::cout << "Failed to execute VI/VX widening for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT8, typename DT16, typename DT32, typename DT64>
void vector_op_vix_wx(Word src1, std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rdest, uint32_t vsew, uint32_t vl, uint32_t vmask) {
  switch (vsew) {
  case 8:
    vector_op_vix<OP, DT16>(src1, vreg_file, rsrc0, rdest, vl, vmask);
    break;
  case 16:
    vector_op_vix<OP, DT32>(src1, vreg_file, rsrc0, rdest, vl, vmask);
    break;
  case 32:
    vector_op_vix<OP, DT64>(src1, vreg_file, rsrc0, rdest, vl, vmask);
    break;
  default:
    std::cout << "Failed to execute VI/VX widening wx for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT, typename DTR>
void vector_op_vix_n(DT first, std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rdest, uint32_t vl, uint32_t vmask, uint32_t vxrm, uint32_t &vxsat) {
  for (uint32_t i = 0; i < vl; i++) {
    if (isMasked(vreg_file, 0, i, vmask))
      continue;

    DT second = getVregData<DT>(vreg_file, rsrc0, i);
    DTR result = OP<DT, DTR>::apply(first, second, vxrm, vxsat);
    DP(4, "Narrowing " << (OP<DT, DTR>::name()) << "(" << +first << ", " << +second << ")" << " = " << +result);
    getVregData<DTR>(vreg_file, rdest, i) = result;
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT8, typename DT16, typename DT32, typename DT64>
void vector_op_vix_n(Word src1, std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rdest, uint32_t vsew, uint32_t vl, uint32_t vmask, uint32_t vxrm, uint32_t &vxsat) {
  switch (vsew) {
  case 8:
    vector_op_vix_n<OP, DT16, DT8>(src1, vreg_file, rsrc0, rdest, vl, vmask, vxrm, vxsat);
    break;
  case 16:
    vector_op_vix_n<OP, DT32, DT16>(src1, vreg_file, rsrc0, rdest, vl, vmask, vxrm, vxsat);
    break;
  case 32:
    vector_op_vix_n<OP, DT64, DT32>(src1, vreg_file, rsrc0, rdest, vl, vmask, vxrm, vxsat);
    break;
  default:
    std::cout << "Failed to execute VI/VX narrowing for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT, typename DTR>
void vector_op_vix_sat(DTR first, std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rdest, uint32_t vl, uint32_t vmask, uint32_t vxrm, uint32_t &vxsat) {
  for (uint32_t i = 0; i < vl; i++) {
    if (isMasked(vreg_file, 0, i, vmask))
      continue;

    DT second = getVregData<DTR>(vreg_file, rsrc0, i);
    DTR result = OP<DT, DTR>::apply(first, second, vxrm, vxsat);
    DP(4, "Saturating " << (OP<DT, DTR>::name()) << "(" << +(DTR)first << ", " << +(DTR)second << ")" << " = " << +(DTR)result);
    getVregData<DTR>(vreg_file, rdest, i) = result;
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT8, typename DT16, typename DT32, typename DT64, typename DT128>
void vector_op_vix_sat(Word src1, std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rdest, uint32_t vsew, uint32_t vl, uint32_t vmask, uint32_t vxrm, uint32_t &vxsat) {
  switch (vsew) {
  case 8:
    vector_op_vix_sat<OP, DT16, DT8>(src1, vreg_file, rsrc0, rdest, vl, vmask, vxrm, vxsat);
    break;
  case 16:
    vector_op_vix_sat<OP, DT32, DT16>(src1, vreg_file, rsrc0, rdest, vl, vmask, vxrm, vxsat);
    break;
  case 32:
    vector_op_vix_sat<OP, DT64, DT32>(src1, vreg_file, rsrc0, rdest, vl, vmask, vxrm, vxsat);
    break;
  case 64:
    vector_op_vix_sat<OP, DT128, DT64>(src1, vreg_file, rsrc0, rdest, vl, vmask, vxrm, vxsat);
    break;
  default:
    std::cout << "Failed to execute VI/VX saturating for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT8, typename DT16, typename DT32, typename DT64>
void vector_op_vix_scale(Word src1, std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rdest, uint32_t vsew, uint32_t vl, uint32_t vmask, uint32_t vxrm, uint32_t &vxsat) {
  switch (vsew) {
  case 8:
    vector_op_vix_sat<OP, DT8, DT8>(src1, vreg_file, rsrc0, rdest, vl, vmask, vxrm, vxsat);
    break;
  case 16:
    vector_op_vix_sat<OP, DT16, DT16>(src1, vreg_file, rsrc0, rdest, vl, vmask, vxrm, vxsat);
    break;
  case 32:
    vector_op_vix_sat<OP, DT32, DT32>(src1, vreg_file, rsrc0, rdest, vl, vmask, vxrm, vxsat);
    break;
  case 64:
    vector_op_vix_sat<OP, DT64, DT64>(src1, vreg_file, rsrc0, rdest, vl, vmask, vxrm, vxsat);
    break;
  default:
    std::cout << "Failed to execute VI/VX scale for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <template <typename DT1, typename DT2> class OP>
void vector_op_vix_ext(Word src1, std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rdest, uint32_t vsew, uint32_t vl, uint32_t vmask) {
  if (vsew == 16) {
    switch (src1) {
    case 0b00110: // vzext.vf2
      vector_op_vix_w<OP, uint8_t, uint16_t>(src1, vreg_file, rsrc0, rdest, vl, vmask);
      break;
    case 0b00111: // vsext.vf2
      vector_op_vix_w<OP, int8_t, int16_t>(src1, vreg_file, rsrc0, rdest, vl, vmask);
      break;
    default:
      std::cout << "Xunary0 has unsupported value for vf: " << src1 << std::endl;
      std::abort();
    }
  } else if (vsew == 32) {
    switch (src1) {
    case 0b00100: // vzext.vf4
      vector_op_vix_w<OP, uint8_t, uint32_t>(src1, vreg_file, rsrc0, rdest, vl, vmask);
      break;
    case 0b00101: // vsext.vf4
      vector_op_vix_w<OP, int8_t, int32_t>(src1, vreg_file, rsrc0, rdest, vl, vmask);
      break;
    case 0b00110: // vzext.vf2
      vector_op_vix_w<OP, uint16_t, uint32_t>(src1, vreg_file, rsrc0, rdest, vl, vmask);
      break;
    case 0b00111: // vsext.vf2
      vector_op_vix_w<OP, int16_t, int32_t>(src1, vreg_file, rsrc0, rdest, vl, vmask);
      break;
    default:
      std::cout << "Xunary0 has unsupported value for vf: " << src1 << std::endl;
      std::abort();
    }
  } else if (vsew == 64) {
    switch (src1) {
    case 0b00010: // vzext.vf8
      vector_op_vix_w<OP, uint8_t, uint64_t>(src1, vreg_file, rsrc0, rdest, vl, vmask);
      break;
    case 0b00011: // vsext.vf8
      vector_op_vix_w<OP, int8_t, int64_t>(src1, vreg_file, rsrc0, rdest, vl, vmask);
      break;
    case 0b00100: // vzext.vf4
      vector_op_vix_w<OP, uint16_t, uint64_t>(src1, vreg_file, rsrc0, rdest, vl, vmask);
      break;
    case 0b00101: // vsext.vf4
      vector_op_vix_w<OP, int16_t, int64_t>(src1, vreg_file, rsrc0, rdest, vl, vmask);
      break;
    case 0b00110: // vzext.vf2
      vector_op_vix_w<OP, uint32_t, uint64_t>(src1, vreg_file, rsrc0, rdest, vl, vmask);
      break;
    case 0b00111: // vsext.vf2
      vector_op_vix_w<OP, int32_t, int64_t>(src1, vreg_file, rsrc0, rdest, vl, vmask);
      break;
    default:
      std::cout << "Xunary0 has unsupported value for vf: " << src1 << std::endl;
      std::abort();
    }
  } else {
    std::cout << "Failed to execute Xunary0 for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT>
void vector_op_vix_mask(DT first, std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rdest, uint32_t vl, uint32_t vmask) {
  for (uint32_t i = 0; i < vl; i++) {
    if (isMasked(vreg_file, 0, i, vmask))
      continue;

    DT second = getVregData<DT>(vreg_file, rsrc0, i);
    bool result = OP<DT, bool>::apply(first, second, 0);
    DP(4, "Integer/float compare mask " << (OP<DT, bool>::name()) << "(" << +first << ", " << +second << ")" << " = " << +result);
    if (result) {
      getVregData<uint8_t>(vreg_file, rdest, i / 8) |= 1 << (i % 8);
    } else {
      getVregData<uint8_t>(vreg_file, rdest, i / 8) &= ~(1 << (i % 8));
    }
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT8, typename DT16, typename DT32, typename DT64>
void vector_op_vix_mask(Word src1, std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rdest, uint32_t vsew, uint32_t vl, uint32_t vmask) {
  switch (vsew) {
  case 8:
    vector_op_vix_mask<OP, DT8>(src1, vreg_file, rsrc0, rdest, vl, vmask);
    break;
  case 16:
    vector_op_vix_mask<OP, DT16>(src1, vreg_file, rsrc0, rdest, vl, vmask);
    break;
  case 32:
    vector_op_vix_mask<OP, DT32>(src1, vreg_file, rsrc0, rdest, vl, vmask);
    break;
  case 64:
    vector_op_vix_mask<OP, DT64>(src1, vreg_file, rsrc0, rdest, vl, vmask);
    break;
  default:
    std::cout << "Failed to execute VI/VX integer/float compare mask for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <typename DT>
void vector_op_vix_slide(Word first, std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rdest, uint32_t vl, Word vlmax, uint32_t vmask, bool scalar) {
  // If vlmax > 0 this means we have a vslidedown instruction, vslideup does not require vlmax
  bool slideDown = vlmax;
  uint32_t scalarPos = slideDown ? vl - 1 : 0;
  // If scalar set is set this means we have a v(f)slide1up or v(f)slide1down instruction,
  // so first is our scalar value and we need to overwrite it with 1 for later computations
  if (scalar && vl && !isMasked(vreg_file, 0, scalarPos, vmask)) {
    DP(4, "Slide - Moving scalar value " << +first << " to position " << +scalarPos);
    getVregData<DT>(vreg_file, rdest, scalarPos) = first;
  }
  first = scalar ? 1 : first;

  for (Word i = slideDown ? 0 : first; i < vl - (scalar && vl && slideDown); i++) {
    if (isMasked(vreg_file, 0, i, vmask))
      continue;

    __uint128_t iSrc = slideDown ? (__uint128_t)i + (__uint128_t)first : (__uint128_t)i - (__uint128_t)first; // prevent overflows/underflows
    DT value = (!slideDown || iSrc < vlmax) ? getVregData<DT>(vreg_file, rsrc0, iSrc) : 0;
    DP(4, "Slide - Moving value " << +value << " from position " << (uint64_t)iSrc << " to position " << +i);
    getVregData<DT>(vreg_file, rdest, i) = value;
  }
}

template <typename DT8, typename DT16, typename DT32, typename DT64>
void vector_op_vix_slide(Word src1, std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rdest, uint32_t vsew, uint32_t vl, Word vlmax, uint32_t vmask, bool scalar) {
  switch (vsew) {
  case 8:
    vector_op_vix_slide<DT8>(src1, vreg_file, rsrc0, rdest, vl, vlmax, vmask, scalar);
    break;
  case 16:
    vector_op_vix_slide<DT16>(src1, vreg_file, rsrc0, rdest, vl, vlmax, vmask, scalar);
    break;
  case 32:
    vector_op_vix_slide<DT32>(src1, vreg_file, rsrc0, rdest, vl, vlmax, vmask, scalar);
    break;
  case 64:
    vector_op_vix_slide<DT64>(src1, vreg_file, rsrc0, rdest, vl, vlmax, vmask, scalar);
    break;
  default:
    std::cout << "Failed to execute VI/VX slide for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <typename DT>
void vector_op_vix_gather(Word first, std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rdest, uint32_t vl, Word vlmax, uint32_t vmask) {
  for (Word i = 0; i < vl; i++) {
    if (isMasked(vreg_file, 0, i, vmask))
      continue;

    DT value = first < vlmax ? getVregData<DT>(vreg_file, rsrc0, first) : 0;
    DP(4, "Register gather - Moving value " << +value << " from position " << +first << " to position " << +i);
    getVregData<DT>(vreg_file, rdest, i) = value;
  }
}

template <typename DT8, typename DT16, typename DT32, typename DT64>
void vector_op_vix_gather(Word src1, std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rdest, uint32_t vsew, uint32_t vl, Word vlmax, uint32_t vmask) {
  switch (vsew) {
  case 8:
    vector_op_vix_gather<DT8>(src1, vreg_file, rsrc0, rdest, vl, vlmax, vmask);
    break;
  case 16:
    vector_op_vix_gather<DT16>(src1, vreg_file, rsrc0, rdest, vl, vlmax, vmask);
    break;
  case 32:
    vector_op_vix_gather<DT32>(src1, vreg_file, rsrc0, rdest, vl, vlmax, vmask);
    break;
  case 64:
    vector_op_vix_gather<DT64>(src1, vreg_file, rsrc0, rdest, vl, vlmax, vmask);
    break;
  default:
    std::cout << "Failed to execute VI/VX register gather for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT>
void vector_op_vv(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vl, uint32_t vmask) {
  for (uint32_t i = 0; i < vl; i++) {
    if (isMasked(vreg_file, 0, i, vmask))
      continue;

    DT first = getVregData<DT>(vreg_file, rsrc0, i);
    DT second = getVregData<DT>(vreg_file, rsrc1, i);
    DT third = getVregData<DT>(vreg_file, rdest, i);
    DT result = OP<DT, DT>::apply(first, second, third);
    DP(4, (OP<DT, DT>::name()) << "(" << +first << ", " << +second << ", " << +third << ")" << " = " << +result);
    getVregData<DT>(vreg_file, rdest, i) = result;
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT8, typename DT16, typename DT32, typename DT64>
void vector_op_vv(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vsew, uint32_t vl, uint32_t vmask) {
  switch (vsew) {
  case 8:
    vector_op_vv<OP, DT8>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
    break;
  case 16:
    vector_op_vv<OP, DT16>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
    break;
  case 32:
    vector_op_vv<OP, DT32>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
    break;
  case 64:
    vector_op_vv<OP, DT64>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
    break;
  default:
    std::cout << "Failed to execute VV for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT>
void vector_op_vv_carry(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vl) {
  for (uint32_t i = 0; i < vl; i++) {
    DT first = getVregData<DT>(vreg_file, rsrc0, i);
    DT second = getVregData<DT>(vreg_file, rsrc1, i);
    bool third = !isMasked(vreg_file, 0, i, false);
    DT result = OP<DT, DT>::apply(first, second, third);
    DP(4, (OP<DT, DT>::name()) << "(" << +first << ", " << +second << ", " << +third << ")" << " = " << +result);
    getVregData<DT>(vreg_file, rdest, i) = result;
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT8, typename DT16, typename DT32, typename DT64>
void vector_op_vv_carry(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vsew, uint32_t vl) {
  switch (vsew) {
  case 8:
    vector_op_vv_carry<OP, DT8>(vreg_file, rsrc0, rsrc1, rdest, vl);
    break;
  case 16:
    vector_op_vv_carry<OP, DT16>(vreg_file, rsrc0, rsrc1, rdest, vl);
    break;
  case 32:
    vector_op_vv_carry<OP, DT32>(vreg_file, rsrc0, rsrc1, rdest, vl);
    break;
  case 64:
    vector_op_vv_carry<OP, DT64>(vreg_file, rsrc0, rsrc1, rdest, vl);
    break;
  default:
    std::cout << "Failed to execute VV carry for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT, typename DTR>
void vector_op_vv_carry_out(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vl, uint32_t vmask) {
  for (uint32_t i = 0; i < vl; i++) {
    DT first = getVregData<DT>(vreg_file, rsrc0, i);
    DT second = getVregData<DT>(vreg_file, rsrc1, i);
    bool third = !vmask && !isMasked(vreg_file, 0, i, vmask);
    bool result = OP<DT, DTR>::apply(first, second, third);
    DP(4, (OP<DT, DT>::name()) << "(" << +first << ", " << +second << ", " << +third << ")" << " = " << +result);
    if (result) {
      getVregData<uint8_t>(vreg_file, rdest, i / 8) |= 1 << (i % 8);
    } else {
      getVregData<uint8_t>(vreg_file, rdest, i / 8) &= ~(1 << (i % 8));
    }
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT8, typename DT16, typename DT32, typename DT64, typename DT128>
void vector_op_vv_carry_out(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vsew, uint32_t vl, uint32_t vmask) {
  switch (vsew) {
  case 8:
    vector_op_vv_carry_out<OP, DT8, DT16>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
    break;
  case 16:
    vector_op_vv_carry_out<OP, DT16, DT32>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
    break;
  case 32:
    vector_op_vv_carry_out<OP, DT32, DT64>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
    break;
  case 64:
    vector_op_vv_carry_out<OP, DT64, DT128>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
    break;
  default:
    std::cout << "Failed to execute VV carry out for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <typename DT>
void vector_op_vv_merge(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vl, uint32_t vmask) {
  for (uint32_t i = 0; i < vl; i++) {
    uint32_t rsrc = isMasked(vreg_file, 0, i, vmask) ? rsrc1 : rsrc0;
    DT result = getVregData<DT>(vreg_file, rsrc, i);
    DP(4, "Merge - Choosing result: " << +result);
    getVregData<DT>(vreg_file, rdest, i) = result;
  }
}

template <typename DT8, typename DT16, typename DT32, typename DT64>
void vector_op_vv_merge(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vsew, uint32_t vl, uint32_t vmask) {
  switch (vsew) {
  case 8:
    vector_op_vv_merge<DT8>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
    break;
  case 16:
    vector_op_vv_merge<DT16>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
    break;
  case 32:
    vector_op_vv_merge<DT32>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
    break;
  case 64:
    vector_op_vv_merge<DT64>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
    break;
  default:
    std::cout << "Failed to execute VV for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <typename DT>
void vector_op_vv_gather(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vl, bool ei16, uint32_t vlmax, uint32_t vmask) {
  for (Word i = 0; i < vl; i++) {
    if (isMasked(vreg_file, 0, i, vmask))
      continue;

    uint32_t first = ei16 ? getVregData<uint16_t>(vreg_file, rsrc0, i) : getVregData<DT>(vreg_file, rsrc0, i);
    DT value = first < vlmax ? getVregData<DT>(vreg_file, rsrc1, first) : 0;
    DP(4, "Register gather - Moving value " << +value << " from position " << +first << " to position " << +i);
    getVregData<DT>(vreg_file, rdest, i) = value;
  }
}

template <typename DT8, typename DT16, typename DT32, typename DT64>
void vector_op_vv_gather(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vsew, uint32_t vl, bool ei16, uint32_t vlmax, uint32_t vmask) {
  switch (vsew) {
  case 8:
    vector_op_vv_gather<DT8>(vreg_file, rsrc0, rsrc1, rdest, vl, ei16, vlmax, vmask);
    break;
  case 16:
    vector_op_vv_gather<DT16>(vreg_file, rsrc0, rsrc1, rdest, vl, ei16, vlmax, vmask);
    break;
  case 32:
    vector_op_vv_gather<DT32>(vreg_file, rsrc0, rsrc1, rdest, vl, ei16, vlmax, vmask);
    break;
  case 64:
    vector_op_vv_gather<DT64>(vreg_file, rsrc0, rsrc1, rdest, vl, ei16, vlmax, vmask);
    break;
  default:
    std::cout << "Failed to execute VV register gather for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT, typename DTR>
void vector_op_vv_w(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vl, uint32_t vmask) {
  for (uint32_t i = 0; i < vl; i++) {
    if (isMasked(vreg_file, 0, i, vmask))
      continue;

    DT first = getVregData<DT>(vreg_file, rsrc0, i);
    DT second = getVregData<DT>(vreg_file, rsrc1, i);
    DTR third = getVregData<DTR>(vreg_file, rdest, i);
    DTR result = OP<DT, DTR>::apply(first, second, third);
    DP(4, "Widening " << (OP<DT, DTR>::name()) << "(" << +first << ", " << +second << ", " << +third << ")" << " = " << +result);
    getVregData<DTR>(vreg_file, rdest, i) = result;
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT8, typename DT16, typename DT32, typename DT64>
void vector_op_vv_w(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vsew, uint32_t vl, uint32_t vmask) {
  switch (vsew) {
  case 8:
    vector_op_vv_w<OP, DT8, DT16>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
    break;
  case 16:
    vector_op_vv_w<OP, DT16, DT32>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
    break;
  case 32:
    vector_op_vv_w<OP, DT32, DT64>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
    break;
  default:
    std::cout << "Failed to execute VV widening for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT, typename DTR>
void vector_op_vv_wv(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vl, uint32_t vmask) {
  for (uint32_t i = 0; i < vl; i++) {
    if (isMasked(vreg_file, 0, i, vmask))
      continue;

    DT first = getVregData<DT>(vreg_file, rsrc0, i);
    DTR second = getVregData<DTR>(vreg_file, rsrc1, i);
    DTR third = getVregData<DTR>(vreg_file, rdest, i);
    DTR result = OP<DTR, DTR>::apply(first, second, third);
    DP(4, "Widening wv " << (OP<DT, DTR>::name()) << "(" << +first << ", " << +second << ", " << +third << ")" << " = " << +result);
    getVregData<DTR>(vreg_file, rdest, i) = result;
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT8, typename DT16, typename DT32, typename DT64>
void vector_op_vv_wv(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vsew, uint32_t vl, uint32_t vmask) {
  switch (vsew) {
  case 8:
    vector_op_vv_wv<OP, DT8, DT16>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
    break;
  case 16:
    vector_op_vv_wv<OP, DT16, DT32>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
    break;
  case 32:
    vector_op_vv_wv<OP, DT32, DT64>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
    break;
  default:
    std::cout << "Failed to execute VV widening wv for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT, typename DTR>
void vector_op_vv_wfv(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vl, uint32_t vmask) {
  for (uint32_t i = 0; i < vl; i++) {
    if (isMasked(vreg_file, 0, i, vmask))
      continue;

    DT first = getVregData<DT>(vreg_file, rsrc0, i);
    DTR second = getVregData<DTR>(vreg_file, rsrc1, i);
    DTR third = getVregData<DTR>(vreg_file, rdest, i);
    DTR result = OP<DTR, DTR>::apply(rv_ftod(first), second, third);
    DP(4, "Widening wfv " << (OP<DT, DTR>::name()) << "(" << +first << ", " << +second << ", " << +third << ")" << " = " << +result);
    getVregData<DTR>(vreg_file, rdest, i) = result;
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT8, typename DT16, typename DT32, typename DT64>
void vector_op_vv_wfv(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vsew, uint32_t vl, uint32_t vmask) {
  if (vsew == 32) {
    vector_op_vv_wfv<OP, DT32, DT64>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
  } else {
    std::cout << "Failed to execute VV widening wfv for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT, typename DTR>
void vector_op_vv_n(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vl, uint32_t vmask, uint32_t vxrm, uint32_t &vxsat) {
  for (uint32_t i = 0; i < vl; i++) {
    if (isMasked(vreg_file, 0, i, vmask))
      continue;

    DTR first = getVregData<DTR>(vreg_file, rsrc0, i);
    DT second = getVregData<DT>(vreg_file, rsrc1, i);
    DTR result = OP<DT, DTR>::apply(first, second, vxrm, vxsat);
    DP(4, "Narrowing " << (OP<DT, DTR>::name()) << "(" << +first << ", " << +second << ")" << " = " << +result);
    getVregData<DTR>(vreg_file, rdest, i) = result;
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT8, typename DT16, typename DT32, typename DT64>
void vector_op_vv_n(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vsew, uint32_t vl, uint32_t vmask, uint32_t vxrm, uint32_t &vxsat) {
  switch (vsew) {
  case 8:
    vector_op_vv_n<OP, DT16, DT8>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask, vxrm, vxsat);
    break;
  case 16:
    vector_op_vv_n<OP, DT32, DT16>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask, vxrm, vxsat);
    break;
  case 32:
    vector_op_vv_n<OP, DT64, DT32>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask, vxrm, vxsat);
    break;
  default:
    std::cout << "Failed to execute VV narrowing for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT, typename DTR>
void vector_op_vv_sat(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vl, uint32_t vmask, uint32_t vxrm, uint32_t &vxsat) {
  for (uint32_t i = 0; i < vl; i++) {
    if (isMasked(vreg_file, 0, i, vmask))
      continue;

    DT first = getVregData<DTR>(vreg_file, rsrc0, i);
    DT second = getVregData<DTR>(vreg_file, rsrc1, i);
    DTR result = OP<DT, DTR>::apply(first, second, vxrm, vxsat);
    DP(4, "Saturating " << (OP<DT, DTR>::name()) << "(" << +(DTR)first << ", " << +(DTR)second << ")" << " = " << +(DTR)result);
    getVregData<DTR>(vreg_file, rdest, i) = result;
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT8, typename DT16, typename DT32, typename DT64, typename DT128>
void vector_op_vv_sat(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vsew, uint32_t vl, uint32_t vmask, uint32_t vxrm, uint32_t &vxsat) {
  switch (vsew) {
  case 8:
    vector_op_vv_sat<OP, DT16, DT8>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask, vxrm, vxsat);
    break;
  case 16:
    vector_op_vv_sat<OP, DT32, DT16>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask, vxrm, vxsat);
    break;
  case 32:
    vector_op_vv_sat<OP, DT64, DT32>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask, vxrm, vxsat);
    break;
  case 64:
    vector_op_vv_sat<OP, DT128, DT64>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask, vxrm, vxsat);
    break;
  default:
    std::cout << "Failed to execute VV saturating for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT8, typename DT16, typename DT32, typename DT64>
void vector_op_vv_scale(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vsew, uint32_t vl, uint32_t vmask, uint32_t vxrm, uint32_t &vxsat) {
  switch (vsew) {
  case 8:
    vector_op_vv_sat<OP, DT8, DT8>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask, vxrm, vxsat);
    break;
  case 16:
    vector_op_vv_sat<OP, DT16, DT16>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask, vxrm, vxsat);
    break;
  case 32:
    vector_op_vv_sat<OP, DT32, DT32>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask, vxrm, vxsat);
    break;
  case 64:
    vector_op_vv_sat<OP, DT64, DT64>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask, vxrm, vxsat);
    break;
  default:
    std::cout << "Failed to execute VV scale for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT>
void vector_op_vv_red(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vl, uint32_t vmask) {
  for (uint32_t i = 0; i < vl; i++) {
    // use rdest as accumulator
    if (i == 0) {
      getVregData<DT>(vreg_file, rdest, 0) = getVregData<DT>(vreg_file, rsrc0, 0);
    }
    if (isMasked(vreg_file, 0, i, vmask))
      continue;

    DT first = getVregData<DT>(vreg_file, rdest, 0);
    DT second = getVregData<DT>(vreg_file, rsrc1, i);
    DT result = OP<DT, DT>::apply(first, second, 0);
    DP(4, "Reduction " << (OP<DT, DT>::name()) << "(" << +first << ", " << +second << ")" << " = " << +result);
    getVregData<DT>(vreg_file, rdest, 0) = result;
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT8, typename DT16, typename DT32, typename DT64>
void vector_op_vv_red(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vsew, uint32_t vl, uint32_t vmask) {
  switch (vsew) {
  case 8:
    vector_op_vv_red<OP, DT8>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
    break;
  case 16:
    vector_op_vv_red<OP, DT16>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
    break;
  case 32:
    vector_op_vv_red<OP, DT32>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
    break;
  case 64:
    vector_op_vv_red<OP, DT64>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
    break;
  default:
    std::cout << "Failed to execute VV reduction for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT, typename DTR>
void vector_op_vv_red_w(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vl, uint32_t vmask) {
  for (uint32_t i = 0; i < vl; i++) {
    // use rdest as accumulator
    if (i == 0) {
      getVregData<DTR>(vreg_file, rdest, 0) = getVregData<DTR>(vreg_file, rsrc0, 0);
    }
    if (isMasked(vreg_file, 0, i, vmask))
      continue;

    DTR first = getVregData<DTR>(vreg_file, rdest, 0);
    DT second = getVregData<DT>(vreg_file, rsrc1, i);
    DTR second_w = std::is_signed<DT>() ? sext((DTR)second, sizeof(DT) * 8) : zext((DTR)second, sizeof(DT) * 8);
    DTR result = OP<DTR, DTR>::apply(first, second_w, 0);
    DP(4, "Widening reduction " << (OP<DTR, DTR>::name()) << "(" << +first << ", " << +second_w << ")" << " = " << +result);
    getVregData<DTR>(vreg_file, rdest, 0) = result;
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT8, typename DT16, typename DT32, typename DT64>
void vector_op_vv_red_w(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vsew, uint32_t vl, uint32_t vmask) {
  switch (vsew) {
  case 8:
    vector_op_vv_red_w<OP, DT8, DT16>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
    break;
  case 16:
    vector_op_vv_red_w<OP, DT16, DT32>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
    break;
  case 32:
    vector_op_vv_red_w<OP, DT32, DT64>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
    break;
  default:
    std::cout << "Failed to execute VV widening reduction for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT, typename DTR>
void vector_op_vv_red_wf(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vl, uint32_t vmask) {
  for (uint32_t i = 0; i < vl; i++) {
    // use rdest as accumulator
    if (i == 0) {
      getVregData<DTR>(vreg_file, rdest, 0) = getVregData<DTR>(vreg_file, rsrc0, 0);
    }
    if (isMasked(vreg_file, 0, i, vmask))
      continue;

    DTR first = getVregData<DTR>(vreg_file, rdest, 0);
    DT second = getVregData<DT>(vreg_file, rsrc1, i);
    DTR second_w = rv_ftod(second);
    DTR result = OP<DTR, DTR>::apply(first, second_w, 0);
    DP(4, "Float widening reduction " << (OP<DTR, DTR>::name()) << "(" << +first << ", " << +second_w << ")" << " = " << +result);
    getVregData<DTR>(vreg_file, rdest, 0) = result;
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT8, typename DT16, typename DT32, typename DT64>
void vector_op_vv_red_wf(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vsew, uint32_t vl, uint32_t vmask) {
  if (vsew == 32) {
    vector_op_vv_red_wf<OP, DT32, DT64>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
  } else {
    std::cout << "Failed to execute VV float widening reduction for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <typename DT>
void vector_op_vid(std::vector<std::vector<Byte>> &vreg_file, uint32_t rdest, uint32_t vl, uint32_t vmask) {
  for (uint32_t i = 0; i < vl; i++) {
    if (isMasked(vreg_file, 0, i, vmask))
      continue;

    DP(4, "Element Index = " << +i);
    getVregData<DT>(vreg_file, rdest, i) = i;
  }
}

void vector_op_vid(std::vector<std::vector<Byte>> &vreg_file, uint32_t rdest, uint32_t vsew, uint32_t vl, uint32_t vmask) {
  switch (vsew) {
  case 8:
    vector_op_vid<uint8_t>(vreg_file, rdest, vl, vmask);
    break;
  case 16:
    vector_op_vid<uint16_t>(vreg_file, rdest, vl, vmask);
    break;
  case 32:
    vector_op_vid<uint32_t>(vreg_file, rdest, vl, vmask);
    break;
  case 64:
    vector_op_vid<uint64_t>(vreg_file, rdest, vl, vmask);
    break;
  default:
    std::cout << "Failed to execute vector element index for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT>
void vector_op_vv_mask(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vl, uint32_t vmask) {
  for (uint32_t i = 0; i < vl; i++) {
    if (isMasked(vreg_file, 0, i, vmask))
      continue;

    DT first = getVregData<DT>(vreg_file, rsrc0, i);
    DT second = getVregData<DT>(vreg_file, rsrc1, i);
    bool result = OP<DT, bool>::apply(first, second, 0);
    DP(4, "Integer/float compare mask " << (OP<DT, bool>::name()) << "(" << +first << ", " << +second << ")" << " = " << +result);
    if (result) {
      getVregData<uint8_t>(vreg_file, rdest, i / 8) |= 1 << (i % 8);
    } else {
      getVregData<uint8_t>(vreg_file, rdest, i / 8) &= ~(1 << (i % 8));
    }
  }
}

template <template <typename DT1, typename DT2> class OP, typename DT8, typename DT16, typename DT32, typename DT64>
void vector_op_vv_mask(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vsew, uint32_t vl, uint32_t vmask) {
  switch (vsew) {
  case 8:
    vector_op_vv_mask<OP, DT8>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
    break;
  case 16:
    vector_op_vv_mask<OP, DT16>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
    break;
  case 32:
    vector_op_vv_mask<OP, DT32>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
    break;
  case 64:
    vector_op_vv_mask<OP, DT64>(vreg_file, rsrc0, rsrc1, rdest, vl, vmask);
    break;
  default:
    std::cout << "Failed to execute VV integer/float compare mask for vsew: " << vsew << std::endl;
    std::abort();
  }
}

template <template <typename DT1, typename DT2> class OP>
void vector_op_vv_mask(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vl) {
  for (uint32_t i = 0; i < vl; i++) {
    uint8_t firstMask = getVregData<uint8_t>(vreg_file, rsrc0, i / 8);
    bool first = (firstMask >> (i % 8)) & 0x1;
    uint8_t secondMask = getVregData<uint8_t>(vreg_file, rsrc1, i / 8);
    bool second = (secondMask >> (i % 8)) & 0x1;
    bool result = OP<uint8_t, uint8_t>::apply(first, second, 0) & 0x1;
    DP(4, "Compare mask bits " << (OP<uint8_t, uint8_t>::name()) << "(" << +first << ", " << +second << ")" << " = " << +result);
    if (result) {
      getVregData<uint8_t>(vreg_file, rdest, i / 8) |= 1 << (i % 8);
    } else {
      getVregData<uint8_t>(vreg_file, rdest, i / 8) &= ~(1 << (i % 8));
    }
  }
}

template <typename DT>
void vector_op_vv_compress(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vl) {
  int currPos = 0;
  for (uint32_t i = 0; i < vl; i++) {
    // Special case: use rsrc0 as mask vector register instead of default v0
    // This instruction is always masked (vmask == 0), but encoded as unmasked (vmask == 1)
    if (isMasked(vreg_file, rsrc0, i, 0))
      continue;

    DT value = getVregData<DT>(vreg_file, rsrc1, i);
    DP(4, "Compression - Moving value " << +value << " from position " << i << " to position " << currPos);
    getVregData<DT>(vreg_file, rdest, currPos) = value;
    currPos++;
  }
}

template <typename DT8, typename DT16, typename DT32, typename DT64>
void vector_op_vv_compress(std::vector<std::vector<Byte>> &vreg_file, uint32_t rsrc0, uint32_t rsrc1, uint32_t rdest, uint32_t vsew, uint32_t vl) {
  switch (vsew) {
  case 8:
    vector_op_vv_compress<DT8>(vreg_file, rsrc0, rsrc1, rdest, vl);
    break;
  case 16:
    vector_op_vv_compress<DT16>(vreg_file, rsrc0, rsrc1, rdest, vl);
    break;
  case 32:
    vector_op_vv_compress<DT32>(vreg_file, rsrc0, rsrc1, rdest, vl);
    break;
  case 64:
    vector_op_vv_compress<DT64>(vreg_file, rsrc0, rsrc1, rdest, vl);
    break;
  default:
    std::cout << "Failed to execute VV compression for vsew: " << vsew << std::endl;
    std::abort();
  }
}
#endif
// --- End of content from sim/simx/vpu.h ---

// --- Start of content from sim/simx/core.h ---
// Original pragma: #pragma once
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


#include <vector>
#include <simobject.h>
// MERGED_LOCALLY: #include "types.h"
// MERGED_LOCALLY: #include "emulator.h"
// MERGED_LOCALLY: #include "pipeline.h"
// MERGED_LOCALLY: #include "cache_sim.h"
// MERGED_LOCALLY: #include "local_mem.h"
// MERGED_LOCALLY: #include "ibuffer.h"
// MERGED_LOCALLY: #include "scoreboard.h"
// MERGED_LOCALLY: #include "operand.h"
// MERGED_LOCALLY: #include "dispatcher.h"
// MERGED_LOCALLY: #include "func_unit.h"
// MERGED_LOCALLY: #include "mem_coalescer.h"
// MERGED_LOCALLY: #include "VX_config.h"

namespace vortex {

class Socket;
class Arch;
class DCRS;

using TraceArbiter = Arbiter<instr_trace_t*>;

class Core : public SimObject<Core> {
public:
  struct PerfStats {
    uint64_t cycles;
    uint64_t instrs;
    uint64_t sched_idle;
    uint64_t sched_stalls;
    uint64_t ibuf_stalls;
    uint64_t scrb_stalls;
    uint64_t opds_stalls;
    uint64_t scrb_alu;
    uint64_t scrb_fpu;
    uint64_t scrb_lsu;
    uint64_t scrb_sfu;
    uint64_t scrb_csrs;
    uint64_t scrb_wctl;
    uint64_t ifetches;
    uint64_t loads;
    uint64_t stores;
    uint64_t ifetch_latency;
    uint64_t load_latency;
    uint64_t total_issued_warps;
    uint64_t total_active_threads;
    

    PerfStats()
      : cycles(0)
      , instrs(0)
      , sched_idle(0)
      , sched_stalls(0)
      , ibuf_stalls(0)
      , scrb_stalls(0)
      , opds_stalls(0)
      , scrb_alu(0)
      , scrb_fpu(0)
      , scrb_lsu(0)
      , scrb_sfu(0)
      , scrb_csrs(0)
      , scrb_wctl(0)
      , ifetches(0)
      , loads(0)
      , stores(0)
      , ifetch_latency(0)
      , load_latency(0)
      , total_issued_warps(0)
      , total_active_threads(0)
    {}
  };

  std::vector<SimPort<MemReq>> icache_req_ports;
  std::vector<SimPort<MemRsp>> icache_rsp_ports;

  std::vector<SimPort<MemReq>> dcache_req_ports;
  std::vector<SimPort<MemRsp>> dcache_rsp_ports;

  Core(const SimContext& ctx,
       uint32_t core_id,
       Socket* socket,
       const Arch &arch,
       const DCRS &dcrs);

  ~Core();

  void reset();

  void tick();

  void attach_ram(RAM* ram);
#ifdef VM_ENABLE
  void set_satp(uint64_t satp);
#endif

  bool running() const;

  void resume(uint32_t wid);

  bool barrier(uint32_t bar_id, uint32_t count, uint32_t wid);

  bool wspawn(uint32_t num_warps, Word nextPC);

  uint32_t id() const {
    return core_id_;
  }

  const Arch& arch() const {
    return arch_;
  }

  Socket* socket() const {
    return socket_;
  }

  const LocalMem::Ptr& local_mem() const {
    return local_mem_;
  }

  const MemCoalescer::Ptr& mem_coalescer(uint32_t idx) const {
    return mem_coalescers_.at(idx);
  }

  const PerfStats& perf_stats() const {
    return perf_stats_;
  }

  int get_exitcode() const;

private:

  void schedule();
  void fetch();
  void decode();
  void issue();
  void execute();
  void commit();

  uint32_t core_id_;
  Socket* socket_;
  const Arch& arch_;

  Emulator emulator_;

  std::vector<IBuffer> ibuffers_;
  Scoreboard scoreboard_;
  std::vector<Operand::Ptr> operands_;
  std::vector<Dispatcher::Ptr> dispatchers_;
  std::vector<FuncUnit::Ptr> func_units_;
  LocalMem::Ptr local_mem_;
  std::vector<LocalMemSwitch::Ptr> lmem_switch_;
  std::vector<MemCoalescer::Ptr> mem_coalescers_;

  PipelineLatch fetch_latch_;
  PipelineLatch decode_latch_;

  HashTable<instr_trace_t*> pending_icache_;
  uint64_t pending_instrs_;

  uint64_t pending_ifetches_;

  PerfStats perf_stats_;

  std::vector<TraceArbiter::Ptr> commit_arbs_;

  uint32_t commit_exe_;
  uint32_t ibuffer_idx_;

  friend class LsuUnit;
  friend class AluUnit;
  friend class FpuUnit;
  friend class SfuUnit;
  friend class TcuUnit;
};

} // namespace vortex
// --- End of content from sim/simx/core.h ---

// --- Start of content from sim/simx/processor_impl.h ---
// Original pragma: #pragma once
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


// MERGED_LOCALLY: #include "mem_sim.h"
// MERGED_LOCALLY: #include "cache_sim.h"
// MERGED_LOCALLY: #include "constants.h"
// MERGED_LOCALLY: #include "dcrs.h"
// MERGED_LOCALLY: #include "cluster.h"

namespace vortex {

class ProcessorImpl {
public:
  struct PerfStats {
    CacheSim::PerfStats l3cache;
    MemSim::PerfStats memsim;
    uint64_t mem_reads;
    uint64_t mem_writes;
    uint64_t mem_latency;
  };

  ProcessorImpl(const Arch& arch);
  ~ProcessorImpl();

  void attach_ram(RAM* mem);

  int run();

  void dcr_write(uint32_t addr, uint32_t value);

#ifdef VM_ENABLE
  void set_satp(uint64_t satp);
#endif

  PerfStats perf_stats() const;

private:

  void reset();

  const Arch& arch_;
  std::vector<std::shared_ptr<Cluster>> clusters_;
  DCRS dcrs_;
  MemSim::Ptr memsim_;
  CacheSim::Ptr l3cache_;
  uint64_t perf_mem_reads_;
  uint64_t perf_mem_writes_;
  uint64_t perf_mem_latency_;
  uint64_t perf_mem_pending_reads_;
};

}
// --- End of content from sim/simx/processor_impl.h ---

// --- Start of content from sim/simx/cache_cluster.h ---
// Original pragma: #pragma once
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


// MERGED_LOCALLY: #include "cache_sim.h"

namespace vortex {

class CacheCluster : public SimObject<CacheCluster> {
public:
	std::vector<std::vector<SimPort<MemReq>>> CoreReqPorts;
	std::vector<std::vector<SimPort<MemRsp>>> CoreRspPorts;
	std::vector<SimPort<MemReq>> MemReqPorts;
	std::vector<SimPort<MemRsp>> MemRspPorts;

	CacheCluster(const SimContext& ctx,
							const char* name,
							uint32_t num_inputs,
							uint32_t num_units,
							const CacheSim::Config& cache_config)
		: SimObject(ctx, name)
		, CoreReqPorts(num_inputs, std::vector<SimPort<MemReq>>(cache_config.num_inputs, this))
		, CoreRspPorts(num_inputs, std::vector<SimPort<MemRsp>>(cache_config.num_inputs, this))
		, MemReqPorts(cache_config.mem_ports, this)
		, MemRspPorts(cache_config.mem_ports, this)
		, caches_(MAX(num_units, 0x1)) {

		CacheSim::Config cache_config2(cache_config);
		if (0 == num_units) {
			num_units = 1;
			cache_config2.bypass = true;
		}

		char sname[100];

		// Arbitrate incoming core interfaces
		std::vector<MemArbiter::Ptr> input_arbs(cache_config.num_inputs);
		for (uint32_t i = 0; i < cache_config.num_inputs; ++i) {
			snprintf(sname, 100, "%s-input-arb%d", name, i);
			input_arbs.at(i) = MemArbiter::Create(sname, ArbiterType::RoundRobin, num_inputs, num_units);
			for (uint32_t j = 0; j < num_inputs; ++j) {
				this->CoreReqPorts.at(j).at(i).bind(&input_arbs.at(i)->ReqIn.at(j));
				input_arbs.at(i)->RspIn.at(j).bind(&this->CoreRspPorts.at(j).at(i));
			}
		}

		// Arbitrate outgoing memory interfaces
		std::vector<MemArbiter::Ptr> mem_arbs(cache_config.mem_ports);
		for (uint32_t i = 0; i < cache_config.mem_ports; ++i) {
			snprintf(sname, 100, "%s-mem-arb%d", name, i);
			mem_arbs.at(i) = MemArbiter::Create(sname, ArbiterType::RoundRobin, num_units, 1);
			mem_arbs.at(i)->ReqOut.at(0).bind(&this->MemReqPorts.at(i));
			this->MemRspPorts.at(i).bind(&mem_arbs.at(i)->RspOut.at(0));
		}

		// Connect caches
		for (uint32_t i = 0; i < num_units; ++i) {
			snprintf(sname, 100, "%s-cache%d", name, i);
			caches_.at(i) = CacheSim::Create(sname, cache_config2);

			for (uint32_t j = 0; j < cache_config.num_inputs; ++j) {
				input_arbs.at(j)->ReqOut.at(i).bind(&caches_.at(i)->CoreReqPorts.at(j));
				caches_.at(i)->CoreRspPorts.at(j).bind(&input_arbs.at(j)->RspOut.at(i));
			}

			for (uint32_t j = 0; j < cache_config.mem_ports; ++j) {
				caches_.at(i)->MemReqPorts.at(j).bind(&mem_arbs.at(j)->ReqIn.at(i));
				mem_arbs.at(j)->RspIn.at(i).bind(&caches_.at(i)->MemRspPorts.at(j));
			}
		}
	}

	~CacheCluster() {}

	void reset() {}

	void tick() {}

	CacheSim::PerfStats perf_stats() const {
		CacheSim::PerfStats perf;
		for (auto cache : caches_) {
			perf += cache->perf_stats();
		}
		return perf;
	}

private:
  std::vector<CacheSim::Ptr> caches_;
};

}
// --- End of content from sim/simx/cache_cluster.h ---

// --- Start of content from sim/simx/processor.h ---
// Original pragma: #pragma once
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


#include <stdint.h>
#include <VX_config.h>
#include <mem.h>

namespace vortex {

class Arch;
class RAM;
class ProcessorImpl;
#ifdef VM_ENABLE
class SATP_t;
#endif

class Processor {
public:
  Processor(const Arch& arch);
  ~Processor();

  void attach_ram(RAM* mem);

  int run();

  void dcr_write(uint32_t addr, uint32_t value);
#ifdef VM_ENABLE
  bool is_satp_unset();
  uint8_t get_satp_mode();
  uint64_t get_base_ppn();
  int16_t set_satp_by_addr(uint64_t addr);
#endif

private:
  ProcessorImpl* impl_;
#ifdef VM_ENABLE
  SATP_t *satp_;
#endif
};

}
// --- End of content from sim/simx/processor.h ---

// --- Start of content from sim/simx/instr.h ---
// Original pragma: #pragma once
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


// MERGED_LOCALLY: #include "types.h"

namespace vortex {

enum class Opcode {
  NONE      = 0,
  R         = 0x33,
  L         = 0x3,
  I         = 0x13,
  S         = 0x23,
  B         = 0x63,
  LUI       = 0x37,
  AUIPC     = 0x17,
  JAL       = 0x6f,
  JALR      = 0x67,
  SYS       = 0x73,
  FENCE     = 0x0f,
  AMO       = 0x2f,
  // F Extension
  FL        = 0x7,
  FS        = 0x27,
  FCI       = 0x53,
  FMADD     = 0x43,
  FMSUB     = 0x47,
  FMNMSUB   = 0x4b,
  FMNMADD   = 0x4f,
  // RV64 Standard Extension
  R_W       = 0x3b,
  I_W       = 0x1b,
  // Vector Extension
  VSET      = 0x57,
  // Custom Extensions
  EXT1      = 0x0b,
  EXT2      = 0x2b,
  EXT3      = 0x5b,
  TCU       = 0x7b
};

enum class InstType {
  R,
  I,
  S,
  B,
  U,
  J,
  V,
  R4
};

enum DecodeConstants {
  width_opcode= 7,
  width_reg   = 5,
  width_func2 = 2,
  width_func3 = 3,
  width_func6 = 6,
  width_func7 = 7,
  width_mop   = 3,
  width_vmask = 1,
  width_i_imm = 12,
  width_j_imm = 20,
  width_v_zimm = 11,
  width_v_ma = 1,
  width_v_ta = 1,
  width_v_sew = 3,
  width_v_lmul = 3,
  width_aq    = 1,
  width_rl    = 1,

  shift_opcode= 0,
  shift_rd    = width_opcode,
  shift_func3 = shift_rd + width_reg,
  shift_rs1   = shift_func3 + width_func3,
  shift_rs2   = shift_rs1 + width_reg,
  shift_func2 = shift_rs2 + width_reg,
  shift_func7 = shift_rs2 + width_reg,
  shift_rs3   = shift_func7 + width_func2,
  shift_vmop  = shift_func7 + width_vmask,
  shift_vnf   = shift_vmop + width_mop,
  shift_func6 = shift_func7 + width_vmask,
  shift_vset  = shift_func7 + width_func6,
  shift_v_sew = width_v_lmul,
  shift_v_ta  = shift_v_sew + width_v_sew,
  shift_v_ma  = shift_v_ta + width_v_ta,

  mask_opcode = (1 << width_opcode) - 1,
  mask_reg    = (1 << width_reg)   - 1,
  mask_func2  = (1 << width_func2) - 1,
  mask_func3  = (1 << width_func3) - 1,
  mask_func6  = (1 << width_func6) - 1,
  mask_func7  = (1 << width_func7) - 1,
  mask_i_imm  = (1 << width_i_imm) - 1,
  mask_j_imm  = (1 << width_j_imm) - 1,
  mask_v_zimm = (1 << width_v_zimm) - 1,
  mask_v_ma   = (1 << width_v_ma) - 1,
  mask_v_ta   = (1 << width_v_ta) - 1,
  mask_v_sew  = (1 << width_v_sew) - 1,
  mask_v_lmul = (1 << width_v_lmul) - 1,
};

enum VectorAttrMask {
  vattr_vlswidth = (1 << 0),
  vattr_vmop     = (1 << 1),
  vattr_vumop    = (1 << 2),
  vattr_vnf      = (1 << 3),
  vattr_vmask    = (1 << 4),
  vattr_vs3      = (1 << 5),
  vattr_zimm     = (1 << 6),
  vattr_vlmul    = (1 << 7),
  vattr_vsew     = (1 << 8),
  vattr_vta      = (1 << 9),
  vattr_vma      = (1 << 10),
  vattr_vediv    = (1 << 11)
};

class Instr {
public:
  Instr()
    : opcode_(Opcode::NONE)
    , num_rsrcs_(0)
    , has_imm_(false)
    , rdest_type_(RegType::None)
    , imm_(0)
    , rdest_(0)
    , func2_(0)
    , func3_(0)
    , func6_(0)
    , func7_(0)
    , vmask_(0)
    , vlsWidth_(0)
    , vMop_(0)
    , vUmop_(0)
    , vNf_(0)
    , vs3_(0)
    , has_zimm_(false)
    , vlmul_(0)
    , vsew_(0)
    , vta_(0)
    , vma_(0)
    , vediv_(0)
    , vattr_mask_(0) {
    for (uint32_t i = 0; i < MAX_REG_SOURCES; ++i) {
       rsrc_type_[i] = RegType::None;
       rsrc_[i] = 0;
    }
  }

  void setOpcode(Opcode opcode) {
    opcode_ = opcode;
  }

  void setDestReg(uint32_t destReg, RegType type) {
    rdest_type_ = type;
    rdest_ = destReg;
  }

  void addSrcReg(uint32_t srcReg, RegType type) {
    rsrc_type_[num_rsrcs_] = type;
    rsrc_[num_rsrcs_] = srcReg;
    ++num_rsrcs_;
  }

  void setSrcReg(uint32_t index, uint32_t srcReg, RegType type) {
    rsrc_type_[index] = type;
    rsrc_[index] = srcReg;
    num_rsrcs_ = std::max<uint32_t>(num_rsrcs_, index+1);
  }

  void setImm(uint32_t imm) { has_imm_ = true; imm_ = imm; }

  void setFunc2(uint32_t func2) { func2_ = func2; }
  void setFunc3(uint32_t func3) { func3_ = func3; }
  void setFunc6(uint32_t func6) { func6_ = func6; }
  void setFunc7(uint32_t func7) { func7_ = func7; }

  // Attributes for Vector instructions
  void setVlsWidth(uint32_t width) { vlsWidth_ = width; vattr_mask_ |= vattr_vlswidth; }
  void setVmop(uint32_t mop) { vMop_ = mop; vattr_mask_ |= vattr_vmop; }
  void setVumop(uint32_t umop) { vUmop_ = umop; vattr_mask_ |= vattr_vumop; }
  void setVnf(uint32_t nf) { vNf_ = nf; vattr_mask_ |= vattr_vnf; }
  void setVmask(uint32_t mask) { vmask_ = mask; vattr_mask_ |= vattr_vmask; }
  void setVs3(uint32_t vs) { vs3_ = vs; vattr_mask_ |= vattr_vs3; }
  void setZimm(bool has_zimm) { has_zimm_ = has_zimm; vattr_mask_ |= vattr_zimm; }
  void setVlmul(uint32_t lmul) { vlmul_ = lmul; vattr_mask_ |= vattr_vlmul; }
  void setVsew(uint32_t sew) { vsew_ = sew; vattr_mask_ |= vattr_vsew; }
  void setVta(uint32_t vta) { vta_ = vta; vattr_mask_ |= vattr_vta; }
  void setVma(uint32_t vma) { vma_ = vma; vattr_mask_ |= vattr_vma; }
  void setVediv(uint32_t ediv) { vediv_ = 1 << ediv; vattr_mask_ |= vattr_vediv; }

  Opcode   getOpcode() const { return opcode_; }

  uint32_t getNRSrc() const { return num_rsrcs_; }
  uint32_t getRSrc(uint32_t i) const { return rsrc_[i]; }
  RegType  getRSType(uint32_t i) const { return rsrc_type_[i]; }

  uint32_t getRDest() const { return rdest_; }
  RegType  getRDType() const { return rdest_type_; }

  bool     hasImm() const { return has_imm_; }
  uint32_t getImm() const { return imm_; }

  uint32_t getFunc2() const { return func2_; }
  uint32_t getFunc3() const { return func3_; }
  uint32_t getFunc6() const { return func6_; }
  uint32_t getFunc7() const { return func7_; }

  uint32_t getVlsWidth() const { return vlsWidth_; }
  uint32_t getVmop() const { return vMop_; }
  uint32_t getVumop() const { return vUmop_; }
  uint32_t getVnf() const { return vNf_; }
  uint32_t getVmask() const { return vmask_; }
  uint32_t getVs3() const { return vs3_; }
  bool     hasZimm() const { return has_zimm_; }
  uint32_t getVlmul() const { return vlmul_; }
  uint32_t getVsew() const { return vsew_; }
  uint32_t getVta() const { return vta_; }
  uint32_t getVma() const { return vma_; }
  uint32_t getVediv() const { return vediv_; }
  uint32_t getVattrMask() const { return vattr_mask_; }

private:

  enum {
    MAX_REG_SOURCES = 3
  };

  Opcode opcode_;
  uint32_t num_rsrcs_;
  bool has_imm_;
  RegType rdest_type_;
  uint32_t imm_;
  RegType rsrc_type_[MAX_REG_SOURCES];
  uint32_t rsrc_[MAX_REG_SOURCES];
  uint32_t rdest_;
  uint32_t func2_;
  uint32_t func3_;
  uint32_t func6_;
  uint32_t func7_;

  // Vector
  uint32_t vmask_;
  uint32_t vlsWidth_;
  uint32_t vMop_;
  uint32_t vUmop_;
  uint32_t vNf_;
  uint32_t vs3_;
  bool     has_zimm_;
  uint32_t vlmul_;
  uint32_t vsew_;
  uint32_t vta_;
  uint32_t vma_;
  uint32_t vediv_;
  uint32_t vattr_mask_;

  friend std::ostream &operator<<(std::ostream &, const Instr&);
};

}
// --- End of content from sim/simx/instr.h ---

// --- Start of content from sim/simx/cache_sim.h ---
// Original pragma: #pragma once
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


#include <simobject.h>
// MERGED_LOCALLY: #include "mem_sim.h"

namespace vortex {

class CacheSim : public SimObject<CacheSim> {
public:
	struct Config {
		bool    bypass;         // cache bypass
		uint8_t C;              // log2 cache size
		uint8_t L;              // log2 line size
		uint8_t W;              // log2 word size
		uint8_t A;              // log2 associativity
		uint8_t B;              // log2 number of banks
		uint8_t addr_width;     // word address bits
		uint8_t ports_per_bank; // number of ports per bank
		uint8_t num_inputs;     // number of inputs
		uint8_t mem_ports;      // memory ports
		bool    write_back;     // is write-back
		bool    write_reponse;  // enable write response
		uint16_t mshr_size;     // MSHR buffer size
		uint8_t latency;        // pipeline latency
	};

	struct PerfStats {
		uint64_t reads;
		uint64_t writes;
		uint64_t read_misses;
		uint64_t write_misses;
		uint64_t evictions;
		uint64_t pipeline_stalls;
		uint64_t bank_stalls;
		uint64_t mshr_stalls;
		uint64_t mem_latency;

		PerfStats()
			: reads(0)
			, writes(0)
			, read_misses(0)
			, write_misses(0)
			, evictions(0)
			, pipeline_stalls(0)
			, bank_stalls(0)
			, mshr_stalls(0)
			, mem_latency(0)
		{}

		PerfStats& operator+=(const PerfStats& rhs) {
			this->reads += rhs.reads;
			this->writes += rhs.writes;
			this->read_misses += rhs.read_misses;
			this->write_misses += rhs.write_misses;
			this->evictions += rhs.evictions;
			this->pipeline_stalls += rhs.pipeline_stalls;
			this->bank_stalls += rhs.bank_stalls;
			this->mshr_stalls += rhs.mshr_stalls;
			this->mem_latency += rhs.mem_latency;
			return *this;
		}
	};

	std::vector<SimPort<MemReq>> CoreReqPorts;
	std::vector<SimPort<MemRsp>> CoreRspPorts;
	std::vector<SimPort<MemReq>> MemReqPorts;
	std::vector<SimPort<MemRsp>> MemRspPorts;

	CacheSim(const SimContext& ctx, const char* name, const Config& config);
	~CacheSim();

	void reset();

	void tick();

	const PerfStats& perf_stats() const;

private:
	class Impl;
	Impl* impl_;
};

}
// --- End of content from sim/simx/cache_sim.h ---

// --- Start of content from sim/simx/cluster.h ---
// Original pragma: #pragma once
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


#include <simobject.h>
// MERGED_LOCALLY: #include "dcrs.h"
// MERGED_LOCALLY: #include "arch.h"
// MERGED_LOCALLY: #include "cache_cluster.h"
// MERGED_LOCALLY: #include "local_mem.h"
// MERGED_LOCALLY: #include "core.h"
// MERGED_LOCALLY: #include "socket.h"
// MERGED_LOCALLY: #include "constants.h"

namespace vortex {

class ProcessorImpl;

class Cluster : public SimObject<Cluster> {
public:
  struct PerfStats {
    CacheSim::PerfStats l2cache;
  };

  std::vector<SimPort<MemReq>> mem_req_ports;
  std::vector<SimPort<MemRsp>> mem_rsp_ports;

  Cluster(const SimContext& ctx,
          uint32_t cluster_id,
          ProcessorImpl* processor,
          const Arch &arch,
          const DCRS &dcrs);

  ~Cluster();

  uint32_t id() const {
    return cluster_id_;
  }

  ProcessorImpl* processor() const {
    return processor_;
  }

  void reset();

  void tick();

  void attach_ram(RAM* ram);

  #ifdef VM_ENABLE
  void set_satp(uint64_t satp);
  #endif

  bool running() const;

  int get_exitcode() const;

  void barrier(uint32_t bar_id, uint32_t count, uint32_t core_id);

  PerfStats perf_stats() const;

private:
  uint32_t                    cluster_id_;
  ProcessorImpl*              processor_;
  std::vector<Socket::Ptr>    sockets_;
  std::vector<CoreMask>       barriers_;
  CacheSim::Ptr               l2cache_;
  uint32_t                    cores_per_socket_;
};

} // namespace vortex
// --- End of content from sim/simx/cluster.h ---

// --- Start of content from sim/simx/debug.h ---
// Original include guard: DEBUG_LEVEL
// Copyright © 2019-2023
// 
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
// 
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#pragma once


#define DEBUG_HEADER << "DEBUG "
//#define DEBUG_HEADER << "DEBUG " << __FILE__ << ':' << std::dec << __LINE__ << ": "

#define TRACE_HEADER << "TRACE "
//#define TRACE_HEADER << "DEBUG " << __FILE__ << ':' << std::dec << __LINE__ << ": "

#ifndef NDEBUG

#include <iostream>
#include <iomanip>

#define DP(lvl, x) do { \
  if ((lvl) <= DEBUG_LEVEL) { \
    std::cout DEBUG_HEADER << x << std::endl; \
  } \
} while(0)

#define DPH(lvl, x) do { \
  if ((lvl) <= DEBUG_LEVEL) { \
    std::cout DEBUG_HEADER << x; \
  } \
} while(0)

#define DPN(lvl, x) do { \
  if ((lvl) <= DEBUG_LEVEL) { \
    std::cout << x; \
  } \
} while(0)

#define DT(lvl, x) do { \
  if ((lvl) <= DEBUG_LEVEL) { \
    std::cout TRACE_HEADER << std::setw(10) << std::dec << SimPlatform::instance().cycles() << std::setw(0) << ": " << x << std::endl; \
  } \
} while(0)

#define DTH(lvl, x) do { \
  if ((lvl) <= DEBUG_LEVEL) { \
    std::cout TRACE_HEADER << std::setw(10) << std::dec << SimPlatform::instance().cycles() << std::setw(0) << ": " << x; \
  } \
} while(0)

#define DTN(lvl, x) do { \
  if ((lvl) <= DEBUG_LEVEL) { \
    std::cout << x; \
  } \
} while(0)


#else

#define DP(lvl, x) do {} while(0)
#define DPH(lvl, x) do {} while(0)
#define DPN(lvl, x) do {} while(0)

#define DT(lvl, x) do {} while(0)
#define DTH(lvl, x) do {} while(0)
#define DTN(lvl, x) do {} while(0)
// --- End of content from sim/simx/debug.h ---

// --- Start of content from sim/simx/emulator.h ---
// Original include guard: __WARP_H
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


#include <vector>
#include <sstream>
#include <stack>
#include <mem.h>
// MERGED_LOCALLY: #include "types.h"

namespace vortex {

class Arch;
class DCRS;
class Core;
class Instr;
class instr_trace_t;

class Emulator {
public:
  Emulator(const Arch &arch,
           const DCRS &dcrs,
           Core* core);

  ~Emulator();

  void clear();

  void attach_ram(RAM* ram);
#ifdef VM_ENABLE
  void set_satp(uint64_t satp) ;

  instr_trace_t* step();

  bool running() const;

  void suspend(uint32_t wid);

  void resume(uint32_t wid);

  bool barrier(uint32_t bar_id, uint32_t count, uint32_t wid);

  bool wspawn(uint32_t num_warps, Word nextPC);

  int get_exitcode() const;

  Word get_tiles();
  Word get_tc_size();
  Word get_tc_num();

  void dcache_read(void* data, uint64_t addr, uint32_t size);

  void dcache_write(const void* data, uint64_t addr, uint32_t size);

private:

  struct ipdom_entry_t {
    ipdom_entry_t(const ThreadMask &orig_tmask, const ThreadMask &else_tmask, Word PC)
      : orig_tmask (orig_tmask)
      , else_tmask (else_tmask)
      , PC         (PC)
      , fallthrough(false)
    {}

    ThreadMask  orig_tmask;
    ThreadMask  else_tmask;
    Word        PC;
    bool        fallthrough;
  };

  struct vtype_t {
    uint32_t vill;
    uint32_t vma;
    uint32_t vta;
    uint32_t vsew;
    uint32_t vlmul;
  };

  union reg_data_t {
    Word     u;
    WordI    i;
    WordF    f;
    float    f32;
    double   f64;
    uint32_t u32;
    uint64_t u64;
    int32_t  i32;
    int64_t  i64;
  };

  struct warp_t {
    warp_t(const Arch& arch);
    void clear(uint64_t startup_addr);

    Word                              PC;
    ThreadMask                        tmask;
    std::vector<std::vector<Word>>    ireg_file;
    std::vector<std::vector<uint64_t>>freg_file;
    std::stack<ipdom_entry_t>         ipdom_stack;
    Byte                              fcsr;
#ifdef EXT_V_ENABLE
    std::vector<std::vector<Byte>>    vreg_file;
    vtype_t                           vtype;
    uint32_t                          vl;
    Word                              vlmax;
    uint32_t                          uuid;
  };

  struct wspawn_t {
    bool valid;
    uint32_t num_warps;
    Word nextPC;
  };

  std::shared_ptr<Instr> decode(uint32_t code) const;

  void execute(const Instr &instr, uint32_t wid, instr_trace_t *trace);

#ifdef EXT_V_ENABLE
  void loadVector(const Instr &instr, uint32_t wid, std::vector<reg_data_t[3]> &rsdata);
  void storeVector(const Instr &instr, uint32_t wid, std::vector<reg_data_t[3]> &rsdata);
  void executeVector(const Instr &instr, uint32_t wid, std::vector<reg_data_t[3]> &rsdata, std::vector<reg_data_t> &rddata);

  void icache_read(void* data, uint64_t addr, uint32_t size);

  void dcache_amo_reserve(uint64_t addr);

  bool dcache_amo_check(uint64_t addr);

  void writeToStdOut(const void* data, uint64_t addr, uint32_t size);

  void cout_flush();

  Word get_csr(uint32_t addr, uint32_t tid, uint32_t wid);

  void set_csr(uint32_t addr, Word value, uint32_t tid, uint32_t wid);

  uint32_t get_fpu_rm(uint32_t func3, uint32_t tid, uint32_t wid);

  void update_fcrs(uint32_t fflags, uint32_t tid, uint32_t wid);

  // temporarily added for riscv-vector tests
  // TODO: remove once ecall/ebreak are supported
  void trigger_ecall();
  void trigger_ebreak();

  const Arch& arch_;
  const DCRS& dcrs_;
  Core*       core_;
  std::vector<warp_t> warps_;
  WarpMask    active_warps_;
  WarpMask    stalled_warps_;
  std::vector<WarpMask> barriers_;
  std::unordered_map<int, std::stringstream> print_bufs_;
  MemoryUnit  mmu_;
  uint32_t    ipdom_size_;
  Word        csr_mscratch_;
  wspawn_t    wspawn_;
  std::vector<Word> scratchpad;
  uint32_t mat_size;
  uint32_t tc_size;
  uint32_t tc_num;
  std::vector<std::vector<std::unordered_map<uint32_t, uint32_t>>> csrs_;
};

}
// --- End of content from sim/simx/emulator.h ---

// --- Start of content from sim/simx/ibuffer.h ---
// Original pragma: #pragma once
// Copyright © 2019-2023
// 
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
// 
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


// MERGED_LOCALLY: #include "instr_trace.h"
#include <queue>

namespace vortex {

class IBuffer {
public:
	IBuffer(uint32_t size) 
		: capacity_(size)
	{}

	bool empty() const {
		return entries_.empty();
	}
	
	bool full() const {
		return (entries_.size() == capacity_);
	}

	instr_trace_t* top() const {
		return entries_.front();
	}

	void push(instr_trace_t* trace) {
		entries_.emplace(trace);
	}

	void pop() {
		return entries_.pop();
	}

	void clear() {
		std::queue<instr_trace_t*> empty;
		std::swap(entries_, empty );
	}

private:
	std::queue<instr_trace_t*> entries_;
	uint32_t capacity_;
};

}
// --- End of content from sim/simx/ibuffer.h ---

// --- Start of content from sim/simx/pipeline.h ---
// Original pragma: #pragma once
// Copyright © 2019-2023
// 
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
// 
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.



// MERGED_LOCALLY: #include "instr_trace.h"
#include <queue>

namespace vortex {

class PipelineLatch {
public:
  PipelineLatch() {}
  ~PipelineLatch() {}
  
  bool empty() const {
    return queue_.empty();
  }

  instr_trace_t* front() {
    return queue_.front();
  }

  void push(instr_trace_t* value) {    
    queue_.push(value);
  }

  void pop() {
    queue_.pop();
  }

  void clear() {
    std::queue<instr_trace_t*> empty;
    std::swap(queue_, empty);
  }

protected:
  std::queue<instr_trace_t*> queue_;
};

}
// --- End of content from sim/simx/pipeline.h ---

// --- Start of content from sim/simx/constants.h ---
// Original include guard: RAM_PAGE_SIZE
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#pragma once

#include <VX_config.h>


#ifndef MEM_CLOCK_RATIO
#define MEM_CLOCK_RATIO   1

inline constexpr int LSU_WORD_SIZE    = (XLEN / 8);
inline constexpr int LSU_CHANNELS     = NUM_LSU_LANES;
inline constexpr int LSU_NUM_REQS	    = (NUM_LSU_BLOCKS * LSU_CHANNELS);

// The dcache uses coalesced memory blocks
inline constexpr int DCACHE_WORD_SIZE = LSU_LINE_SIZE;
inline constexpr int DCACHE_CHANNELS 	= UP((NUM_LSU_LANES * (XLEN / 8)) / DCACHE_WORD_SIZE);
inline constexpr int DCACHE_NUM_REQS	= (NUM_LSU_BLOCKS * DCACHE_CHANNELS);

inline constexpr int NUM_SOCKETS      = UP(NUM_CORES / SOCKET_SIZE);

inline constexpr int L2_NUM_REQS      = NUM_SOCKETS * L1_MEM_PORTS;

inline constexpr int L3_NUM_REQS      = NUM_CLUSTERS * L2_MEM_PORTS;

inline constexpr int PER_ISSUE_WARPS  = NUM_WARPS / ISSUE_WIDTH;
// --- End of content from sim/simx/constants.h ---

// --- Start of content from sim/simx/operand.h ---
// Original pragma: #pragma once
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


// MERGED_LOCALLY: #include "instr_trace.h"

namespace vortex {

class Operand : public SimObject<Operand> {
private:
		static constexpr uint32_t NUM_BANKS = 4;
		uint32_t total_stalls_ = 0;

public:
    SimPort<instr_trace_t*> Input;
    SimPort<instr_trace_t*> Output;

    Operand(const SimContext& ctx)
			: SimObject<Operand>(ctx, "Operand")
			, Input(this)
			, Output(this)
    {
			total_stalls_ = 0;
		}

    virtual ~Operand() {}

    virtual void reset() {
			total_stalls_ = 0;
		}

    virtual void tick() {
			if (Input.empty())
				return;
			auto trace = Input.front();

			uint32_t stalls = 0;

			for (int i = 0; i < NUM_SRC_REGS; ++i) {
				for (int j = i + 1; j < NUM_SRC_REGS; ++j) {
					int bank_i = trace->src_regs[i].idx % NUM_BANKS;
					int bank_j = trace->src_regs[j].idx % NUM_BANKS;
					if ((trace->src_regs[i].type != RegType::None)
					 && (trace->src_regs[j].type != RegType::None)
					 && (trace->src_regs[i].idx != 0)
					 && (trace->src_regs[j].idx != 0)
					 && bank_i == bank_j) {
						++stalls;
					}
				}
			}

			total_stalls_ += stalls;

			Output.push(trace, 2 + stalls);

			DT(3, "pipeline-operands: " << *trace);

			Input.pop();
    };

		uint32_t total_stalls() const {
			return total_stalls_;
		}
};

}
// --- End of content from sim/simx/operand.h ---

// --- Start of content from sim/simx/instr_trace.h ---
// Original pragma: #pragma once
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.



#include <memory>
#include <iostream>
#include <util.h>
// MERGED_LOCALLY: #include "types.h"
// MERGED_LOCALLY: #include "arch.h"
// MERGED_LOCALLY: #include "debug.h"

namespace vortex {

class ITraceData {
public:
    using Ptr = std::shared_ptr<ITraceData>;
    ITraceData() {}
    virtual ~ITraceData() {}
};

struct LsuTraceData : public ITraceData {
  using Ptr = std::shared_ptr<LsuTraceData>;
  std::vector<mem_addr_size_t> mem_addrs;
  LsuTraceData(uint32_t num_threads) : mem_addrs(num_threads) {}
};

struct SFUTraceData : public ITraceData {
  using Ptr = std::shared_ptr<SFUTraceData>;
  Word arg1;
  Word arg2;
  SFUTraceData(Word arg1, Word arg2) : arg1(arg1), arg2(arg2) {}
};

struct instr_trace_t {
public:
  struct reg_t {
    RegType  type;
    uint32_t idx;
  };

  //--
  const uint64_t uuid;
  const Arch&    arch;

  //--
  uint32_t    cid;
  uint32_t    wid;
  ThreadMask  tmask;
  Word        PC;
  bool        wb;

  //--
  reg_t       dst_reg;

  //--
  std::vector<reg_t> src_regs;

  //-
  FUType     fu_type;

  //--
  union {
    uint32_t unit_type;
    LsuType  lsu_type;
    AluType  alu_type;
    FpuType  fpu_type;
    SfuType  sfu_type;
    TCUType  tcu_type; 
  };

  ITraceData::Ptr data;

  int  pid;
  bool sop;
  bool eop;

  bool fetch_stall;

  instr_trace_t(uint64_t uuid, const Arch& arch)
    : uuid(uuid)
    , arch(arch)
    , cid(0)
    , wid(0)
    , tmask(0)
    , PC(0)
    , wb(false)
    , dst_reg({RegType::None, 0})
    , src_regs(NUM_SRC_REGS, {RegType::None, 0})
    , fu_type(FUType::ALU)
    , unit_type(0)
    , data(nullptr)
    , pid(-1)
    , sop(true)
    , eop(true)
    , fetch_stall(false)
    , log_once_(false)
  {}

  instr_trace_t(const instr_trace_t& rhs)
    : uuid(rhs.uuid)
    , arch(rhs.arch)
    , cid(rhs.cid)
    , wid(rhs.wid)
    , tmask(rhs.tmask)
    , PC(rhs.PC)
    , wb(rhs.wb)
    , dst_reg(rhs.dst_reg)
    , src_regs(rhs.src_regs)
    , fu_type(rhs.fu_type)
    , unit_type(rhs.unit_type)
    , data(rhs.data)
    , pid(rhs.pid)
    , sop(rhs.sop)
    , eop(rhs.eop)
    , fetch_stall(rhs.fetch_stall)
    , log_once_(false)
  {}

  ~instr_trace_t() {}

  bool log_once(bool enable) {
    bool old = log_once_;
    log_once_ = enable;
    return old;
  }

private:
  bool log_once_;
};

inline std::ostream &operator<<(std::ostream &os, const instr_trace_t& trace) {
  os << "cid=" << trace.cid;
  os << ", wid=" << trace.wid;
  os << ", tmask=";
  for (uint32_t i = 0, n = trace.arch.num_threads(); i < n; ++i) {
      os << trace.tmask.test(i);
  }
  os << ", PC=0x" << std::hex << trace.PC << std::dec;
  os << ", wb=" << trace.wb;
  if (trace.dst_reg.type != RegType::None) {
     os << ", rd=" << trace.dst_reg.type << trace.dst_reg.idx;
  }
  for (uint32_t i = 0; i < trace.src_regs.size(); ++i) {
    if (trace.src_regs[i].type != RegType::None) {
      os << ", rs" << i << "=" << trace.src_regs[i].type << trace.src_regs[i].idx;
    }
  }
  os << ", ex=" << trace.fu_type;
  if (trace.pid != -1) {
    os << ", pid=" << trace.pid;
    os << ", sop=" << trace.sop;
    os << ", eop=" << trace.eop;
  }
  os << " (#" << trace.uuid << ")";
  return os;
}

}
// --- End of content from sim/simx/instr_trace.h ---

// --- Start of content from sim/simx/dcrs.h ---
// Original pragma: #pragma once
// Copyright © 2019-2023
// 
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
// 
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.


#include <util.h>
#include <VX_types.h>
#include <array>

namespace vortex {

class BaseDCRS {
public:
  uint32_t read(uint32_t addr) const {
    uint32_t state = VX_DCR_BASE_STATE(addr);
    return states_.at(state);
  }

	void write(uint32_t addr, uint32_t value) {
		uint32_t state = VX_DCR_BASE_STATE(addr);
		states_.at(state) = value;
	}

private:
  std::array<uint32_t, VX_DCR_BASE_STATE_COUNT> states_;
};

class DCRS {
public:
  void write(uint32_t addr, uint32_t value);

  BaseDCRS base_dcrs;
};

}
// --- End of content from sim/simx/dcrs.h ---

// --- Start of content from sim/common/dram_sim.cpp ---
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// MERGED_LOCALLY: #include "dram_sim.h"
// MERGED_LOCALLY: #include "util.h"
#include <fstream>

DISABLE_WARNING_PUSH
DISABLE_WARNING_UNUSED_PARAMETER
DISABLE_WARNING_MISSING_FIELD_INITIALIZERS
#include <base/base.h>
#include <base/request.h>
#include <base/config.h>
#include <frontend/frontend.h>
#include <memory_system/memory_system.h>
DISABLE_WARNING_POP

using namespace vortex;

class DramSim::Impl {
private:
	struct mem_req_t {
		uint64_t addr;
		bool is_write;
		ResponseCallback callback;
		void* arg;
	};

	Ramulator::IFrontEnd* ramulator_frontend_;
	Ramulator::IMemorySystem* ramulator_memorysystem_;
	uint32_t cpu_channel_size_;
	uint64_t cpu_cycles_;
	uint32_t scaled_dram_cycles_;
	static const uint32_t tick_cycles_ = 1000;
	static const uint32_t dram_channel_size_ = 16; // 128 bits
	std::queue<mem_req_t> pending_reqs_;

	void handle_pending_requests() {
		if (pending_reqs_.empty())
			return;
		auto& req = pending_reqs_.front();
		auto req_type = req.is_write ? Ramulator::Request::Type::Write : Ramulator::Request::Type::Read;
		std::function<void(Ramulator::Request&)> callback = nullptr;
		if (req.callback) {
			callback = [req_callback = std::move(req.callback), req_arg = std::move(req.arg)](Ramulator::Request& /*dram_req*/) {
				req_callback(req_arg);
			};
		}
		if (ramulator_frontend_->receive_external_requests(req_type, req.addr, 0, callback)) {
			if (req.is_write) {
				// Ramulator does not handle write responses, so we fire the callback ourselves.
				if (req.callback) {
					req.callback(req.arg);
				}
			}
			pending_reqs_.pop();
		}
	}

public:
	Impl(uint32_t num_channels, uint32_t channel_size, float clock_ratio) {
		YAML::Node dram_config;
		dram_config["Frontend"]["impl"] = "GEM5";
		dram_config["MemorySystem"]["impl"] = "GenericDRAM";
		dram_config["MemorySystem"]["clock_ratio"] = 1;
		dram_config["MemorySystem"]["DRAM"]["impl"] = "HBM2";
		dram_config["MemorySystem"]["DRAM"]["org"]["preset"] = "HBM2_8Gb";
		dram_config["MemorySystem"]["DRAM"]["org"]["density"] = 8192;
		dram_config["MemorySystem"]["DRAM"]["org"]["channel"] = num_channels;
		dram_config["MemorySystem"]["DRAM"]["timing"]["preset"] = "HBM2_2Gbps";
		dram_config["MemorySystem"]["Controller"]["impl"] = "Generic";
		dram_config["MemorySystem"]["Controller"]["Scheduler"]["impl"] = "FRFCFS";
		dram_config["MemorySystem"]["Controller"]["RefreshManager"]["impl"] = "AllBank";
		dram_config["MemorySystem"]["Controller"]["RowPolicy"]["impl"] = "OpenRowPolicy";
		{
			YAML::Node draw_plugin;
			draw_plugin["ControllerPlugin"]["impl"] = "TraceRecorder";
			draw_plugin["ControllerPlugin"]["path"] = "./trace/ramulator.log";
			dram_config["MemorySystem"]["Controller"]["plugins"].push_back(draw_plugin);
		}
		dram_config["MemorySystem"]["AddrMapper"]["impl"] = "RoBaRaCoCh";

		ramulator_frontend_ = Ramulator::Factory::create_frontend(dram_config);
		ramulator_memorysystem_ = Ramulator::Factory::create_memory_system(dram_config);
		ramulator_frontend_->connect_memory_system(ramulator_memorysystem_);
		ramulator_memorysystem_->connect_frontend(ramulator_frontend_);

		cpu_channel_size_ = channel_size;
		scaled_dram_cycles_ = static_cast<uint64_t>(clock_ratio * tick_cycles_);
		this->reset();
	}

	~Impl() {
		std::ofstream nullstream("ramulator.stats.log");
		auto original_buf = std::cout.rdbuf();
		std::cout.rdbuf(nullstream.rdbuf());
		ramulator_frontend_->finalize();
  	ramulator_memorysystem_->finalize();
		std::cout.rdbuf(original_buf);
	}

	void reset() {
		cpu_cycles_ = 0;
	}

	void tick() {
		cpu_cycles_ += tick_cycles_;
		while (cpu_cycles_ >= scaled_dram_cycles_) {
			this->handle_pending_requests();
			ramulator_memorysystem_->tick();
			cpu_cycles_ -= scaled_dram_cycles_;
		}
	}

	void send_request(uint64_t addr, bool is_write, ResponseCallback response_cb, void* arg) {
		// enqueue the request
		if (cpu_channel_size_ > dram_channel_size_) {
			uint32_t n = cpu_channel_size_ / dram_channel_size_;
			for (uint32_t i = 0; i < n; ++i) {
				uint64_t dram_byte_addr = (addr / cpu_channel_size_) * dram_channel_size_ + (i * dram_channel_size_);
				if (i == 0) {
					pending_reqs_.push({dram_byte_addr, is_write, response_cb, arg});
				} else {
					pending_reqs_.push({dram_byte_addr, is_write, nullptr, nullptr});
				}
			}
		} else if (cpu_channel_size_ < dram_channel_size_) {
			uint64_t dram_byte_addr = (addr / cpu_channel_size_) * dram_channel_size_;
			pending_reqs_.push({dram_byte_addr, is_write, response_cb, arg});
		} else {
			uint64_t dram_byte_addr = addr;
			pending_reqs_.push({dram_byte_addr, is_write, response_cb, arg});
		}
	}
};

///////////////////////////////////////////////////////////////////////////////

DramSim::DramSim(uint32_t num_channels, uint32_t channel_size, float clock_ratio)
	: impl_(new Impl(num_channels, channel_size, clock_ratio))
{}

DramSim::~DramSim() {
  delete impl_;
}

void DramSim::reset() {
  impl_->reset();
}

void DramSim::tick() {
  impl_->tick();
}

void DramSim::send_request(uint64_t addr, bool is_write, ResponseCallback callback, void* arg) {
  impl_->send_request(addr, is_write, callback, arg);
}
// --- End of content from sim/common/dram_sim.cpp ---

// --- Start of content from sim/common/mem.cpp ---
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// MERGED_LOCALLY: #include "mem.h"
#include <vector>
#include <iostream>
#include <fstream>
#include <assert.h>
// MERGED_LOCALLY: #include "util.h"
#include <VX_config.h>
#include <bitset>

using namespace vortex;

#ifdef VM_ENABLE
// #ifndef NDEBUG
// #define DBGPRINT(format, ...) do { printf("[VXDRV] " format "", ##__VA_ARGS__); } while (0)
// #else
#define DBGPRINT(format, ...) ((void)0)
// #endif
#endif


RamMemDevice::RamMemDevice(const char *filename, uint32_t wordSize)
  : wordSize_(wordSize) {
  std::ifstream input(filename);

  if (!input) {
    std::cout << "Error reading file \"" << filename << "\" into RamMemDevice.\n";
    std::abort();
  }

  do {
    contents_.push_back(input.get());
  } while (input);

  while (contents_.size() & (wordSize-1)) {
    contents_.push_back(0x00);
  }
}

RamMemDevice::RamMemDevice(uint64_t size, uint32_t wordSize)
  : contents_(size)
  , wordSize_(wordSize)
{}

void RamMemDevice::read(void* data, uint64_t addr, uint64_t size) {
  auto addr_end = addr + size;
  if ((addr & (wordSize_-1))
   || (addr_end & (wordSize_-1))
   || (addr_end <= contents_.size())) {
    std::cout << "lookup of 0x" << std::hex << (addr_end-1) << std::dec << " failed.\n";
    throw BadAddress();
  }

  const uint8_t *s = contents_.data() + addr;
  for (uint8_t *d = (uint8_t*)data, *de = d + size; d != de;) {
    *d++ = *s++;
  }
}

void RamMemDevice::write(const void* data, uint64_t addr, uint64_t size) {
  auto addr_end = addr + size;
  if ((addr & (wordSize_-1))
   || (addr_end & (wordSize_-1))
   || (addr_end <= contents_.size())) {
    std::cout << "lookup of 0x" << std::hex << (addr_end-1) << std::dec << " failed.\n";
    throw BadAddress();
  }

  const uint8_t *s = (const uint8_t*)data;
  for (uint8_t *d = contents_.data() + addr, *de = d + size; d != de;) {
    *d++ = *s++;
  }
}

///////////////////////////////////////////////////////////////////////////////

void RomMemDevice::write(const void* /*data*/, uint64_t /*addr*/, uint64_t /*size*/) {
  std::cout << "attempt to write to ROM.\n";
  std::abort();
}

///////////////////////////////////////////////////////////////////////////////

bool MemoryUnit::ADecoder::lookup(uint64_t addr, uint32_t wordSize, mem_accessor_t* ma) {
  uint64_t end = addr + (wordSize - 1);
  assert(end >= addr);
  for (auto iter = entries_.rbegin(), iterE = entries_.rend(); iter != iterE; ++iter) {
    if (addr >= iter->start && end <= iter->end) {
      ma->md   = iter->md;
      ma->addr = addr - iter->start;
      return true;
    }
  }
  return false;
}

void MemoryUnit::ADecoder::map(uint64_t start, uint64_t end, MemDevice &md) {
  assert(end >= start);
  entry_t entry{&md, start, end};
  entries_.emplace_back(entry);
}

void MemoryUnit::ADecoder::read(void* data, uint64_t addr, uint64_t size) {
  mem_accessor_t ma;
  if (!this->lookup(addr, size, &ma)) {
    std::cout << "lookup of 0x" << std::hex << addr << std::dec << " failed.\n";
    throw BadAddress();
  }
  ma.md->read(data, ma.addr, size);
}

void MemoryUnit::ADecoder::write(const void* data, uint64_t addr, uint64_t size) {
  mem_accessor_t ma;
  if (!this->lookup(addr, size, &ma)) {
    std::cout << "lookup of 0x" << std::hex << addr << std::dec << " failed.\n";
    throw BadAddress();
  }
  ma.md->write(data, ma.addr, size);
}

///////////////////////////////////////////////////////////////////////////////

MemoryUnit::MemoryUnit(uint64_t pageSize)
  : pageSize_(pageSize)
#ifndef VM_ENABLE
  , enableVM_(pageSize != 0)
#endif
  , amo_reservation_({0x0, false}) 
#ifdef VM_ENABLE
  , TLB_HIT(0)
  , TLB_MISS(0)
  , TLB_EVICT(0)
  , PTW(0)
  , satp_(NULL) {};
#else
  {
    if (pageSize != 0)
    {
      tlb_[0] = TLBEntry(0, 077);
    }
  }
#endif

void MemoryUnit::attach(MemDevice &m, uint64_t start, uint64_t end) {
  decoder_.map(start, end, m);
}


#ifdef VM_ENABLE
std::pair<bool, uint64_t> MemoryUnit::tlbLookup(uint64_t vAddr, ACCESS_TYPE type, uint64_t* size_bits) {
  
  //Find entry while accounting for different sizes.
  for (auto entry : tlb_)
  {
    if(entry.first == vAddr >> entry.second.size_bits)
    {
        *size_bits = entry.second.size_bits;
        vAddr = vAddr >> (*size_bits);
    }
  }

  
  auto iter = tlb_.find(vAddr);
  if (iter != tlb_.end()) {
    TLBEntry e = iter->second;

    //Set mru bit if it is a hit.
    iter->second.mru_bit = true;

    //If at full capacity and no other unset bits.
    // Clear all bits except the one we just looked up.
    if (tlb_.size() == TLB_SIZE)
    {
      // bool no_cleared = true;
      // for (auto& entry : tlb_)
      // {
      //   no_cleared = no_cleared & entry.second.mru_bit;
      // }

      // if(no_cleared)
      // {
        for (auto& entry : tlb_)
        {
          entry.second.mru_bit = false;
        }
        iter->second.mru_bit = true;
      //}
      
    }
    //Check access permissions.
    if ( (type == ACCESS_TYPE::FETCH) & ((e.r == 0) | (e.x == 0)) )
    {
      throw Page_Fault_Exception("Page Fault : Incorrect permissions.");
    }
    else if ( (type == ACCESS_TYPE::LOAD) & (e.r == 0) )
    {
      throw Page_Fault_Exception("Page Fault : Incorrect permissions.");
    }
    else if ( (type == ACCESS_TYPE::STORE) & (e.w == 0) )
    {
      throw Page_Fault_Exception("Page Fault : Incorrect permissions.");
    }
    else
    {
      //TLB Hit
      return std::make_pair(true, iter->second.pfn);
    }
  } else {
    //TLB Miss
    return std::make_pair(false, 0);
  }
}
#else
MemoryUnit::TLBEntry MemoryUnit::tlbLookup(uint64_t vAddr, uint32_t flagMask) {
  auto iter = tlb_.find(vAddr / pageSize_);
  if (iter != tlb_.end()) {
    if (iter->second.flags & flagMask)
      return iter->second;
    else {
      throw PageFault(vAddr, false);
    }
  } else {
    throw PageFault(vAddr, true);
  }
}

uint64_t MemoryUnit::toPhyAddr(uint64_t addr, uint32_t flagMask) {
  uint64_t pAddr;
  if (enableVM_) {
    TLBEntry t = this->tlbLookup(addr, flagMask);
    pAddr = t.pfn * pageSize_ + addr % pageSize_;
  } else {
    pAddr = addr;
  }
  return pAddr;
}
#endif

#ifdef VM_ENABLE
void MemoryUnit::read(void* data, uint64_t addr, uint32_t size, ACCESS_TYPE type) {
  DBGPRINT("  [MMU:read] 0x%lx, 0x%x, %u\n",addr,size,type);
  uint64_t pAddr;
  pAddr = vAddr_to_pAddr(addr, type);
  return decoder_.read(data, pAddr, size);
}
#else
void MemoryUnit::read(void* data, uint64_t addr, uint32_t size, bool sup) {
  uint64_t pAddr = this->toPhyAddr(addr, sup ? 8 : 1);
  return decoder_.read(data, pAddr, size);
}
#endif
#ifdef VM_ENABLE
void MemoryUnit::write(const void* data, uint64_t addr, uint32_t size, ACCESS_TYPE type) {
  DBGPRINT("  [MMU:Write] 0x%lx, 0x%x, %u\n",addr,size,type);
  uint64_t pAddr;
  pAddr = vAddr_to_pAddr(addr, type);
  decoder_.write(data, pAddr, size);
  amo_reservation_.valid = false;
}
#else
void MemoryUnit::write(const void* data, uint64_t addr, uint32_t size, bool sup) {
  uint64_t pAddr = this->toPhyAddr(addr, sup ? 16 : 1);
  decoder_.write(data, pAddr, size);
  amo_reservation_.valid = false;
}
#endif

#ifdef VM_ENABLE
void MemoryUnit::amo_reserve(uint64_t addr) {
  DBGPRINT("  [MMU:amo_reserve] 0x%lx\n",addr);
  uint64_t pAddr = this->vAddr_to_pAddr(addr,ACCESS_TYPE::LOAD);
  amo_reservation_.addr = pAddr;
  amo_reservation_.valid = true;
}
#else
void MemoryUnit::amo_reserve(uint64_t addr) {
  uint64_t pAddr = this->toPhyAddr(addr, 1);
  amo_reservation_.addr = pAddr;
  amo_reservation_.valid = true;
}
#endif

#ifdef VM_ENABLE
bool MemoryUnit::amo_check(uint64_t addr) {
  DBGPRINT("  [MMU:amo_check] 0x%lx\n",addr);
  uint64_t pAddr = this->vAddr_to_pAddr(addr, ACCESS_TYPE::LOAD);
  return amo_reservation_.valid && (amo_reservation_.addr == pAddr);
}
#else
bool MemoryUnit::amo_check(uint64_t addr) {
  uint64_t pAddr = this->toPhyAddr(addr, 1);
  return amo_reservation_.valid && (amo_reservation_.addr == pAddr);
}
#endif


#ifdef VM_ENABLE

void MemoryUnit::tlbAdd(uint64_t virt, uint64_t phys, uint32_t flags, uint64_t size_bits) {
  // HW: evict TLB by Most Recently Used
  if (tlb_.size() == TLB_SIZE - 1) {
    for (auto& entry : tlb_)
    {
      entry.second.mru_bit = false;
    }
    
  } else if (tlb_.size() == TLB_SIZE) {
    uint64_t del;
    for (auto entry : tlb_) {
      if (!entry.second.mru_bit)
      {
        del = entry.first;
        break;
      }
    }
    tlb_.erase(tlb_.find(del));
    TLB_EVICT++;
  }
  tlb_[virt / pageSize_] = TLBEntry(phys / pageSize_, flags, size_bits);
}
#else

void MemoryUnit::tlbAdd(uint64_t virt, uint64_t phys, uint32_t flags) {
  tlb_[virt / pageSize_] = TLBEntry(phys / pageSize_, flags);
}
#endif

void MemoryUnit::tlbRm(uint64_t va) {
  if (tlb_.find(va / pageSize_) != tlb_.end())
    tlb_.erase(tlb_.find(va / pageSize_));
}

///////////////////////////////////////////////////////////////////////////////

void ACLManager::set(uint64_t addr, uint64_t size, int flags) {
  if (size == 0)
    return;

  uint64_t end = addr + size;

  // get starting interval
  auto it = acl_map_.lower_bound(addr);
  if (it != acl_map_.begin() && (--it)->second.end < addr) {
    ++it;
  }

  // Remove existing entries that overlap or are within the new range
  while (it != acl_map_.end() && it->first < end) {
    auto current = it++;
    uint64_t current_end = current->second.end;
    if (current_end <= addr)
      continue; // No overlap, no need to adjust

    // Adjust the current interval or erase it depending on overlap and flags
    if (current->first < addr) {
      if (current_end > end) {
        acl_map_[end] = {current_end, current->second.flags};
      }
      current->second.end = addr;
    } else {
      if (current_end > end) {
        acl_map_[end] = {current_end, current->second.flags};
      }
      acl_map_.erase(current);
    }
  }

  // Insert new range if flags are not zero
  if (flags != 0) {
    it = acl_map_.emplace(addr, acl_entry_t{end, flags}).first;
    // Merge adjacent ranges with the same flags
    auto prev = it;
    if (it != acl_map_.begin() && (--prev)->second.end == addr && prev->second.flags == flags) {
      prev->second.end = it->second.end;
      acl_map_.erase(it);
      it = prev;
    }
    auto next = std::next(it);
    if (next != acl_map_.end() && it->second.end == next->first && it->second.flags == next->second.flags) {
      it->second.end = next->second.end;
      acl_map_.erase(next);
    }
  }
}

bool ACLManager::check(uint64_t addr, uint64_t size, int flags) const {
  uint64_t end = addr + size;

  auto it = acl_map_.lower_bound(addr);
  if (it != acl_map_.begin() && (--it)->second.end < addr) {
    ++it;
  }

  while (it != acl_map_.end() && it->first < end) {
    if (it->second.end > addr) {
      if ((it->second.flags & flags) != flags) {
        std::cout << "Memory access violation from 0x" << std::hex << addr << " to 0x" << end << ", curent flags=" << it->second.flags << ", access flags=" << flags << std::dec << std::endl;
        return false; // Overlapping entry is missing at least one required flag bit
      }
      addr = it->second.end; // Move to the end of the current matching range
    }
    ++it;
  }

  return true;
}

///////////////////////////////////////////////////////////////////////////////

RAM::RAM(uint64_t capacity, uint32_t page_size)
  : capacity_(capacity)
  , page_bits_(log2ceil(page_size))
  , last_page_(nullptr)
  , last_page_index_(0)
  , check_acl_(false) {
  assert(ispow2(page_size));
  if (capacity != 0) {
    assert(ispow2(capacity));
    assert(page_size <= capacity);
    assert(0 == (capacity % page_size));
  }
}

RAM::~RAM() {
  this->clear();
}

void RAM::clear() {
  for (auto& page : pages_) {
    delete[] page.second;
  }
}

uint64_t RAM::size() const {
  return uint64_t(pages_.size()) << page_bits_;
}

uint8_t *RAM::get(uint64_t address) const {
  if (capacity_ != 0 && address >= capacity_) {
    throw OutOfRange();
  }
  uint32_t page_size   = 1 << page_bits_;
  uint32_t page_offset = address & (page_size - 1);
  uint64_t page_index  = address >> page_bits_;

  uint8_t* page;
  if (last_page_ && last_page_index_ == page_index) {
    page = last_page_;
  } else {
    auto it = pages_.find(page_index);
    if (it != pages_.end()) {
      page = it->second;
    } else {
      uint8_t *ptr = new uint8_t[page_size];
      // set uninitialized data to "baadf00d"
      for (uint32_t i = 0; i < page_size; ++i) {
        ptr[i] = (0xbaadf00d >> ((i & 0x3) * 8)) & 0xff;
      }
      pages_.emplace(page_index, ptr);
      page = ptr;
    }
    last_page_ = page;
    last_page_index_ = page_index;
  }

  return page + page_offset;
}

void RAM::read(void* data, uint64_t addr, uint64_t size) {
  // printf("====%s (addr= 0x%lx, size= 0x%lx) ====\n", __PRETTY_FUNCTION__,addr,size);
  if (check_acl_ && acl_mngr_.check(addr, size, 0x1) == false) {
    throw BadAddress();
  }
  uint8_t* d = (uint8_t*)data;
  for (uint64_t i = 0; i < size; i++) {
    d[i] = *this->get(addr + i);
  }
}

void RAM::write(const void* data, uint64_t addr, uint64_t size) {
  if (check_acl_ && acl_mngr_.check(addr, size, 0x2) == false) {
    throw BadAddress();
  }
  const uint8_t* d = (const uint8_t*)data;
  for (uint64_t i = 0; i < size; i++) {
    *this->get(addr + i) = d[i];
  }
}

void RAM::set_acl(uint64_t addr, uint64_t size, int flags) {
  if (capacity_ != 0 && (addr + size)> capacity_) {
    throw OutOfRange();
  }
  acl_mngr_.set(addr, size, flags);
}

void RAM::loadBinImage(const char* filename, uint64_t destination) {
  std::ifstream ifs(filename);
  if (!ifs) {
    std::cout << "error: " << filename << " not found" << std::endl;
    std::abort();
  }

  ifs.seekg(0, ifs.end);
  size_t size = ifs.tellg();
  std::vector<uint8_t> content(size);
  ifs.seekg(0, ifs.beg);
  ifs.read((char*)content.data(), size);

  this->clear();
  this->write(content.data(), destination, size);
}

void RAM::loadHexImage(const char* filename) {
  auto hti = [&](char c)->uint32_t {
    if (c >= 'A' && c <= 'F')
      return c - 'A' + 10;
    if (c >= 'a' && c <= 'f')
      return c - 'a' + 10;
    return c - '0';
  };

  auto hToI = [&](const char *c, uint32_t size)->uint32_t {
    uint32_t value = 0;
    for (uint32_t i = 0; i < size; i++) {
      value += hti(c[i]) << ((size - i - 1) * 4);
    }
    return value;
  };

  std::ifstream ifs(filename);
  if (!ifs) {
    std::cout << "error: " << filename << " not found" << std::endl;
    std::abort();
  }

  ifs.seekg(0, ifs.end);
  size_t size = ifs.tellg();
  std::vector<char> content(size);
  ifs.seekg(0, ifs.beg);
  ifs.read(content.data(), size);

  uint32_t offset = 0;
  char *line = content.data();

  this->clear();

  while (true) {
    if (line[0] == ':') {
      uint32_t byteCount = hToI(line + 1, 2);
      uint32_t nextAddr = hToI(line + 3, 4) + offset;
      uint32_t key = hToI(line + 7, 2);
      switch (key) {
      case 0:
        for (uint32_t i = 0; i < byteCount; i++) {
          uint32_t addr  = nextAddr + i;
          uint32_t value = hToI(line + 9 + i * 2, 2);
          *this->get(addr) = value;
        }
        break;
      case 2:
        offset = hToI(line + 9, 4) << 4;
        break;
      case 4:
        offset = hToI(line + 9, 4) << 16;
        break;
      default:
        break;
      }
    }
    while (*line != '\n' && size != 0) {
      ++line;
      --size;
    }
    if (size <= 1)
      break;
    ++line;
    --size;
  }
}

#ifdef VM_ENABLE

uint64_t MemoryUnit::get_base_ppn()
{
  assert(satp_!= NULL);
  return satp_->get_base_ppn();
}  

uint64_t MemoryUnit::get_satp()
{
  if (is_satp_unset())
    return 0;
  else
    return satp_->get_satp();
}  

uint8_t MemoryUnit::is_satp_unset()
{
  return (satp_==NULL);
}  

uint8_t MemoryUnit::get_mode()
{
  assert(satp_!= NULL);
  return satp_->get_mode();
}  
void MemoryUnit::set_satp(uint64_t satp)
{
  // uint16_t asid = 0; // set asid for different process
  satp_ = new SATP_t (satp );
}

bool MemoryUnit::need_trans(uint64_t dev_pAddr)
  {
    // Check if the satp is set and BARE mode
    if ( is_satp_unset() || (get_mode() == BARE))
      return 0;

    // Check if the address is reserved for system usage
    // bool isReserved = (PAGE_TABLE_BASE_ADDR <= dev_pAddr && dev_pAddr < PAGE_TABLE_BASE_ADDR + PT_SIZE_LIMIT);
    if (PAGE_TABLE_BASE_ADDR <= dev_pAddr)
      return 0;

    // Check if the address is reserved for IO usage
    if (dev_pAddr < USER_BASE_ADDR)
      return 0;
    // Check if the address falls within the startup address range
    if ((STARTUP_ADDR <= dev_pAddr) && (dev_pAddr <= (STARTUP_ADDR + 0x40000)))
      return 0;

    // Now all conditions are not met. Return true because the address needs translation 
    return 1;
  }

uint64_t MemoryUnit::vAddr_to_pAddr(uint64_t vAddr, ACCESS_TYPE type)
{
    uint64_t pfn;
    uint64_t size_bits;
    DBGPRINT("  [MMU: V2P] vaddr = 0x%lx, type = 0x%u\n",vAddr,type);
    if (!need_trans(vAddr))
    {
        DBGPRINT("  [MMU: V2P] Translation is not needed.\n");
        return vAddr;
    }

    //First lookup TLB.
    std::pair<bool, uint64_t> tlb_access = tlbLookup(vAddr, type,  &size_bits);
    if (tlb_access.first)
    {

        pfn = tlb_access.second;
        TLB_HIT++;
    }
    else //Else walk the PT.
    {
        std::pair<uint64_t, uint8_t> ptw_access = page_table_walk(vAddr, type, &size_bits);
        tlbAdd(vAddr>>size_bits, ptw_access.first, ptw_access.second,size_bits);
        pfn = ptw_access.first; TLB_MISS++; PTW++;
        unique_translations.insert(vAddr>>size_bits);
        PERF_UNIQUE_PTW = unique_translations.size();

    }

    //Construct final address using pfn and offset.
    DBGPRINT("  [MMU: V2P] translated vAddr: 0x%lx to pAddr 0x%lx\n",vAddr,((pfn << size_bits) + (vAddr & ((1 << size_bits) - 1))));
    return (pfn << size_bits) + (vAddr & ((1 << size_bits) - 1));
}

uint64_t MemoryUnit::get_pte_address(uint64_t base_ppn, uint64_t vpn)
{
  return (base_ppn * PT_SIZE) + (vpn * PTE_SIZE);
}

std::pair<uint64_t, uint8_t> MemoryUnit::page_table_walk(uint64_t vAddr_bits, ACCESS_TYPE type, uint64_t *size_bits)
{
  DBGPRINT("  [MMU:PTW] Start: vaddr = 0x%lx, type = %u.\n", vAddr_bits, type);
  uint8_t level = PT_LEVEL;
  int i = level-1;
  vAddr_t vaddr(vAddr_bits);
  uint32_t flags =0;
  uint64_t pte_addr = 0, pte_bytes = 0;
  uint64_t cur_base_ppn = get_base_ppn();
  // Need to fix for super page
  *size_bits = 12; 

  while (true)
  {
    // Read PTE.
    pte_addr = get_pte_address(cur_base_ppn, vaddr.vpn[i]);
    decoder_.read(&pte_bytes, pte_addr, PTE_SIZE);
    PTE_t pte(pte_bytes);
    DBGPRINT("  [MMU:PTW] Level[%u] pte_addr=0x%lx, pte_bytes =0x%lx, pte.ppn= 0x%lx, pte.flags = %u)\n", i, pte_addr, pte_bytes, pte.ppn, pte.flags);

    assert(((pte.pte_bytes & 0xFFFFFFFF) != 0xbaadf00d) && "ERROR: uninitialzed PTE\n" );

    // Check if it has invalid flag bits.
    if ((pte.v == 0) | ((pte.r == 0) & (pte.w == 1)))
    {
       assert(0);
      throw Page_Fault_Exception("  [MMU:PTW] Page Fault : Attempted to access invalid entry.");
    }

    if ((pte.r == 0) & (pte.w == 0) & (pte.x == 0))
    {
      // Not a leaf node as rwx == 000
      i--;
      if (i < 0)
      {
        assert(0);
        throw Page_Fault_Exception("  [MMU:PTW] Page Fault : No leaf node found.");
      }
      else
      {
        // Continue on to next level.
        cur_base_ppn= pte.ppn;
        DBGPRINT("  [MMU:PTW] next base_ppn: 0x%lx\n", cur_base_ppn);
        continue;
      }
    }
    else
    {
      // Leaf node found, finished walking.
      // Check RWX permissions according to access type.
      if ((type == ACCESS_TYPE::FETCH) & ((pte.r == 0) | (pte.x == 0)))
      {
        assert(0);
        throw Page_Fault_Exception("  [MMU:PTW] Page Fault : TYPE FETCH, Incorrect permissions.");
      }
      else if ((type == ACCESS_TYPE::LOAD) & (pte.r == 0))
      {
        assert(0);
        throw Page_Fault_Exception("  [MMU:PTW] Page Fault : TYPE LOAD, Incorrect permissions.");
      }
      else if ((type == ACCESS_TYPE::STORE) & (pte.w == 0))
      {
        assert(0);
        throw Page_Fault_Exception("  [MMU:PTW] Page Fault : TYPE STORE, Incorrect permissions.");
      }
      cur_base_ppn = pte.ppn;
      flags = pte.flags;
      break;
    }
  }
  return std::make_pair(cur_base_ppn, flags);
}

#endif
// --- End of content from sim/common/mem.cpp ---

// --- Start of content from sim/common/rvfloats.cpp ---
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// MERGED_LOCALLY: #include "rvfloats.h"
#include <stdio.h>

extern "C" {
#include <softfloat.h>
// MERGED_LOCALLY: #include "softfloat_ext.h"
#include <internals.h>
#include <../RISCV/specialize.h>
}

#define F32_SIGN 0x80000000
#define F64_SIGN 0x8000000000000000

inline float32_t to_float32_t(uint32_t x) { return float32_t{x}; }
inline float64_t to_float64_t(uint64_t x) { return float64_t{x}; }

inline uint32_t from_float32_t(float32_t x) { return uint32_t(x.v); }
inline uint64_t from_float64_t(float64_t x) { return uint64_t(x.v); }

inline void rv_init(uint32_t frm) {
  softfloat_exceptionFlags = 0;
  softfloat_roundingMode = frm;
}

#ifdef __cplusplus
extern "C" {
#endif

uint32_t rv_fadd_s(uint32_t a, uint32_t b, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto r = f32_add(to_float32_t(a), to_float32_t(b));
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return from_float32_t(r);
}

uint64_t rv_fadd_d(uint64_t a, uint64_t b, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto r = f64_add(to_float64_t(a), to_float64_t(b));
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return from_float64_t(r);
}

uint32_t rv_fsub_s(uint32_t a, uint32_t b, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto r = f32_sub(to_float32_t(a), to_float32_t(b));
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return from_float32_t(r);
}

uint64_t rv_fsub_d(uint64_t a, uint64_t b, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto r = f64_sub(to_float64_t(a), to_float64_t(b));
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return from_float64_t(r);
}

uint32_t rv_fmul_s(uint32_t a, uint32_t b, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto r = f32_mul(to_float32_t(a), to_float32_t(b));
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return from_float32_t(r);
}

uint64_t rv_fmul_d(uint64_t a, uint64_t b, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto r = f64_mul(to_float64_t(a), to_float64_t(b));
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return from_float64_t(r);
}

uint32_t rv_fmadd_s(uint32_t a, uint32_t b, uint32_t c, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto r = f32_mulAdd(to_float32_t(a), to_float32_t(b), to_float32_t(c));
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return from_float32_t(r);
}

uint64_t rv_fmadd_d(uint64_t a, uint64_t b, uint64_t c, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto r = f64_mulAdd(to_float64_t(a), to_float64_t(b), to_float64_t(c));
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return from_float64_t(r);
}

uint32_t rv_fmsub_s(uint32_t a, uint32_t b, uint32_t c, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto c_neg = c ^ F32_SIGN;
  auto r = f32_mulAdd(to_float32_t(a), to_float32_t(b), to_float32_t(c_neg));
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return from_float32_t(r);
}

uint64_t rv_fmsub_d(uint64_t a, uint64_t b, uint64_t c, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto c_neg = c ^ F64_SIGN;
  auto r = f64_mulAdd(to_float64_t(a), to_float64_t(b), to_float64_t(c_neg));
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return from_float64_t(r);
}

uint32_t rv_fnmadd_s(uint32_t a, uint32_t b, uint32_t c, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto a_neg = a ^ F32_SIGN;
  auto c_neg = c ^ F32_SIGN;
  auto r = f32_mulAdd(to_float32_t(a_neg), to_float32_t(b), to_float32_t(c_neg));
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return from_float32_t(r);
}

uint64_t rv_fnmadd_d(uint64_t a, uint64_t b, uint64_t c, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto a_neg = a ^ F64_SIGN;
  auto c_neg = c ^ F64_SIGN;
  auto r = f64_mulAdd(to_float64_t(a_neg), to_float64_t(b), to_float64_t(c_neg));
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return from_float64_t(r);
}

uint32_t rv_fnmsub_s(uint32_t a, uint32_t b, uint32_t c, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto a_neg = a ^ F32_SIGN;
  auto r = f32_mulAdd(to_float32_t(a_neg), to_float32_t(b), to_float32_t(c));
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return from_float32_t(r);
}

uint64_t rv_fnmsub_d(uint64_t a, uint64_t b, uint64_t c, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto a_neg = a ^ F64_SIGN;
  auto r = f64_mulAdd(to_float64_t(a_neg), to_float64_t(b), to_float64_t(c));
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return from_float64_t(r);
}

uint32_t rv_fdiv_s(uint32_t a, uint32_t b, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto r = f32_div(to_float32_t(a), to_float32_t(b));
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return from_float32_t(r);
}

uint64_t rv_fdiv_d(uint64_t a, uint64_t b, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto r = f64_div(to_float64_t(a), to_float64_t(b));
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return from_float64_t(r);
}

uint32_t rv_frecip7_s(uint32_t a, uint32_t frm, uint32_t* fflags) {
  softfloat_roundingMode = frm;
  auto r = f32_recip7(to_float32_t(a));
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return from_float32_t(r);
}

uint64_t rv_frecip7_d(uint64_t a, uint32_t frm, uint32_t* fflags) {
  softfloat_roundingMode = frm;
  auto r = f64_recip7(to_float64_t(a));
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return from_float64_t(r);
}

uint32_t rv_frsqrt7_s(uint32_t a, uint32_t frm, uint32_t* fflags) {
  softfloat_roundingMode = frm;
  auto r = f32_rsqrte7(to_float32_t(a));
  if (fflags) { *fflags =softfloat_exceptionFlags; }
  return from_float32_t(r);
}

uint64_t rv_frsqrt7_d(uint64_t a, uint32_t frm, uint32_t* fflags) {
  softfloat_roundingMode = frm;
  auto r = f64_rsqrte7(to_float64_t(a));
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return from_float64_t(r);
}

uint32_t rv_fsqrt_s(uint32_t a, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto r = f32_sqrt(to_float32_t(a));
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return from_float32_t(r);
}

uint64_t rv_fsqrt_d(uint64_t a, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto r = f64_sqrt(to_float64_t(a));
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return from_float64_t(r);
}

uint32_t rv_ftoi_s(uint32_t a, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto r = f32_to_i32(to_float32_t(a), frm, true);
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return r;
}

uint32_t rv_ftoi_d(uint64_t a, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto r = f64_to_i32(to_float64_t(a), frm, true);
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return r;
}

uint32_t rv_ftou_s(uint32_t a, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto r = f32_to_ui32(to_float32_t(a), frm, true);
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return r;
}

uint32_t rv_ftou_d(uint64_t a, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto r = f64_to_ui32(to_float64_t(a), frm, true);
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return r;
}

uint64_t rv_ftol_s(uint32_t a, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto r = f32_to_i64(to_float32_t(a), frm, true);
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return r;
}

uint64_t rv_ftol_d(uint64_t a, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto r = f64_to_i64(to_float64_t(a), frm, true);
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return r;
}

uint64_t rv_ftolu_s(uint32_t a, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto r = f32_to_ui64(to_float32_t(a), frm, true);
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return r;
}

uint64_t rv_ftolu_d(uint64_t a, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto r = f64_to_ui64(to_float64_t(a), frm, true);
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return r;
}

uint32_t rv_itof_s(uint32_t a, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto r = i32_to_f32(a);
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return from_float32_t(r);
}

uint64_t rv_itof_d(uint32_t a, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto r = i32_to_f64(a);
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return from_float64_t(r);
}

uint32_t rv_utof_s(uint32_t a, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto r = ui32_to_f32(a);
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return from_float32_t(r);
}

uint64_t rv_utof_d(uint32_t a, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto r = ui32_to_f64(a);
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return from_float64_t(r);
}

uint32_t rv_ltof_s(uint64_t a, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto r = i64_to_f32(a);
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return from_float32_t(r);
}

uint64_t rv_ltof_d(uint64_t a, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto r = i64_to_f64(a);
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return from_float64_t(r);
}

uint32_t rv_lutof_s(uint64_t a, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto r = ui64_to_f32(a);
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return from_float32_t(r);
}

uint64_t rv_lutof_d(uint64_t a, uint32_t frm, uint32_t* fflags) {
  rv_init(frm);
  auto r = ui64_to_f64(a);
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return from_float64_t(r);
}

bool rv_flt_s(uint32_t a, uint32_t b, uint32_t* fflags) {
  rv_init(0);
  auto r = f32_lt(to_float32_t(a), to_float32_t(b));
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return r;
}

bool rv_flt_d(uint64_t a, uint64_t b, uint32_t* fflags) {
  rv_init(0);
  auto r = f64_lt(to_float64_t(a), to_float64_t(b));
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return r;
}

bool rv_fle_s(uint32_t a, uint32_t b, uint32_t* fflags) {
  rv_init(0);
  auto r = f32_le(to_float32_t(a), to_float32_t(b));
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return r;
}

bool rv_fle_d(uint64_t a, uint64_t b, uint32_t* fflags) {
  rv_init(0);
  auto r = f64_le(to_float64_t(a), to_float64_t(b));
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return r;
}

bool rv_feq_s(uint32_t a, uint32_t b, uint32_t* fflags) {
  rv_init(0);
  auto r = f32_eq(to_float32_t(a), to_float32_t(b));
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return r;
}

bool rv_feq_d(uint64_t a, uint64_t b, uint32_t* fflags) {
  rv_init(0);
  auto r = f64_eq(to_float64_t(a), to_float64_t(b));
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return r;
}

uint32_t rv_fmin_s(uint32_t a, uint32_t b, uint32_t* fflags) {
  uint32_t r;
  rv_init(0);
  if (isNaNF32UI(a) && isNaNF32UI(b)) {
    r = defaultNaNF32UI;
  } else {
    auto fa = to_float32_t(a);
    auto fb = to_float32_t(b);
    if ((f32_lt_quiet(fa, fb) || (f32_eq(fa, fb) && (a & F32_SIGN)))
     || isNaNF32UI(b)) {
      r = a;
    } else {
      r = b;
    }
  }
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return r;
}

uint64_t rv_fmin_d(uint64_t a, uint64_t b, uint32_t* fflags) {
  uint64_t r;
  rv_init(0);
  if (isNaNF64UI(a) && isNaNF64UI(b)) {
    r = defaultNaNF64UI;
  } else {
    auto fa = to_float64_t(a);
    auto fb = to_float64_t(b);
    if ((f64_lt_quiet(fa, fb) || (f64_eq(fa, fb) && (a & F64_SIGN)))
     || isNaNF64UI(b)) {
      r = a;
    } else {
      r = b;
    }
  }
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return r;
}

uint32_t rv_fmax_s(uint32_t a, uint32_t b, uint32_t* fflags) {
  uint32_t r;
  rv_init(0);
  if (isNaNF32UI(a) && isNaNF32UI(b)) {
    r = defaultNaNF32UI;
  } else {
    auto fa = to_float32_t(a);
    auto fb = to_float32_t(b);
    if ((f32_lt_quiet(fb, fa) || (f32_eq(fb, fa) && (b & F32_SIGN)))
     || isNaNF32UI(b)) {
      r = a;
    } else {
      r = b;
    }
  }
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return r;
}

uint64_t rv_fmax_d(uint64_t a, uint64_t b, uint32_t* fflags) {
  uint64_t r;
  rv_init(0);
  if (isNaNF64UI(a) && isNaNF64UI(b)) {
    r = defaultNaNF64UI;
  } else {
    auto fa = to_float64_t(a);
    auto fb = to_float64_t(b);
    if ((f64_lt_quiet(fb, fa) || (f64_eq(fb, fa) && (b & F64_SIGN)))
     || isNaNF64UI(b)) {
      r = a;
    } else {
      r = b;
    }
  }
  if (fflags) { *fflags = softfloat_exceptionFlags; }
  return r;
}

uint32_t rv_fclss_s(uint32_t a) {
  auto infOrNaN      = (0xff == expF32UI(a));
  auto subnormOrZero = (0 == expF32UI(a));
  bool sign          = signF32UI(a);
  bool fracZero      = (0 == fracF32UI(a));
  bool isNaN         = isNaNF32UI(a);
  bool isSNaN        = softfloat_isSigNaNF32UI(a);

  uint32_t r =
      (  sign && infOrNaN && fracZero )        << 0 |
      (  sign && !infOrNaN && !subnormOrZero ) << 1 |
      (  sign && subnormOrZero && !fracZero )  << 2 |
      (  sign && subnormOrZero && fracZero )   << 3 |
      ( !sign && infOrNaN && fracZero )        << 7 |
      ( !sign && !infOrNaN && !subnormOrZero ) << 6 |
      ( !sign && subnormOrZero && !fracZero )  << 5 |
      ( !sign && subnormOrZero && fracZero )   << 4 |
      ( isNaN &&  isSNaN )                     << 8 |
      ( isNaN && !isSNaN )                     << 9;

  return r;
}

uint32_t rv_fclss_d(uint64_t a) {
  auto infOrNaN      = (0x7ff == expF64UI(a));
  auto subnormOrZero = (0 == expF64UI(a));
  bool sign          = signF64UI(a);
  bool fracZero      = (0 == fracF64UI(a));
  bool isNaN         = isNaNF64UI(a);
  bool isSNaN        = softfloat_isSigNaNF64UI(a);

  uint32_t r =
      (  sign && infOrNaN && fracZero )        << 0 |
      (  sign && !infOrNaN && !subnormOrZero ) << 1 |
      (  sign && subnormOrZero && !fracZero )  << 2 |
      (  sign && subnormOrZero && fracZero )   << 3 |
      ( !sign && infOrNaN && fracZero )        << 7 |
      ( !sign && !infOrNaN && !subnormOrZero ) << 6 |
      ( !sign && subnormOrZero && !fracZero )  << 5 |
      ( !sign && subnormOrZero && fracZero )   << 4 |
      ( isNaN &&  isSNaN )                     << 8 |
      ( isNaN && !isSNaN )                     << 9;

  return r;
}

uint32_t rv_fsgnj_s(uint32_t a, uint32_t b) {
  auto sign = b & F32_SIGN;
  auto r = sign | (a & ~F32_SIGN);
  return r;
}

uint64_t rv_fsgnj_d(uint64_t a, uint64_t b) {
  auto sign = b & F64_SIGN;
  auto r = sign | (a & ~F64_SIGN);
  return r;
}

uint32_t rv_fsgnjn_s(uint32_t a, uint32_t b) {
  auto sign = ~b & F32_SIGN;
  auto r = sign | (a & ~F32_SIGN);
  return r;
}

uint64_t rv_fsgnjn_d(uint64_t a, uint64_t b) {
  auto sign = ~b & F64_SIGN;
  auto r = sign | (a & ~F64_SIGN);
  return r;
}

uint32_t rv_fsgnjx_s(uint32_t a, uint32_t b) {
  auto sign1 = a & F32_SIGN;
  auto sign2 = b & F32_SIGN;
  auto r = (sign1 ^ sign2) | (a & ~F32_SIGN);
  return r;
}

uint64_t rv_fsgnjx_d(uint64_t a, uint64_t b) {
  auto sign1 = a & F64_SIGN;
  auto sign2 = b & F64_SIGN;
  auto r = (sign1 ^ sign2) | (a & ~F64_SIGN);
  return r;
}

uint32_t rv_dtof_r(uint64_t a, uint32_t frm) {
  rv_init(frm);
  return rv_dtof(a);
}

uint32_t rv_dtof(uint64_t a) {
  auto r = f64_to_f32(to_float64_t(a));
  return from_float32_t(r);
}

uint64_t rv_ftod(uint32_t a) {
  auto r = f32_to_f64(to_float32_t(a));
  return from_float64_t(r);
}

#ifdef __cplusplus
}
#endif
// --- End of content from sim/common/rvfloats.cpp ---

// --- Start of content from sim/common/softfloat_ext.cpp ---
/*============================================================================

This C source file is part of the SoftFloat IEEE Floating-Point Arithmetic
Package, Release 3e, by John R. Hauser.

Copyright 2011, 2012, 2013, 2014, 2015, 2016 The Regents of the University of
California.  All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

 1. Redistributions of source code must retain the above copyright notice,
    this list of conditions, and the following disclaimer.

 2. Redistributions in binary form must reproduce the above copyright notice,
    this list of conditions, and the following disclaimer in the documentation
    and/or other materials provided with the distribution.

 3. Neither the name of the University nor the names of its contributors may
    be used to endorse or promote products derived from this software without
    specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS "AS IS", AND ANY
EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE, ARE
DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE FOR ANY
DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

=============================================================================*/

// MERGED_LOCALLY: #include "softfloat_ext.h"
#include <../RISCV/specialize.h>
#include <assert.h>
#include <internals.h>
#include <softfloat.h>
#include <stdbool.h>

#ifdef __cplusplus
extern "C" {
#endif

uint_fast16_t f16_classify(float16_t a) {
  union ui16_f16 uA;
  uint_fast16_t uiA;

  uA.f = a;
  uiA = uA.ui;

  uint_fast16_t infOrNaN = expF16UI(uiA) == 0x1F;
  uint_fast16_t subnormalOrZero = expF16UI(uiA) == 0;
  bool sign = signF16UI(uiA);
  bool fracZero = fracF16UI(uiA) == 0;
  bool isNaN = isNaNF16UI(uiA);
  bool isSNaN = softfloat_isSigNaNF16UI(uiA);

  return (sign && infOrNaN && fracZero) << 0 |
         (sign && !infOrNaN && !subnormalOrZero) << 1 |
         (sign && subnormalOrZero && !fracZero) << 2 |
         (sign && subnormalOrZero && fracZero) << 3 |
         (!sign && infOrNaN && fracZero) << 7 |
         (!sign && !infOrNaN && !subnormalOrZero) << 6 |
         (!sign && subnormalOrZero && !fracZero) << 5 |
         (!sign && subnormalOrZero && fracZero) << 4 | (isNaN && isSNaN) << 8 |
         (isNaN && !isSNaN) << 9;
}

uint_fast16_t f32_classify(float32_t a) {
  union ui32_f32 uA;
  uint_fast32_t uiA;

  uA.f = a;
  uiA = uA.ui;

  uint_fast16_t infOrNaN = expF32UI(uiA) == 0xFF;
  uint_fast16_t subnormalOrZero = expF32UI(uiA) == 0;
  bool sign = signF32UI(uiA);
  bool fracZero = fracF32UI(uiA) == 0;
  bool isNaN = isNaNF32UI(uiA);
  bool isSNaN = softfloat_isSigNaNF32UI(uiA);

  return (sign && infOrNaN && fracZero) << 0 |
         (sign && !infOrNaN && !subnormalOrZero) << 1 |
         (sign && subnormalOrZero && !fracZero) << 2 |
         (sign && subnormalOrZero && fracZero) << 3 |
         (!sign && infOrNaN && fracZero) << 7 |
         (!sign && !infOrNaN && !subnormalOrZero) << 6 |
         (!sign && subnormalOrZero && !fracZero) << 5 |
         (!sign && subnormalOrZero && fracZero) << 4 | (isNaN && isSNaN) << 8 |
         (isNaN && !isSNaN) << 9;
}

uint_fast16_t f64_classify(float64_t a) {
  union ui64_f64 uA;
  uint_fast64_t uiA;

  uA.f = a;
  uiA = uA.ui;

  uint_fast16_t infOrNaN = expF64UI(uiA) == 0x7FF;
  uint_fast16_t subnormalOrZero = expF64UI(uiA) == 0;
  bool sign = signF64UI(uiA);
  bool fracZero = fracF64UI(uiA) == 0;
  bool isNaN = isNaNF64UI(uiA);
  bool isSNaN = softfloat_isSigNaNF64UI(uiA);

  return (sign && infOrNaN && fracZero) << 0 |
         (sign && !infOrNaN && !subnormalOrZero) << 1 |
         (sign && subnormalOrZero && !fracZero) << 2 |
         (sign && subnormalOrZero && fracZero) << 3 |
         (!sign && infOrNaN && fracZero) << 7 |
         (!sign && !infOrNaN && !subnormalOrZero) << 6 |
         (!sign && subnormalOrZero && !fracZero) << 5 |
         (!sign && subnormalOrZero && fracZero) << 4 | (isNaN && isSNaN) << 8 |
         (isNaN && !isSNaN) << 9;
}

static inline uint64_t extract64(uint64_t val, int pos, int len) {
  assert(pos >= 0 && len > 0 && len <= 64 - pos);
  return (val >> pos) & (~UINT64_C(0) >> (64 - len));
}

static inline uint64_t make_mask64(int pos, int len) {
  assert(pos >= 0 && len > 0 && pos < 64 && len <= 64);
  return (UINT64_MAX >> (64 - len)) << pos;
}

// user needs to truncate output to required length
static inline uint64_t rsqrte7(uint64_t val, int e, int s, bool sub) {
  uint64_t exp = extract64(val, s, e);
  uint64_t sig = extract64(val, 0, s);
  uint64_t sign = extract64(val, s + e, 1);
  const int p = 7;

  static const uint8_t table[] = {
      52,  51,  50,  48,  47,  46,  44,  43,  42,  41,  40,  39,  38,  36,  35,
      34,  33,  32,  31,  30,  30,  29,  28,  27,  26,  25,  24,  23,  23,  22,
      21,  20,  19,  19,  18,  17,  16,  16,  15,  14,  14,  13,  12,  12,  11,
      10,  10,  9,   9,   8,   7,   7,   6,   6,   5,   4,   4,   3,   3,   2,
      2,   1,   1,   0,   127, 125, 123, 121, 119, 118, 116, 114, 113, 111, 109,
      108, 106, 105, 103, 102, 100, 99,  97,  96,  95,  93,  92,  91,  90,  88,
      87,  86,  85,  84,  83,  82,  80,  79,  78,  77,  76,  75,  74,  73,  72,
      71,  70,  70,  69,  68,  67,  66,  65,  64,  63,  63,  62,  61,  60,  59,
      59,  58,  57,  56,  56,  55,  54,  53};

  if (sub) {
    while (extract64(sig, s - 1, 1) == 0)
      exp--, sig <<= 1;
      
    sig = (sig << 1) & make_mask64(0, s);
  }

  int idx = ((exp & 1) << (p - 1)) | (sig >> (s - p + 1));
  uint64_t out_sig = (uint64_t)(table[idx]) << (s - p);
  uint64_t out_exp = (3 * make_mask64(0, e - 1) + ~exp) / 2;

  return (sign << (s + e)) | (out_exp << s) | out_sig;
}

float16_t f16_rsqrte7(float16_t in) {
  union ui16_f16 uA;

  uA.f = in;
  unsigned int ret = f16_classify(in);
  bool sub = false;
  switch (ret) {
  case 0x001: // -inf
  case 0x002: // -normal
  case 0x004: // -subnormal
  case 0x100: // sNaN
    softfloat_exceptionFlags |= softfloat_flag_invalid;
    [[fallthrough]];
  case 0x200: // qNaN
    uA.ui = defaultNaNF16UI;
    break;
  case 0x008: // -0
    uA.ui = 0xfc00;
    softfloat_exceptionFlags |= softfloat_flag_infinite;
    break;
  case 0x010: // +0
    uA.ui = 0x7c00;
    softfloat_exceptionFlags |= softfloat_flag_infinite;
    break;
  case 0x080: //+inf
    uA.ui = 0x0;
    break;
  case 0x020: //+ sub
    sub = true;
    [[fallthrough]];
  default: // +num
    uA.ui = rsqrte7(uA.ui, 5, 10, sub);
    break;
  }

  return uA.f;
}

float32_t f32_rsqrte7(float32_t in) {
  union ui32_f32 uA;

  uA.f = in;
  unsigned int ret = f32_classify(in);
  bool sub = false;
  switch (ret) {
  case 0x001: // -inf
  case 0x002: // -normal
  case 0x004: // -subnormal
  case 0x100: // sNaN
    softfloat_exceptionFlags |= softfloat_flag_invalid;
    [[fallthrough]];
  case 0x200: // qNaN
    uA.ui = defaultNaNF32UI;
    break;
  case 0x008: // -0
    uA.ui = 0xff800000;
    softfloat_exceptionFlags |= softfloat_flag_infinite;
    break;
  case 0x010: // +0
    uA.ui = 0x7f800000;
    softfloat_exceptionFlags |= softfloat_flag_infinite;
    break;
  case 0x080: //+inf
    uA.ui = 0x0;
    break;
  case 0x020: //+ sub
    sub = true;
    [[fallthrough]];
  default: // +num
    uA.ui = rsqrte7(uA.ui, 8, 23, sub);
    break;
  }

  return uA.f;
}

float64_t f64_rsqrte7(float64_t in) {
  union ui64_f64 uA;

  uA.f = in;
  unsigned int ret = f64_classify(in);
  bool sub = false;
  switch (ret) {
  case 0x001: // -inf
  case 0x002: // -normal
  case 0x004: // -subnormal
  case 0x100: // sNaN
    softfloat_exceptionFlags |= softfloat_flag_invalid;
    [[fallthrough]];
  case 0x200: // qNaN
    uA.ui = defaultNaNF64UI;
    break;
  case 0x008: // -0
    uA.ui = 0xfff0000000000000ul;
    softfloat_exceptionFlags |= softfloat_flag_infinite;
    break;
  case 0x010: // +0
    uA.ui = 0x7ff0000000000000ul;
    softfloat_exceptionFlags |= softfloat_flag_infinite;
    break;
  case 0x080: //+inf
    uA.ui = 0x0;
    break;
  case 0x020: //+ sub
    sub = true;
    [[fallthrough]];
  default: // +num
    uA.ui = rsqrte7(uA.ui, 11, 52, sub);
    break;
  }

  return uA.f;
}

// user needs to truncate output to required length
static inline uint64_t recip7(uint64_t val, int e, int s, int rm, bool sub,
                              bool *round_abnormal) {
  uint64_t exp = extract64(val, s, e);
  uint64_t sig = extract64(val, 0, s);
  uint64_t sign = extract64(val, s + e, 1);
  const int p = 7;

  static const uint8_t table[] = {
      127, 125, 123, 121, 119, 117, 116, 114, 112, 110, 109, 107, 105, 104, 102,
      100, 99,  97,  96,  94,  93,  91,  90,  88,  87,  85,  84,  83,  81,  80,
      79,  77,  76,  75,  74,  72,  71,  70,  69,  68,  66,  65,  64,  63,  62,
      61,  60,  59,  58,  57,  56,  55,  54,  53,  52,  51,  50,  49,  48,  47,
      46,  45,  44,  43,  42,  41,  40,  40,  39,  38,  37,  36,  35,  35,  34,
      33,  32,  31,  31,  30,  29,  28,  28,  27,  26,  25,  25,  24,  23,  23,
      22,  21,  21,  20,  19,  19,  18,  17,  17,  16,  15,  15,  14,  14,  13,
      12,  12,  11,  11,  10,  9,   9,   8,   8,   7,   7,   6,   5,   5,   4,
      4,   3,   3,   2,   2,   1,   1,   0};

  if (sub) {
    while (extract64(sig, s - 1, 1) == 0)
      exp--, sig <<= 1;

    sig = (sig << 1) & make_mask64(0, s);

    if (exp != 0 && exp != UINT64_MAX) {
      *round_abnormal = true;
      if (rm == 1 || (rm == 2 && !sign) || (rm == 3 && sign))
        return ((sign << (s + e)) | make_mask64(s, e)) - 1;
      else
        return (sign << (s + e)) | make_mask64(s, e);
    }
  }

  int idx = sig >> (s - p);
  uint64_t out_sig = (uint64_t)(table[idx]) << (s - p);
  uint64_t out_exp = 2 * make_mask64(0, e - 1) + ~exp;
  if (out_exp == 0 || out_exp == UINT64_MAX) {
    out_sig = (out_sig >> 1) | make_mask64(s - 1, 1);
    if (out_exp == UINT64_MAX) {
      out_sig >>= 1;
      out_exp = 0;
    }
  }

  return (sign << (s + e)) | (out_exp << s) | out_sig;
}

float16_t f16_recip7(float16_t in) {
  union ui16_f16 uA;

  uA.f = in;
  unsigned int ret = f16_classify(in);
  bool sub = false;
  bool round_abnormal = false;
  switch (ret) {
  case 0x001: // -inf
    uA.ui = 0x8000;
    break;
  case 0x080: //+inf
    uA.ui = 0x0;
    break;
  case 0x008: // -0
    uA.ui = 0xfc00;
    softfloat_exceptionFlags |= softfloat_flag_infinite;
    break;
  case 0x010: // +0
    uA.ui = 0x7c00;
    softfloat_exceptionFlags |= softfloat_flag_infinite;
    break;
  case 0x100: // sNaN
    softfloat_exceptionFlags |= softfloat_flag_invalid;
    [[fallthrough]];
  case 0x200: // qNaN
    uA.ui = defaultNaNF16UI;
    break;
  case 0x004: // -subnormal
  case 0x020: //+ sub
    sub = true;
    [[fallthrough]];
  default: // +- normal
    uA.ui = recip7(uA.ui, 5, 10, softfloat_roundingMode, sub, &round_abnormal);
    if (round_abnormal) {
      softfloat_exceptionFlags |= softfloat_flag_inexact | softfloat_flag_overflow;
    }
    break;
  }

  return uA.f;
}

float32_t f32_recip7(float32_t in) {
  union ui32_f32 uA;

  uA.f = in;
  unsigned int ret = f32_classify(in);
  bool sub = false;
  bool round_abnormal = false;
  switch (ret) {
  case 0x001: // -inf
    uA.ui = 0x80000000;
    break;
  case 0x080: //+inf
    uA.ui = 0x0;
    break;
  case 0x008: // -0
    uA.ui = 0xff800000;
    softfloat_exceptionFlags |= softfloat_flag_infinite;
    break;
  case 0x010: // +0
    uA.ui = 0x7f800000;
    softfloat_exceptionFlags |= softfloat_flag_infinite;
    break;
  case 0x100: // sNaN
    softfloat_exceptionFlags |= softfloat_flag_invalid;
    [[fallthrough]];
  case 0x200: // qNaN
    uA.ui = defaultNaNF32UI;
    break;
  case 0x004: // -subnormal
  case 0x020: //+ sub
    sub = true;
    [[fallthrough]];
  default: // +- normal
    uA.ui = recip7(uA.ui, 8, 23, softfloat_roundingMode, sub, &round_abnormal);
    if (round_abnormal) {
      softfloat_exceptionFlags |= softfloat_flag_inexact | softfloat_flag_overflow;
    }
    break;
  }

  return uA.f;
}

float64_t f64_recip7(float64_t in) {
  union ui64_f64 uA;

  uA.f = in;
  unsigned int ret = f64_classify(in);
  bool sub = false;
  bool round_abnormal = false;
  switch (ret) {
  case 0x001: // -inf
    uA.ui = 0x8000000000000000;
    break;
  case 0x080: //+inf
    uA.ui = 0x0;
    break;
  case 0x008: // -0
    uA.ui = 0xfff0000000000000;
    softfloat_exceptionFlags |= softfloat_flag_infinite;
    break;
  case 0x010: // +0
    uA.ui = 0x7ff0000000000000;
    softfloat_exceptionFlags |= softfloat_flag_infinite;
    break;
  case 0x100: // sNaN
    softfloat_exceptionFlags |= softfloat_flag_invalid;
    [[fallthrough]];
  case 0x200: // qNaN
    uA.ui = defaultNaNF64UI;
    break;
  case 0x004: // -subnormal
  case 0x020: //+ sub
    sub = true;
    [[fallthrough]];
  default: // +- normal
    uA.ui = recip7(uA.ui, 11, 52, softfloat_roundingMode, sub, &round_abnormal);
    if (round_abnormal) {
      softfloat_exceptionFlags |= softfloat_flag_inexact | softfloat_flag_overflow;
    }
    break;
  }

  return uA.f;
}

#ifdef __cplusplus
}
#endif
// --- End of content from sim/common/softfloat_ext.cpp ---

// --- Start of content from sim/common/util.cpp ---
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// MERGED_LOCALLY: #include "util.h"
#include <fstream>
#include <sstream>
#include <string.h>

// return file extension
const char* fileExtension(const char* filepath) {
  const char *ext = strrchr(filepath, '.');
  if (ext == NULL || ext == filepath)
    return "";
  return ext + 1;
}

void* aligned_malloc(size_t size, size_t alignment) {
  // reserve margin for alignment and storing of unaligned address
  assert((alignment & (alignment - 1)) == 0);   // Power of 2 alignment.
  size_t margin = (alignment-1) + sizeof(void*);
  void *unaligned_addr = malloc(size + margin);
  void **aligned_addr = (void**)((uintptr_t)(((uint8_t*)unaligned_addr) + margin) & ~(alignment-1));
  aligned_addr[-1] = unaligned_addr;
  return aligned_addr;
}

void aligned_free(void *ptr) {
  // retreive the stored unaligned address and use it to free the allocation
  void* unaligned_addr = ((void**)ptr)[-1];
  free(unaligned_addr);
}

std::string vortex::resolve_file_path(const std::string& filename, const std::string& searchPaths) {
  std::ifstream ifs(filename);
  if (!ifs) {
    std::stringstream ss(searchPaths);
    std::string path;
    while (std::getline(ss, path, ',')) {
      if (!path.empty()) {
        std::string filePath = path + "/" + filename;
        std::ifstream ifs(filePath);
        if (ifs)
          return filePath;
      }
    }
  }
  return filename;
}
// --- End of content from sim/common/util.cpp ---

// --- Start of content from sim/simx/cache_sim.cpp ---
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// MERGED_LOCALLY: #include "cache_sim.h"
// MERGED_LOCALLY: #include "debug.h"
// MERGED_LOCALLY: #include "types.h"
#include <util.h>
#include <unordered_map>
#include <vector>
#include <list>
#include <queue>

using namespace vortex;

struct params_t {
	uint32_t sets_per_bank;
	uint32_t lines_per_set;
	uint32_t words_per_line;
	uint32_t log2_num_inputs;

	int32_t word_select_addr_start;
	int32_t word_select_addr_end;

	int32_t bank_select_addr_start;
	int32_t bank_select_addr_end;

	int32_t set_select_addr_start;
	int32_t set_select_addr_end;

	int32_t tag_select_addr_start;
	int32_t tag_select_addr_end;

	params_t(const CacheSim::Config& config) {
		int32_t offset_bits = config.L - config.W;
		int32_t index_bits = config.C - (config.L + config.A + config.B);
		assert(offset_bits >= 0);
		assert(index_bits >= 0);

		this->log2_num_inputs = log2ceil(config.num_inputs);

		this->sets_per_bank  = 1 << index_bits;
		this->lines_per_set  = 1 << config.A;
		this->words_per_line = 1 << offset_bits;

		assert(config.ports_per_bank <= this->words_per_line);

		// Word select
		this->word_select_addr_start = config.W;
		this->word_select_addr_end = (this->word_select_addr_start+offset_bits-1);

		// Bank select
		this->bank_select_addr_start = (1+this->word_select_addr_end);
		this->bank_select_addr_end = (this->bank_select_addr_start+config.B-1);

		// Set select
		this->set_select_addr_start = (1+this->bank_select_addr_end);
		this->set_select_addr_end = (this->set_select_addr_start+index_bits-1);

		// Tag select
		this->tag_select_addr_start = (1+this->set_select_addr_end);
		this->tag_select_addr_end = (config.addr_width-1);
	}

	uint32_t addr_bank_id(uint64_t addr) const {
		if (bank_select_addr_end >= bank_select_addr_start)
			return (uint32_t)bit_getw(addr, bank_select_addr_start, bank_select_addr_end);
		else
			return 0;
	}

	uint32_t addr_set_id(uint64_t addr) const {
		if (set_select_addr_end >= set_select_addr_start)
			return (uint32_t)bit_getw(addr, set_select_addr_start, set_select_addr_end);
		else
			return 0;
	}

	uint64_t addr_tag(uint64_t addr) const {
		if (tag_select_addr_end >= tag_select_addr_start)
			return bit_getw(addr, tag_select_addr_start, tag_select_addr_end);
		else
			return 0;
	}

	uint64_t mem_addr(uint32_t bank_id, uint32_t set_id, uint64_t tag) const {
		uint64_t addr(0);
		if (bank_select_addr_end >= bank_select_addr_start)
			addr = bit_setw(addr, bank_select_addr_start, bank_select_addr_end, bank_id);
		if (set_select_addr_end >= set_select_addr_start)
			addr = bit_setw(addr, set_select_addr_start, set_select_addr_end, set_id);
		if (tag_select_addr_end >= tag_select_addr_start)
			addr = bit_setw(addr, tag_select_addr_start, tag_select_addr_end, tag);
		return addr;
	}
};

struct line_t {
	uint64_t tag;
	uint32_t lru_ctr;
	bool     valid;
	bool     dirty;

	void clear() {
		valid = false;
		dirty = false;
	}
};

struct set_t {
	std::vector<line_t> lines;

	set_t(uint32_t num_ways)
		: lines(num_ways)
	{}

	void clear() {
		for (auto& line : lines) {
			line.clear();
		}
	}
};

struct bank_req_port_t {
	uint32_t req_id;
	uint64_t req_tag;
	bool     valid;

	void clear() {
		valid = false;
	}
};

struct bank_req_t {

	enum ReqType {
		None   = 0,
		Fill   = 1,
		Replay = 2,
		Core   = 3
	};

	std::vector<bank_req_port_t> ports;
	uint64_t tag;
	uint32_t set_id;
	uint32_t cid;
	uint64_t uuid;
	ReqType  type;
	bool     write;

	bank_req_t(uint32_t num_ports)
		: ports(num_ports)
	{}

	void clear() {
		for (auto& port : ports) {
			port.clear();
		}
		type = ReqType::None;
	}
};

inline std::ostream &operator<<(std::ostream &os, const bank_req_t& req) {
  os << "set=" << req.set_id << ", rw=" << req.write;
  os << std::dec << ", type=" << req.type;
  os << ", tag=0x" << std::hex << req.tag;
	os << ", req_tags={";
	bool first_port = true;
	for (auto& port : req.ports) {
		if (port.valid) {
			if (!first_port) os << ", ";
			first_port = false;
			os << "["  << std::dec << port.req_id << "]=0x" << std::hex << port.req_tag;
		}
	}
	os << "}";
	os << std::dec << ", cid=" << req.cid;
  os << " (#" << req.uuid << ")";
  return os;
}

struct mshr_entry_t {
	bank_req_t bank_req;
	uint32_t   line_id;

	mshr_entry_t(uint32_t num_ports)
		: bank_req(num_ports)
	{}

	void clear() {
		bank_req.clear();
	}
};

class MSHR {
private:
	std::vector<mshr_entry_t> entries_;
	uint32_t size_;

public:
	MSHR(uint32_t size, uint32_t num_ports)
		: entries_(size, num_ports)
		, size_(0)
	{}

	bool empty() const {
		return (0 == size_);
	}

	bool full() const {
		return (size_ == entries_.size());
	}

	bool lookup(const bank_req_t& bank_req) {
		for (auto& entry : entries_) {;
			if (entry.bank_req.type != bank_req_t::None
		 	 && entry.bank_req.set_id == bank_req.set_id
		   && entry.bank_req.tag == bank_req.tag) {
				return true;
			}
		}
		return false;
	}

	int allocate(const bank_req_t& bank_req, uint32_t line_id) {
		for (uint32_t i = 0, n = entries_.size(); i < n; ++i) {
			auto& entry = entries_.at(i);
			if (entry.bank_req.type == bank_req_t::None) {
				entry.bank_req = bank_req;
				entry.line_id = line_id;
				++size_;
				return i;
			}
		}
		return -1;
	}

	mshr_entry_t& replay(uint32_t id) {
		auto& root_entry = entries_.at(id);
		assert(root_entry.bank_req.type == bank_req_t::Core);
		// mark all related mshr entries for replay
		for (auto& entry : entries_) {
			if (entry.bank_req.type == bank_req_t::Core
			 && entry.bank_req.set_id == root_entry.bank_req.set_id
			 && entry.bank_req.tag == root_entry.bank_req.tag) {
				entry.bank_req.type = bank_req_t::Replay;
			}
		}
		return root_entry;
	}

	bool pop(bank_req_t* out) {
		for (auto& entry : entries_) {
			if (entry.bank_req.type == bank_req_t::Replay) {
				*out = entry.bank_req;
				entry.bank_req.type = bank_req_t::None;
				--size_;
				return true;
			}
		}
		return false;
	}

	void clear() {
		for (auto& entry : entries_) {
			entry.clear();
		}
		size_ = 0;
	}
};

struct bank_t {
	std::vector<set_t> sets;
	MSHR               mshr;

	bank_t(const CacheSim::Config& config,
				 const params_t& params)
		: sets(params.sets_per_bank, params.lines_per_set)
		, mshr(config.mshr_size, config.ports_per_bank)
	{}

	void clear() {
		for (auto& set : sets) {
			set.clear();
		}
		mshr.clear();
	}
};

///////////////////////////////////////////////////////////////////////////////

class CacheSim::Impl {
private:
	CacheSim* const simobject_;
	Config config_;
	params_t params_;
	std::vector<bank_t> banks_;
	MemArbiter::Ptr bank_arb_;
	std::vector<MemArbiter::Ptr> nc_arbs_;
	std::vector<SimPort<MemReq>> mem_req_ports_;
	std::vector<SimPort<MemRsp>> mem_rsp_ports_;
	std::vector<bank_req_t> pipeline_reqs_;
	uint32_t init_cycles_;
	PerfStats perf_stats_;
	uint64_t pending_read_reqs_;
	uint64_t pending_write_reqs_;
	uint64_t pending_fill_reqs_;

public:
	Impl(CacheSim* simobject, const Config& config)
		: simobject_(simobject)
		, config_(config)
		, params_(config)
		, banks_((1 << config.B), {config, params_})
		, nc_arbs_(config.mem_ports)
		, mem_req_ports_((1 << config.B), simobject)
		, mem_rsp_ports_((1 << config.B), simobject)
		, pipeline_reqs_((1 << config.B), config.ports_per_bank)
	{
		char sname[100];

		if (config_.bypass) {
			snprintf(sname, 100, "%s-bypass-arb", simobject->name().c_str());
			auto bypass_arb = MemArbiter::Create(sname, ArbiterType::RoundRobin, config_.num_inputs, config_.mem_ports);
			for (uint32_t i = 0; i < config_.num_inputs; ++i) {
				simobject->CoreReqPorts.at(i).bind(&bypass_arb->ReqIn.at(i));
				bypass_arb->RspIn.at(i).bind(&simobject->CoreRspPorts.at(i));
			}
			for (uint32_t i = 0; i < config_.mem_ports; ++i) {
				bypass_arb->ReqOut.at(i).bind(&simobject->MemReqPorts.at(i));
				simobject->MemRspPorts.at(i).bind(&bypass_arb->RspOut.at(i));
			}
			return;
		}

		// create non-cacheable arbiter
		for (uint32_t i = 0; i < config_.mem_ports; ++i) {
			snprintf(sname, 100, "%s-nc-arb%d", simobject->name().c_str(), i);
			nc_arbs_.at(i) = MemArbiter::Create(sname, ArbiterType::Priority, 2, 1);
		}

		// Connect non-cacheable arbiter output to outgoing memory ports
		for (uint32_t i = 0; i < config_.mem_ports; ++i) {
			nc_arbs_.at(i)->ReqOut.at(0).bind(&simobject->MemReqPorts.at(i));
			simobject->MemRspPorts.at(i).bind(&nc_arbs_.at(i)->RspOut.at(0));
		}

		// Create bank's memory arbiter
		snprintf(sname, 100, "%s-bank-arb", simobject->name().c_str());
		auto bank_mem_arb = MemArbiter::Create(sname, ArbiterType::RoundRobin, (1 << config.B), config_.mem_ports);
		for (uint32_t i = 0, n = (1 << config.B); i < n; ++i) {
			mem_req_ports_.at(i).bind(&bank_mem_arb->ReqIn.at(i));
			bank_mem_arb->RspIn.at(i).bind(&mem_rsp_ports_.at(i));
		}

		// Connect bank's memory arbiter to non-cacheable arbiter's input 0
		for (uint32_t i = 0; i < config_.mem_ports; ++i) {
			bank_mem_arb->ReqOut.at(i).bind(&nc_arbs_.at(i)->ReqIn.at(0));
			nc_arbs_.at(i)->RspIn.at(0).bind(&bank_mem_arb->RspOut.at(i));
		}

		// calculate cache initialization cycles
		init_cycles_ = params_.sets_per_bank * params_.lines_per_set;
	}

  void reset() {
		if (config_.bypass)
			return;

		for (auto& bank : banks_) {
			bank.clear();
		}
		perf_stats_ = PerfStats();
		pending_read_reqs_  = 0;
		pending_write_reqs_ = 0;
		pending_fill_reqs_  = 0;
	}

  void tick() {
		if (config_.bypass)
			return;

		// wait on cache initialization cycles
		if (init_cycles_ != 0) {
			--init_cycles_;
			return;
		}

		// handle cache bypasss responses
		for (uint32_t i = 0, n = config_.mem_ports; i < n; ++i) {
			auto& bypass_port = nc_arbs_.at(i)->RspIn.at(1);
			if (!bypass_port.empty()) {
				auto& mem_rsp = bypass_port.front();
				this->processBypassResponse(mem_rsp);
				bypass_port.pop();
			}
		}

		// initialize pipeline request
		for (auto& pipeline_req : pipeline_reqs_) {
			pipeline_req.clear();
		}

		// first: schedule MSHR replay (flush MSHR queue)
		for (uint32_t bank_id = 0, n = (1 << config_.B); bank_id < n; ++bank_id) {
			auto& bank = banks_.at(bank_id);
			auto& pipeline_req = pipeline_reqs_.at(bank_id);
			bank.mshr.pop(&pipeline_req);
		}

		// second: schedule memory fill (flush memory queue)
		for (uint32_t bank_id = 0, n = (1 << config_.B); bank_id < n; ++bank_id) {
			auto& mem_rsp_port = mem_rsp_ports_.at(bank_id);
			if (mem_rsp_port.empty())
				continue;

			auto& pipeline_req = pipeline_reqs_.at(bank_id);

			// skip if bank already busy
			if (pipeline_req.type != bank_req_t::None)
				continue;

			auto& mem_rsp = mem_rsp_port.front();
			DT(3, simobject_->name() << "-bank" << bank_id << "-fill-rsp: " << mem_rsp);
			pipeline_req.type = bank_req_t::Fill;
			pipeline_req.tag = mem_rsp.tag;
			mem_rsp_port.pop();
		}

		// last: schedule core requests (flush core queue)
		for (uint32_t req_id = 0, n = config_.num_inputs; req_id < n; ++req_id) {
			auto& core_req_port = simobject_->CoreReqPorts.at(req_id);
			if (core_req_port.empty())
				continue;

			auto& core_req = core_req_port.front();

			// check cache bypassing
			if (core_req.type == AddrType::IO) {
				// send bypass request
				this->processBypassRequest(core_req, req_id);
				// remove request
				core_req_port.pop();
				continue;
			}

			auto bank_id = params_.addr_bank_id(core_req.addr);
			auto& bank = banks_.at(bank_id);
			auto& pipeline_req = pipeline_reqs_.at(bank_id);

			// skip if bank already busy
			if (pipeline_req.type != bank_req_t::None)
				continue;

			auto set_id  = params_.addr_set_id(core_req.addr);
			auto tag     = params_.addr_tag(core_req.addr);
			auto port_id = req_id % config_.ports_per_bank;

			// check MSHR capacity
			if ((!core_req.write || config_.write_back)
		   && bank.mshr.full()) {
				++perf_stats_.mshr_stalls;
				continue;
			}

			// check bank conflicts
			if (pipeline_req.type == bank_req_t::Core) {
				// check port conflict
				if (pipeline_req.write != core_req.write
				 || pipeline_req.set_id != set_id
				 || pipeline_req.tag != tag
				 || pipeline_req.ports.at(port_id).valid) {
					++perf_stats_.bank_stalls;
					continue;
				}
				// extend request ports
				pipeline_req.ports.at(port_id) = bank_req_port_t{req_id, core_req.tag, true};
			} else {
				// schedule new request
				bank_req_t bank_req(config_.ports_per_bank);
				bank_req.ports.at(port_id) = bank_req_port_t{req_id, core_req.tag, true};
				bank_req.tag   = tag;
				bank_req.set_id = set_id;
				bank_req.cid   = core_req.cid;
				bank_req.uuid  = core_req.uuid;
				bank_req.type  = bank_req_t::Core;
				bank_req.write = core_req.write;
				pipeline_req   = bank_req;
				DT(3, simobject_->name() << "-core-req: " << core_req);
			}

			if (core_req.write)
				++perf_stats_.writes;
			else
				++perf_stats_.reads;

			// remove request
			auto time = core_req_port.pop();
			perf_stats_.pipeline_stalls += (SimPlatform::instance().cycles() - time);
		}

		// process active request
		this->processBankRequests();
	}

	const PerfStats& perf_stats() const {
		return perf_stats_;
	}

private:

	void processBypassResponse(const MemRsp& mem_rsp) {
		uint32_t req_id = mem_rsp.tag & ((1 << params_.log2_num_inputs)-1);
		uint64_t tag = mem_rsp.tag >> params_.log2_num_inputs;
		MemRsp core_rsp{tag, mem_rsp.cid, mem_rsp.uuid};
		simobject_->CoreRspPorts.at(req_id).push(core_rsp, config_.latency);
		DT(3, simobject_->name() << "-bypass-core-rsp: " << core_rsp);
	}

	void processBypassRequest(const MemReq& core_req, uint32_t req_id) {
		{
			MemReq mem_req(core_req);
			mem_req.tag = (core_req.tag << params_.log2_num_inputs) + req_id;
			uint32_t mem_port = req_id % config_.mem_ports;
			nc_arbs_.at(mem_port)->ReqIn.at(1).push(mem_req, 1);
			DT(3, simobject_->name() << "-bypass-dram-req: " << mem_req);
		}

		if (core_req.write && config_.write_reponse) {
			MemRsp core_rsp{core_req.tag, core_req.cid, core_req.uuid};
			simobject_->CoreRspPorts.at(req_id).push(core_rsp, 1);
			DT(3, simobject_->name() << "-bypass-core-rsp: " << core_rsp);
		}
	}

	void processBankRequests() {
		for (uint32_t bank_id = 0, n = (1 << config_.B); bank_id < n; ++bank_id) {
			auto& bank = banks_.at(bank_id);
			auto pipeline_req = pipeline_reqs_.at(bank_id);

			switch (pipeline_req.type) {
			case bank_req_t::None:
				break;
			case bank_req_t::Fill: {
				// update cache line
				auto& bank  = banks_.at(bank_id);
				auto& entry = bank.mshr.replay(pipeline_req.tag);
				auto& set   = bank.sets.at(entry.bank_req.set_id);
				auto& line  = set.lines.at(entry.line_id);
				line.valid  = true;
				line.tag    = entry.bank_req.tag;
				--pending_fill_reqs_;
			} break;
			case bank_req_t::Replay: {
				// send core response
				if (!pipeline_req.write || config_.write_reponse) {
					for (auto& info : pipeline_req.ports) {
						if (!info.valid)
							continue;
						MemRsp core_rsp{info.req_tag, pipeline_req.cid, pipeline_req.uuid};
						simobject_->CoreRspPorts.at(info.req_id).push(core_rsp, config_.latency);
						DT(3, simobject_->name() << "-bank" << bank_id << "-replay: " << core_rsp);
					}
				}
			} break;
			case bank_req_t::Core: {
				int32_t hit_line_id  = -1;
				int32_t free_line_id = -1;
				int32_t repl_line_id = 0;
				uint32_t max_cnt = 0;

				auto& set = bank.sets.at(pipeline_req.set_id);

				// tag lookup
				for (uint32_t i = 0, n = set.lines.size(); i < n; ++i) {
					auto& line = set.lines.at(i);
					if (max_cnt < line.lru_ctr) {
						max_cnt = line.lru_ctr;
						repl_line_id = i;
					}
					if (line.valid) {
						if (line.tag == pipeline_req.tag) {
							hit_line_id = i;
							line.lru_ctr = 0;
						} else {
							++line.lru_ctr;
						}
					} else {
						free_line_id = i;
					}
				}

				if (hit_line_id != -1) {
					// Hit handling
					if (pipeline_req.write) {
						// handle write has_hit
						auto& hit_line = set.lines.at(hit_line_id);
						if (!config_.write_back) {
							// forward write request to memory
							MemReq mem_req;
							mem_req.addr  = params_.mem_addr(bank_id, pipeline_req.set_id, pipeline_req.tag);
							mem_req.write = true;
							mem_req.cid   = pipeline_req.cid;
							mem_req.uuid  = pipeline_req.uuid;
							mem_req_ports_.at(bank_id).push(mem_req, 1);
							DT(3, simobject_->name() << "-bank" << bank_id << "-writethrough: " << mem_req);
						} else {
							// mark line as dirty
							hit_line.dirty = true;
						}
					}
					// send core response
					if (!pipeline_req.write || config_.write_reponse) {
						for (auto& info : pipeline_req.ports) {
							if (!info.valid)
								continue;
							MemRsp core_rsp{info.req_tag, pipeline_req.cid, pipeline_req.uuid};
							simobject_->CoreRspPorts.at(info.req_id).push(core_rsp, config_.latency);
							DT(3, simobject_->name() << "-bank" << bank_id << "-core-rsp: " << core_rsp);
						}
					}
				} else {
					// Miss handling
					if (pipeline_req.write)
						++perf_stats_.write_misses;
					else
						++perf_stats_.read_misses;

					if (free_line_id == -1 && config_.write_back) {
						// write back dirty line
						auto& repl_line = set.lines.at(repl_line_id);
						if (repl_line.dirty) {
							MemReq mem_req;
							mem_req.addr  = params_.mem_addr(bank_id, pipeline_req.set_id, repl_line.tag);
							mem_req.write = true;
							mem_req.cid   = pipeline_req.cid;
							mem_req_ports_.at(bank_id).push(mem_req, 1);
							DT(3, simobject_->name() << "-bank" << bank_id << "-writeback: " << mem_req);
							++perf_stats_.evictions;
						}
					}

					if (pipeline_req.write && !config_.write_back) {
						// forward write request to memory
						{
							MemReq mem_req;
							mem_req.addr  = params_.mem_addr(bank_id, pipeline_req.set_id, pipeline_req.tag);
							mem_req.write = true;
							mem_req.cid   = pipeline_req.cid;
							mem_req.uuid  = pipeline_req.uuid;
							mem_req_ports_.at(bank_id).push(mem_req, 1);
							DT(3, simobject_->name() << "-bank" << bank_id << "-writethrough: " << mem_req);
						}
						// send core response
						if (config_.write_reponse) {
							for (auto& info : pipeline_req.ports) {
								if (!info.valid)
									continue;
								MemRsp core_rsp{info.req_tag, pipeline_req.cid, pipeline_req.uuid};
								simobject_->CoreRspPorts.at(info.req_id).push(core_rsp, config_.latency);
								DT(3, simobject_->name() << "-bank" << bank_id << "-core-rsp: " << core_rsp);
							}
						}
					} else {
						// MSHR lookup
						auto mshr_pending = bank.mshr.lookup(pipeline_req);

						// allocate MSHR
						auto mshr_id = bank.mshr.allocate(pipeline_req, (free_line_id != -1) ? free_line_id : repl_line_id);
						DT(3, simobject_->name() << "-bank" << bank_id << "-mshr-enqueue: " << pipeline_req);

						// send fill request
						if (!mshr_pending) {
							MemReq mem_req;
							mem_req.addr  = params_.mem_addr(bank_id, pipeline_req.set_id, pipeline_req.tag);
							mem_req.write = false;
							mem_req.tag   = mshr_id;
							mem_req.cid   = pipeline_req.cid;
							mem_req.uuid  = pipeline_req.uuid;
							mem_req_ports_.at(bank_id).push(mem_req, 1);
							DT(3, simobject_->name() << "-bank" << bank_id << "-fill: " << mem_req);
							++pending_fill_reqs_;
						}
					}
				}
			} break;
			}
		}
		// calculate memory latency
		perf_stats_.mem_latency += pending_fill_reqs_;
	}
};

///////////////////////////////////////////////////////////////////////////////

CacheSim::CacheSim(const SimContext& ctx, const char* name, const Config& config)
	: SimObject<CacheSim>(ctx, name)
	, CoreReqPorts(config.num_inputs, this)
	, CoreRspPorts(config.num_inputs, this)
	, MemReqPorts(config.mem_ports, this)
	, MemRspPorts(config.mem_ports, this)
	, impl_(new Impl(this, config))
{}

CacheSim::~CacheSim() {
  delete impl_;
}

void CacheSim::reset() {
  impl_->reset();
}

void CacheSim::tick() {
  impl_->tick();
}

const CacheSim::PerfStats& CacheSim::perf_stats() const {
  return impl_->perf_stats();
}
// --- End of content from sim/simx/cache_sim.cpp ---

// --- Start of content from sim/simx/cluster.cpp ---
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// MERGED_LOCALLY: #include "cluster.h"

using namespace vortex;

Cluster::Cluster(const SimContext& ctx,
                 uint32_t cluster_id,
                 ProcessorImpl* processor,
                 const Arch &arch,
                 const DCRS &dcrs)
  : SimObject(ctx, StrFormat("cluster%d", cluster_id))
  , mem_req_ports(L2_MEM_PORTS, this)
  , mem_rsp_ports(L2_MEM_PORTS, this)
  , cluster_id_(cluster_id)
  , processor_(processor)
  , sockets_(NUM_SOCKETS)
  , barriers_(arch.num_barriers(), 0)
  , cores_per_socket_(arch.socket_size())
{
  char sname[100];

  uint32_t sockets_per_cluster = sockets_.size();

  // create sockets

  for (uint32_t i = 0; i < sockets_per_cluster; ++i) {
    uint32_t socket_id = cluster_id * sockets_per_cluster + i;
    sockets_.at(i) = Socket::Create(socket_id, this, arch, dcrs);
  }

  // Create l2cache

  snprintf(sname, 100, "%s-l2cache", this->name().c_str());
  l2cache_ = CacheSim::Create(sname, CacheSim::Config{
    !L2_ENABLED,
    log2ceil(L2_CACHE_SIZE),// C
    log2ceil(MEM_BLOCK_SIZE),// L
    log2ceil(L1_LINE_SIZE), // W
    log2ceil(L2_NUM_WAYS),  // A
    log2ceil(L2_NUM_BANKS), // B
    XLEN,                   // address bits
    1,                      // number of ports
    L2_NUM_REQS,            // request size
    L2_MEM_PORTS,           // memory ports
    L2_WRITEBACK,           // write-back
    false,                  // write response
    L2_MSHR_SIZE,           // mshr size
    2,                      // pipeline latency
  });

  // connect l2cache core interfaces
  for (uint32_t i = 0; i < sockets_per_cluster; ++i) {
    for (uint32_t j = 0; j < L1_MEM_PORTS; ++j) {
      sockets_.at(i)->mem_req_ports.at(j).bind(&l2cache_->CoreReqPorts.at(i * L1_MEM_PORTS + j));
      l2cache_->CoreRspPorts.at(i * L1_MEM_PORTS + j).bind(&sockets_.at(i)->mem_rsp_ports.at(j));
    }
  }

  // connect l2cache memory interfaces
  for (uint32_t i = 0; i < L2_MEM_PORTS; ++i) {
    l2cache_->MemReqPorts.at(i).bind(&this->mem_req_ports.at(i));
    this->mem_rsp_ports.at(i).bind(&l2cache_->MemRspPorts.at(i));
  }
}

Cluster::~Cluster() {
  //--
}

void Cluster::reset() {
  for (auto& barrier : barriers_) {
    barrier.reset();
  }
}

void Cluster::tick() {
  //--
}

void Cluster::attach_ram(RAM* ram) {
  for (auto& socket : sockets_) {
    socket->attach_ram(ram);
  }
}

#ifdef VM_ENABLE
void Cluster::set_satp(uint64_t satp) {
  for (auto& socket : sockets_) {
    socket->set_satp(satp);
  }
}
#endif

bool Cluster::running() const {
  for (auto& socket : sockets_) {
    if (socket->running())
      return true;
  }
  return false;
}

int Cluster::get_exitcode() const {
  int exitcode = 0;
  for (auto& socket : sockets_) {
    exitcode |= socket->get_exitcode();
  }
  return exitcode;
}

void Cluster::barrier(uint32_t bar_id, uint32_t count, uint32_t core_id) {
  auto& barrier = barriers_.at(bar_id);

  auto sockets_per_cluster = sockets_.size();
  auto cores_per_socket = cores_per_socket_;

  uint32_t cores_per_cluster = sockets_per_cluster * cores_per_socket;
  uint32_t local_core_id = core_id % cores_per_cluster;
  barrier.set(local_core_id);

  DP(3, "*** Suspend core #" << core_id << " at barrier #" << bar_id);

  if (barrier.count() == (size_t)count) {
      // resume all suspended cores
      for (uint32_t s = 0; s < sockets_per_cluster; ++s) {
        for (uint32_t c = 0; c < cores_per_socket; ++c) {
          uint32_t i = s * cores_per_socket + c;
          if (barrier.test(i)) {
            DP(3, "*** Resume core #" << i << " at barrier #" << bar_id);
            sockets_.at(s)->resume(c);
          }
        }
      }
      barrier.reset();
    }
}

Cluster::PerfStats Cluster::perf_stats() const {
  PerfStats perf_stats;
  perf_stats.l2cache = l2cache_->perf_stats();
  return perf_stats;
}
// --- End of content from sim/simx/cluster.cpp ---

// --- Start of content from sim/simx/core.cpp ---
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#include <iostream>
#include <iomanip>
#include <string.h>
#include <assert.h>
#include <util.h>
// MERGED_LOCALLY: #include "types.h"
// MERGED_LOCALLY: #include "arch.h"
// MERGED_LOCALLY: #include "mem.h"
// MERGED_LOCALLY: #include "core.h"
// MERGED_LOCALLY: #include "debug.h"
// MERGED_LOCALLY: #include "constants.h"

using namespace vortex;

Core::Core(const SimContext& ctx,
           uint32_t core_id,
           Socket* socket,
           const Arch &arch,
           const DCRS &dcrs)
  : SimObject(ctx, StrFormat("core%d", core_id))
  , icache_req_ports(1, this)
  , icache_rsp_ports(1, this)
  , dcache_req_ports(DCACHE_NUM_REQS, this)
  , dcache_rsp_ports(DCACHE_NUM_REQS, this)
  , core_id_(core_id)
  , socket_(socket)
  , arch_(arch)
  , emulator_(arch, dcrs, this)
  , ibuffers_(arch.num_warps(), IBUF_SIZE)
  , scoreboard_(arch_)
  , operands_(ISSUE_WIDTH)
  , dispatchers_((uint32_t)FUType::Count)
  , func_units_((uint32_t)FUType::Count)
  , lmem_switch_(NUM_LSU_BLOCKS)
  , mem_coalescers_(NUM_LSU_BLOCKS)
  , pending_icache_(arch_.num_warps())
  , commit_arbs_(ISSUE_WIDTH)
{
  char sname[100];

  for (uint32_t i = 0; i < ISSUE_WIDTH; ++i) {
    operands_.at(i) = SimPlatform::instance().create_object<Operand>();
  }

  // create the memory coalescer
  for (uint32_t i = 0; i < NUM_LSU_BLOCKS; ++i) {
    snprintf(sname, 100, "%s-coalescer%d", this->name().c_str(), i);
    mem_coalescers_.at(i) = MemCoalescer::Create(sname, LSU_CHANNELS, DCACHE_CHANNELS, DCACHE_WORD_SIZE, LSUQ_OUT_SIZE, 1);
  }

  // create local memory
  snprintf(sname, 100, "%s-lmem", this->name().c_str());
  local_mem_ = LocalMem::Create(sname, LocalMem::Config{
    (1 << LMEM_LOG_SIZE),
    LSU_WORD_SIZE,
    LSU_CHANNELS,
    log2ceil(LMEM_NUM_BANKS),
    false
  });

  // create lmem switch
  for (uint32_t i = 0; i < NUM_LSU_BLOCKS; ++i) {
    snprintf(sname, 100, "%s-lmem_switch%d", this->name().c_str(), i);
    lmem_switch_.at(i) = LocalMemSwitch::Create(sname, 1);
  }

  // create dcache adapter
  std::vector<LsuMemAdapter::Ptr> lsu_dcache_adapter(NUM_LSU_BLOCKS);
  for (uint32_t i = 0; i < NUM_LSU_BLOCKS; ++i) {
    snprintf(sname, 100, "%s-lsu_dcache_adapter%d", this->name().c_str(), i);
    lsu_dcache_adapter.at(i) = LsuMemAdapter::Create(sname, DCACHE_CHANNELS, 1);
  }

  // create lmem arbiter
  snprintf(sname, 100, "%s-lmem_arb", this->name().c_str());
  auto lmem_arb = LsuArbiter::Create(sname, ArbiterType::RoundRobin, NUM_LSU_BLOCKS, 1);

  // create lmem adapter
  snprintf(sname, 100, "%s-lsu_lmem_adapter", this->name().c_str());
  auto lsu_lmem_adapter = LsuMemAdapter::Create(sname, LSU_CHANNELS, 1);

  // connect lmem switch
  for (uint32_t b = 0; b < NUM_LSU_BLOCKS; ++b) {
    lmem_switch_.at(b)->ReqDC.bind(&mem_coalescers_.at(b)->ReqIn);
    lmem_switch_.at(b)->ReqLmem.bind(&lmem_arb->ReqIn.at(b));

    mem_coalescers_.at(b)->RspIn.bind(&lmem_switch_.at(b)->RspDC);
    lmem_arb->RspIn.at(b).bind(&lmem_switch_.at(b)->RspLmem);
  }

  // connect lmem arbiter
  lmem_arb->ReqOut.at(0).bind(&lsu_lmem_adapter->ReqIn);
  lsu_lmem_adapter->RspIn.bind(&lmem_arb->RspOut.at(0));

  // connect lmem adapter
  for (uint32_t c = 0; c < LSU_CHANNELS; ++c) {
    lsu_lmem_adapter->ReqOut.at(c).bind(&local_mem_->Inputs.at(c));
    local_mem_->Outputs.at(c).bind(&lsu_lmem_adapter->RspOut.at(c));
  }

  // connect dcache coalescer
  for (uint32_t b = 0; b < NUM_LSU_BLOCKS; ++b) {
    mem_coalescers_.at(b)->ReqOut.bind(&lsu_dcache_adapter.at(b)->ReqIn);
    lsu_dcache_adapter.at(b)->RspIn.bind(&mem_coalescers_.at(b)->RspOut);
  }

  // connect dcache adapter
  for (uint32_t b = 0; b < NUM_LSU_BLOCKS; ++b) {
    for (uint32_t c = 0; c < DCACHE_CHANNELS; ++c) {
      uint32_t i = b * DCACHE_CHANNELS + c;
      lsu_dcache_adapter.at(b)->ReqOut.at(c).bind(&dcache_req_ports.at(i));
      dcache_rsp_ports.at(i).bind(&lsu_dcache_adapter.at(b)->RspOut.at(c));
    }
  }

  // initialize dispatchers
  dispatchers_.at((int)FUType::ALU) = SimPlatform::instance().create_object<Dispatcher>(arch, 2, NUM_ALU_BLOCKS, NUM_ALU_LANES);
  dispatchers_.at((int)FUType::FPU) = SimPlatform::instance().create_object<Dispatcher>(arch, 2, NUM_FPU_BLOCKS, NUM_FPU_LANES);
  dispatchers_.at((int)FUType::LSU) = SimPlatform::instance().create_object<Dispatcher>(arch, 2, NUM_LSU_BLOCKS, NUM_LSU_LANES);
  dispatchers_.at((int)FUType::SFU) = SimPlatform::instance().create_object<Dispatcher>(arch, 2, NUM_SFU_BLOCKS, NUM_SFU_LANES);
  dispatchers_.at((int)FUType::TCU) = SimPlatform::instance().create_object<Dispatcher>(arch, 2, NUM_TCU_BLOCKS, NUM_TCU_LANES);

  // initialize execute units
  func_units_.at((int)FUType::ALU) = SimPlatform::instance().create_object<AluUnit>(this);
  func_units_.at((int)FUType::FPU) = SimPlatform::instance().create_object<FpuUnit>(this);
  func_units_.at((int)FUType::LSU) = SimPlatform::instance().create_object<LsuUnit>(this);
  func_units_.at((int)FUType::SFU) = SimPlatform::instance().create_object<SfuUnit>(this);
  func_units_.at((int)FUType::TCU) = SimPlatform::instance().create_object<TcuUnit>(this);

  // bind commit arbiters
  for (uint32_t i = 0; i < ISSUE_WIDTH; ++i) {
    snprintf(sname, 100, "%s-commit-arb%d", this->name().c_str(), i);
    auto arbiter = TraceArbiter::Create(sname, ArbiterType::RoundRobin, (uint32_t)FUType::Count, 1);
    for (uint32_t j = 0; j < (uint32_t)FUType::Count; ++j) {
      func_units_.at(j)->Outputs.at(i).bind(&arbiter->Inputs.at(j));
    }
    commit_arbs_.at(i) = arbiter;
  }

  this->reset();
}

Core::~Core() {
  //--
}

void Core::reset() {

  emulator_.clear();

  for (auto& commit_arb : commit_arbs_) {
    commit_arb->reset();
  }

  for (auto& ibuf : ibuffers_) {
    ibuf.clear();
  }

  scoreboard_.clear();
  fetch_latch_.clear();
  decode_latch_.clear();
  pending_icache_.clear();

  ibuffer_idx_ = 0;
  pending_instrs_ = 0;
  pending_ifetches_ = 0;

  perf_stats_ = PerfStats();
}

void Core::tick() {
  this->commit();
  this->execute();
  this->issue();
  this->decode();
  this->fetch();
  this->schedule();

  ++perf_stats_.cycles;
  DPN(2, std::flush);
}

void Core::schedule() {
  auto trace = emulator_.step();
  if (trace == nullptr) {
    ++perf_stats_.sched_idle;
    return;
  }

  // suspend warp until decode
  emulator_.suspend(trace->wid);

  DT(3, "pipeline-schedule: " << *trace);

    // track active threads
  perf_stats_.total_issued_warps += 1;
    // tmask是一个OneHot的bitset，表示当前warp中活跃的线程，count()表示活跃线程的数量
  perf_stats_.total_active_threads += trace->tmask.count();

  // advance to fetch stage
  fetch_latch_.push(trace);
  ++pending_instrs_;
}

void Core::fetch() {
  perf_stats_.ifetch_latency += pending_ifetches_;

  // handle icache response
  auto& icache_rsp_port = icache_rsp_ports.at(0);
  if (!icache_rsp_port.empty()){
    auto& mem_rsp = icache_rsp_port.front();
    auto trace = pending_icache_.at(mem_rsp.tag);
    decode_latch_.push(trace);
    DT(3, "icache-rsp: addr=0x" << std::hex << trace->PC << ", tag=0x" << mem_rsp.tag << std::dec << ", " << *trace);
    pending_icache_.release(mem_rsp.tag);
    icache_rsp_port.pop();
    --pending_ifetches_;
  }

  // send icache request
  if (fetch_latch_.empty())
    return;
  auto trace = fetch_latch_.front();
  MemReq mem_req;
  mem_req.addr  = trace->PC;
  mem_req.write = false;
  mem_req.tag   = pending_icache_.allocate(trace);
  mem_req.cid   = trace->cid;
  mem_req.uuid  = trace->uuid;
  icache_req_ports.at(0).push(mem_req, 2);
  DT(3, "icache-req: addr=0x" << std::hex << mem_req.addr << ", tag=0x" << mem_req.tag << std::dec << ", " << *trace);
  fetch_latch_.pop();
  ++perf_stats_.ifetches;
  ++pending_ifetches_;
}

void Core::decode() {
  if (decode_latch_.empty())
    return;

  auto trace = decode_latch_.front();

  // check ibuffer capacity
  auto& ibuffer = ibuffers_.at(trace->wid);
  if (ibuffer.full()) {
    if (!trace->log_once(true)) {
      DT(4, "*** ibuffer-stall: " << *trace);
    }
    ++perf_stats_.ibuf_stalls;
    return;
  } else {
    trace->log_once(false);
  }

  // release warp
  if (!trace->fetch_stall) {
    emulator_.resume(trace->wid);
  }

  DT(3, "pipeline-decode: " << *trace);

  // insert to ibuffer
  ibuffer.push(trace);

  decode_latch_.pop();
}

void Core::issue() {
  // operands to dispatchers
  for (uint32_t i = 0; i < ISSUE_WIDTH; ++i) {
    auto& operand = operands_.at(i);
    if (operand->Output.empty())
      continue;
    auto trace = operand->Output.front();
    if (dispatchers_.at((int)trace->fu_type)->push(i, trace)) {
      operand->Output.pop();
      trace->log_once(false);
    } else {
      if (!trace->log_once(true)) {
        DT(4, "*** dispatch-stall: " << *trace);
      }
    }
  }

  // issue ibuffer instructions
  for (uint32_t i = 0; i < ISSUE_WIDTH; ++i) {
    bool has_instrs = false;
    bool found_match = false;
    for (uint32_t w = 0; w < PER_ISSUE_WARPS; ++w) {
      uint32_t kk = (ibuffer_idx_ + w) % PER_ISSUE_WARPS;
      uint32_t ii = kk * ISSUE_WIDTH + i;
      auto& ibuffer = ibuffers_.at(ii);
      if (ibuffer.empty())
        continue;
      // check scoreboard
      has_instrs = true;
      auto trace = ibuffer.top();
      if (scoreboard_.in_use(trace)) {
        auto uses = scoreboard_.get_uses(trace);
        if (!trace->log_once(true)) {
          DTH(4, "*** scoreboard-stall: dependents={");
          for (uint32_t j = 0, n = uses.size(); j < n; ++j) {
            auto& use = uses.at(j);
            __unused (use);
            if (j) DTN(4, ", ");
            DTN(4, use.reg_type << use.reg_id << "(#" << use.uuid << ")");
          }
          DTN(4, "}, " << *trace << std::endl);
        }
        for (uint32_t j = 0, n = uses.size(); j < n; ++j) {
          auto& use = uses.at(j);
          switch (use.fu_type) {
          case FUType::ALU: ++perf_stats_.scrb_alu; break;
          case FUType::FPU: ++perf_stats_.scrb_fpu; break;
          case FUType::LSU: ++perf_stats_.scrb_lsu; break;
          case FUType::SFU: {
            ++perf_stats_.scrb_sfu;
            switch (use.sfu_type) {
            case SfuType::TMC:
            case SfuType::WSPAWN:
            case SfuType::SPLIT:
            case SfuType::JOIN:
            case SfuType::BAR:
            case SfuType::PRED: ++perf_stats_.scrb_wctl; break;
            case SfuType::CSRRW:
            case SfuType::CSRRS:
            case SfuType::CSRRC: ++perf_stats_.scrb_csrs; break;
            default: assert(false);
            }
          } break;
          default: assert(false);
          }
        }
      } else {
        trace->log_once(false);
        // update scoreboard
        DT(3, "pipeline-scoreboard: " << *trace);
        if (trace->wb) {
          scoreboard_.reserve(trace);
        }
        // to operand stage
        operands_.at(i)->Input.push(trace, 2);
        ibuffer.pop();
        found_match = true;
        break;
      }
    }
    if (has_instrs && !found_match) {
      ++perf_stats_.scrb_stalls;
    }
  }
  ++ibuffer_idx_;
}

void Core::execute() {
  for (uint32_t i = 0; i < (uint32_t)FUType::Count; ++i) {
    auto& dispatch = dispatchers_.at(i);
    auto& func_unit = func_units_.at(i);
    for (uint32_t j = 0; j < ISSUE_WIDTH; ++j) {
      if (dispatch->Outputs.at(j).empty())
        continue;
      auto trace = dispatch->Outputs.at(j).front();
      func_unit->Inputs.at(j).push(trace, 2);
      dispatch->Outputs.at(j).pop();
    }
  }
}

void Core::commit() {
  // process completed instructions
  for (uint32_t i = 0; i < ISSUE_WIDTH; ++i) {
    auto& commit_arb = commit_arbs_.at(i);
    if (commit_arb->Outputs.at(0).empty())
      continue;
    auto trace = commit_arb->Outputs.at(0).front();

    // advance to commit stage
    DT(3, "pipeline-commit: " << *trace);
    assert(trace->cid == core_id_);

    // update scoreboard
    if (trace->eop) {
      if (trace->wb) {
        scoreboard_.release(trace);
      }

      --pending_instrs_;
      // tmask
      perf_stats_.instrs += trace->tmask.count();
    }

    perf_stats_.opds_stalls = 0;
    for (uint32_t i = 0; i < ISSUE_WIDTH; ++i) {
      perf_stats_.opds_stalls += operands_.at(i)->total_stalls();
    }

    commit_arb->Outputs.at(0).pop();

    // delete the trace
    delete trace;
  }
}

int Core::get_exitcode() const {
  return emulator_.get_exitcode();
}

bool Core::running() const {
  return emulator_.running() || (pending_instrs_ != 0);
}

void Core::resume(uint32_t wid) {
  emulator_.resume(wid);
}

bool Core::barrier(uint32_t bar_id, uint32_t count, uint32_t wid) {
  return emulator_.barrier(bar_id, count, wid);
}

bool Core::wspawn(uint32_t num_warps, Word nextPC) {
  return emulator_.wspawn(num_warps, nextPC);
}

void Core::attach_ram(RAM* ram) {
  emulator_.attach_ram(ram);
}

#ifdef VM_ENABLE
void Core::set_satp(uint64_t satp) {
  emulator_.set_satp(satp); //JAEWON wit, tid???
  // emulator_.set_csr(VX_CSR_SATP,satp,0,0); //JAEWON wit, tid???
}
#endif
// --- End of content from sim/simx/core.cpp ---

// --- Start of content from sim/simx/dcrs.cpp ---
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// MERGED_LOCALLY: #include "dcrs.h"
#include <iostream>

using namespace vortex;

void DCRS::write(uint32_t addr, uint32_t value) {
  if (addr >= VX_DCR_BASE_STATE_BEGIN
   && addr < VX_DCR_BASE_STATE_END) {
      base_dcrs.write(addr, value);
      return;
  }

  std::cout << "Error: invalid global DCR addr=0x" << std::hex << addr << std::dec << std::endl;
  std::abort();
}
// --- End of content from sim/simx/dcrs.cpp ---

// --- Start of content from sim/simx/decode.cpp ---
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#include <iostream>
#include <string>
#include <stdlib.h>
#include <string.h>
#include <iomanip>
#include <vector>
#include <unordered_map>
#include <util.h>
// MERGED_LOCALLY: #include "debug.h"
// MERGED_LOCALLY: #include "types.h"
// MERGED_LOCALLY: #include "emulator.h"
// MERGED_LOCALLY: #include "arch.h"
// MERGED_LOCALLY: #include "instr.h"

using namespace vortex;

static const std::unordered_map<Opcode, InstType> sc_instTable = {
  {Opcode::R,       InstType::R},
  {Opcode::L,       InstType::I},
  {Opcode::I,       InstType::I},
  {Opcode::S,       InstType::S},
  {Opcode::B,       InstType::B},
  {Opcode::LUI,     InstType::U},
  {Opcode::AUIPC,   InstType::U},
  {Opcode::JAL,     InstType::J},
  {Opcode::JALR,    InstType::I},
  {Opcode::SYS,     InstType::I},
  {Opcode::FENCE,   InstType::I},
  {Opcode::AMO,     InstType::R},
  {Opcode::FL,      InstType::I},
  {Opcode::FS,      InstType::S},
  {Opcode::FCI,     InstType::R},
  {Opcode::FMADD,   InstType::R4},
  {Opcode::FMSUB,   InstType::R4},
  {Opcode::FMNMADD, InstType::R4},
  {Opcode::FMNMSUB, InstType::R4},
  {Opcode::VSET,    InstType::V},
  {Opcode::EXT1,    InstType::R},
  {Opcode::EXT2,    InstType::R4},
  {Opcode::R_W,     InstType::R},
  {Opcode::I_W,     InstType::I},
  {Opcode::TCU,     InstType::I},
};

static const char* op_string(const Instr &instr) {
  auto opcode = instr.getOpcode();
  auto func2  = instr.getFunc2();
  auto func3  = instr.getFunc3();
  auto func7  = instr.getFunc7();
  auto rd     = instr.getRDest();
  auto rs1    = instr.getRSrc(1);
  auto imm    = instr.getImm();

  switch (opcode) {
  case Opcode::LUI:   return "LUI";
  case Opcode::AUIPC: return "AUIPC";
  case Opcode::R:
    if (func7 == 0x7) {
      if (func3 == 0x5) {
        return "CZERO.EQZ";
      } else
      if (func3 == 0x7) {
        return "CZERO.NEZ";
      } else {
        std::abort();
      }
    } else
    if (func7 & 0x1) {
      switch (func3) {
      case 0: return "MUL";
      case 1: return "MULH";
      case 2: return "MULHSU";
      case 3: return "MULHU";
      case 4: return "DIV";
      case 5: return "DIVU";
      case 6: return "REM";
      case 7: return "REMU";
      default:
        std::abort();
      }
    } else {
      switch (func3) {
      case 0: return (func7 & 0x20) ? "SUB" : "ADD";
      case 1: return "SLL";
      case 2: return "SLT";
      case 3: return "SLTU";
      case 4: return "XOR";
      case 5: return (func7 & 0x20) ? "SRA" : "SRL";
      case 6: return "OR";
      case 7: return "AND";
      default:
        std::abort();
      }
    }
  case Opcode::I:
    switch (func3) {
    case 0: return "ADDI";
    case 1: return "SLLI";
    case 2: return "SLTI";
    case 3: return "SLTIU";
    case 4: return "XORI";
    case 5: return (func7 & 0x20) ? "SRAI" : "SRLI";
    case 6: return "ORI";
    case 7: return "ANDI";
    default:
      std::abort();
    }
  case Opcode::B:
    switch (func3) {
    case 0: return "BEQ";
    case 1: return "BNE";
    case 4: return "BLT";
    case 5: return "BGE";
    case 6: return "BLTU";
    case 7: return "BGEU";
    default:
      std::abort();
    }
  case Opcode::JAL:   return "JAL";
  case Opcode::JALR:  return "JALR";
  case Opcode::L:
    switch (func3) {
    case 0: return "LB";
    case 1: return "LH";
    case 2: return "LW";
    case 3: return "LD";
    case 4: return "LBU";
    case 5: return "LHU";
    case 6: return "LWU";
    default:
      std::abort();
    }
  case Opcode::S:
    switch (func3) {
    case 0: return "SB";
    case 1: return "SH";
    case 2: return "SW";
    case 3: return "SD";
    default:
      std::abort();
    }
  case Opcode::R_W:
    if (func7 & 0x1){
      switch (func3) {
      case 0: return "MULW";
      case 4: return "DIVW";
      case 5: return "DIVUW";
      case 6: return "REMW";
      case 7: return "REMUW";
      default:
        std::abort();
      }
    } else {
      switch (func3) {
      case 0: return (func7 & 0x20) ? "SUBW" : "ADDW";
      case 1: return "SLLW";
      case 5: return (func7 & 0x20) ? "SRAW" : "SRLW";
      default:
        std::abort();
      }
    }
  case Opcode::I_W:
    switch (func3) {
    case 0: return "ADDIW";
    case 1: return "SLLIW";
    case 5: return (func7 & 0x20) ? "SRAIW" : "SRLIW";
    default:
      std::abort();
    }
  case Opcode::SYS:
    switch (func3) {
    case 0:
      switch (imm) {
      case 0x000: return "ECALL";
      case 0x001: return "EBREAK";
      case 0x002: return "URET";
      case 0x102: return "SRET";
      case 0x302: return "MRET";
      default:
        std::abort();
      }
    case 1: return "CSRRW";
    case 2: return "CSRRS";
    case 3: return "CSRRC";
    case 5: return "CSRRWI";
    case 6: return "CSRRSI";
    case 7: return "CSRRCI";
    default:
      std::abort();
    }
  case Opcode::FENCE: return "FENCE";
  case Opcode::FL:
    switch (func3) {
    case 0x2: return "FLW";
    case 0x3: return "FLD";
    case 0x0: return "VL8";
    case 0x5: return "VL16";
    case 0x6: return "VL32";
    case 0x7: return "VL64";
    default:
      std::cout << "Could not decode float/vector load with func3: " << func3 << std::endl;
      std::abort();
    }
  case Opcode::FS:
    switch (func3) {
    case 0x1: return "VS";
    case 0x2: return "FSW";
    case 0x3: return "FSD";
    case 0x0: return "VS8";
    case 0x5: return "VS16";
    case 0x6: return "VS32";
    case 0x7: return "VS64";
    default:
      std::cout << "Could not decode float/vector store with func3: " << func3 << std::endl;
      std::abort();
    }
  case Opcode::AMO: {
    auto amo_type = func7 >> 2;
    switch (func3) {
      case 0x2:
        switch (amo_type) {
        case 0x00: return "AMOADD.W";
        case 0x01: return "AMOSWAP.W";
        case 0x02: return "LR.W";
        case 0x03: return "SC.W";
        case 0x04: return "AMOXOR.W";
        case 0x08: return "AMOOR.W";
        case 0x0c: return "AMOAND.W";
        case 0x10: return "AMOMIN.W";
        case 0x14: return "AMOMAX.W";
        case 0x18: return "AMOMINU.W";
        case 0x1c: return "AMOMAXU.W";
        default:
          std::abort();
        }
      case 0x3:
        switch (amo_type) {
        case 0x00: return "AMOADD.D";
        case 0x01: return "AMOSWAP.D";
        case 0x02: return "LR.D";
        case 0x03: return "SC.D";
        case 0x04: return "AMOXOR.D";
        case 0x08: return "AMOOR.D";
        case 0x0c: return "AMOAND.D";
        case 0x10: return "AMOMIN.D";
        case 0x14: return "AMOMAX.D";
        case 0x18: return "AMOMINU.D";
        case 0x1c: return "AMOMAXU.D";
        default:
          std::abort();
        }
      default:
        std::abort();
    }
  }
  case Opcode::FCI:
    switch (func7) {
    case 0x00: return "FADD.S";
    case 0x01: return "FADD.D";
    case 0x04: return "FSUB.S";
    case 0x05: return "FSUB.D";
    case 0x08: return "FMUL.S";
    case 0x09: return "FMUL.D";
    case 0x0c: return "FDIV.S";
    case 0x0d: return "FDIV.D";
    case 0x2c: return "FSQRT.S";
    case 0x2d: return "FSQRT.D";
    case 0x10:
      switch (func3) {
      case 0: return "FSGNJ.S";
      case 1: return "FSGNJN.S";
      case 2: return "FSGNJX.S";
      default:
        std::abort();
      }
    case 0x11:
      switch (func3) {
      case 0: return "FSGNJ.D";
      case 1: return "FSGNJN.D";
      case 2: return "FSGNJX.D";
      default:
        std::abort();
      }
    case 0x14:
      switch (func3) {
      case 0: return "FMIN.S";
      case 1: return "FMAX.S";
      default:
        std::abort();
      }
    case 0x15:
      switch (func3) {
      case 0: return "FMIN.D";
      case 1: return "FMAX.D";
      default:
        std::abort();
      }
    case 0x20: return "FCVT.S.D";
    case 0x21: return "FCVT.D.S";
    case 0x50:
      switch (func3) {
      case 0: return "FLE.S";
      case 1: return "FLT.S";
      case 2: return "FEQ.S";
      default:
        std::abort();
      }
    case 0x51:
      switch (func3) {
      case 0: return "FLE.D";
      case 1: return "FLT.D";
      case 2: return "FEQ.D";
      default:
        std::abort();
      }
    case 0x60:
      switch (rs1) {
      case 0: return "FCVT.W.S";
      case 1: return "FCVT.WU.S";
      case 2: return "FCVT.L.S";
      case 3: return "FCVT.LU.S";
      default:
        std::abort();
      }
    case 0x61:
      switch (rs1) {
      case 0: return "FCVT.W.D";
      case 1: return "FCVT.WU.D";
      case 2: return "FCVT.L.D";
      case 3: return "FCVT.LU.D";
      default:
        std::abort();
      }
    case 0x68:
      switch (rs1) {
      case 0: return "FCVT.S.W";
      case 1: return "FCVT.S.WU";
      case 2: return "FCVT.S.L";
      case 3: return "FCVT.S.LU";
      default:
        std::abort();
      }
    case 0x69:
      switch (rs1) {
      case 0: return "FCVT.D.W";
      case 1: return "FCVT.D.WU";
      case 2: return "FCVT.D.L";
      case 3: return "FCVT.D.LU";
      default:
        std::abort();
      }
    case 0x70: return func3 ? "FCLASS.S" : "FMV.X.S";
    case 0x71: return func3 ? "FCLASS.D" : "FMV.X.D";
    case 0x78: return "FMV.S.X";
    case 0x79: return "FMV.D.X";
    default:
      std::abort();
    }
  case Opcode::FMADD:   return func2 ? "FMADD.D" : "FMADD.S";
  case Opcode::FMSUB:   return func2 ? "FMSUB.D" : "FMSUB.S";
  case Opcode::FMNMADD: return func2 ? "FNMADD.D" : "FNMADD.S";
  case Opcode::FMNMSUB: return func2 ? "FNMSUB.D" : "FNMSUB.S";
  case Opcode::VSET:    return "VSET";
  case Opcode::EXT1:
    switch (func7) {
    case 0:
      switch (func3) {
      case 0: return "TMC";
      case 1: return "WSPAWN";
      case 2: return rs1 ? "SPLIT.N" : "SPLIT";
      case 3: return "JOIN";
      case 4: return "BAR";
      case 5: return rd ? "PRED.N" : "PRED";
      default:
        std::abort();
      }
    default:
      std::abort();
    }

  case Opcode::TCU:
    switch(func3)
    {
      case 0: return "ML";     // Matrix Load
      case 1: return "MS";     // Matrix Store
      case 2: return "MATMUL"; // Matrix Multiply
      default:
        std::abort();
    }
  default:
    std::abort();
  }
}

#ifdef EXT_V_ENABLE
inline void print_vec_attr(std::ostream &os, const Instr &instr) {
  uint32_t mask = instr.getVattrMask();
  if (mask & vattr_vlswidth)
    os << ", width:" << instr.getVlsWidth();
  if (mask & vattr_vmop)
    os << ", mop:" << instr.getVmop();
  if (mask & vattr_vumop)
    os << ", umop:" << instr.getVumop();
  if (mask & vattr_vnf)
    os << ", nf:" << instr.getVnf();
  if (mask & vattr_vmask)
    os << ", vmask:" << instr.getVmask();
  if (mask & vattr_vs3)
    os << ", vs3:" << instr.getVs3();
  if (mask & vattr_zimm)
    os << ", zimm:" << ((instr.hasZimm()) ? "true" : "false");
  if (mask & vattr_vlmul)
    os << ", lmul:" << instr.getVlmul();
  if (mask & vattr_vsew)
    os << ", sew:" << instr.getVsew();
  if (mask & vattr_vta)
    os << ", ta:" << instr.getVta();
  if (mask & vattr_vma)
    os << ", ma:" << instr.getVma();
  if (mask & vattr_vediv)
    os << ", ediv:" << instr.getVediv();
}
#endif

namespace vortex {
std::ostream &operator<<(std::ostream &os, const Instr &instr) {
  os << op_string(instr);
  int sep = 0;
  if (instr.getRDType() != RegType::None) {
    if (sep++ != 0) { os << ", "; } else { os << " "; }
    os << instr.getRDType() << instr.getRDest();
  }
  for (uint32_t i = 0; i < instr.getNRSrc(); ++i) {
    if (sep++ != 0) { os << ", "; } else { os << " "; }
    if (instr.getRSType(i) != RegType::None) {
      os << instr.getRSType(i) << instr.getRSrc(i);
    } else {
      os << "0x" << std::hex << instr.getRSrc(0) << std::dec;
    }
  }
  if (instr.hasImm()) {
    if (sep++ != 0) { os << ", "; } else { os << " "; }
    os << "0x" << std::hex << instr.getImm() << std::dec;
  }
#ifdef EXT_V_ENABLE
  if (instr.getOpcode() == Opcode::SYS && instr.getFunc3() >= 5) {
    // CSRs with immediate values
    if (sep++ != 0) { os << ", "; } else { os << " "; }
    os << "0x" << std::hex << instr.getRSrc(0);
  }
  // Log vector-specific attributes
  if (instr.getVattrMask() != 0) {
    print_vec_attr(os, instr);
  }
#endif
  return os;
}
}

std::shared_ptr<Instr> Emulator::decode(uint32_t code) const {
  auto instr = std::make_shared<Instr>();
  auto op = Opcode((code >> shift_opcode) & mask_opcode);
  instr->setOpcode(op);

  auto func2 = (code >> shift_func2) & mask_func2;
  auto func3 = (code >> shift_func3) & mask_func3;
  auto func6 = (code >> shift_func6) & mask_func6;
  auto func7 = (code >> shift_func7) & mask_func7;
  __unused(func6);

  auto rd  = (code >> shift_rd)  & mask_reg;
  auto rs1 = (code >> shift_rs1) & mask_reg;
  auto rs2 = (code >> shift_rs2) & mask_reg;
  auto rs3 = (code >> shift_rs3) & mask_reg;

  auto op_it = sc_instTable.find(op);
  if (op_it == sc_instTable.end()) {
    std::cout << "Error: invalid opcode: 0x" << std::hex << static_cast<int>(op) << std::dec << std::endl;
    return nullptr;
  }

  auto iType = op_it->second;
  if (op == Opcode::FL || op == Opcode::FS) {
    if (func3 != 0x2 && func3 != 0x3) {
      iType = InstType::V;
    }
  }

  switch (iType) {
  case InstType::R:
    switch (op) {
    case Opcode::FCI:
      switch (func7) {
      case 0x20: // FCVT.S.D
      case 0x21: // FCVT.D.S
        instr->setDestReg(rd, RegType::Float);
        instr->addSrcReg(rs1, RegType::Float);
        break;
      case 0x2c: // FSQRT.S
      case 0x2d: // FSQRT.D
        instr->setDestReg(rd, RegType::Float);
        instr->addSrcReg(rs1, RegType::Float);
        break;
      case 0x50: // FLE.S, FLT.S, FEQ.S
      case 0x51: // FLE.D, FLT.D, FEQ.D
        instr->setDestReg(rd, RegType::Integer);
        instr->addSrcReg(rs1, RegType::Float);
        instr->addSrcReg(rs2, RegType::Float);
        break;
      case 0x60: // FCVT.W.D, FCVT.WU.D, FCVT.L.D, FCVT.LU.D
      case 0x61: // FCVT.WU.S, FCVT.W.S, FCVT.L.S, FCVT.LU.S
        instr->setDestReg(rd, RegType::Integer);
        instr->addSrcReg(rs1, RegType::Float);
        instr->addSrcReg(rs2, RegType::None);
        break;
      case 0x68: // FCVT.S.W, FCVT.S.WU, FCVT.S.L, FCVT.S.LU
      case 0x69: // FCVT.D.W, FCVT.D.WU, FCVT.D.L, FCVT.D.LU
        instr->setDestReg(rd, RegType::Float);
        instr->addSrcReg(rs1, RegType::Integer);
        instr->addSrcReg(rs2, RegType::None);
        break;
      case 0x70: // FCLASS.S, FMV.X.S
      case 0x71: // FCLASS.D, FMV.X.D
        instr->setDestReg(rd, RegType::Integer);
        instr->addSrcReg(rs1, RegType::Float);
        break;
      case 0x78: // FMV.S.X
      case 0x79: // FMV.D.X
        instr->setDestReg(rd, RegType::Float);
        instr->addSrcReg(rs1, RegType::Integer);
        break;
      default:
        instr->setDestReg(rd, RegType::Float);
        instr->addSrcReg(rs1, RegType::Float);
        instr->addSrcReg(rs2, RegType::Float);
        break;
      }
      break;
    case Opcode::EXT1:
      switch (func7) {
      case 0:
        switch (func3) {
        case 0: // TMC
        case 3: // JOIN
          instr->addSrcReg(rs1, RegType::Integer);
          break;
        case 1: // WSPAWN
        case 4: // BAR
          instr->addSrcReg(rs1, RegType::Integer);
          instr->addSrcReg(rs2, RegType::Integer);
          break;
        case 5: // PRED
          instr->setDestReg(rd, RegType::None);
          instr->addSrcReg(rs1, RegType::Integer);
          instr->addSrcReg(rs2, RegType::Integer);
          break;
        case 2: // SPLIT
          instr->setDestReg(rd, RegType::Integer);
          instr->addSrcReg(rs1, RegType::Integer);
          instr->addSrcReg(rs2, RegType::None);
          break;
        default:
          std::abort();
        }
        break;
      default:
        std::abort();
      }
      break;
    default:
      instr->setDestReg(rd, RegType::Integer);
      instr->addSrcReg(rs1, RegType::Integer);
      instr->addSrcReg(rs2, RegType::Integer);
      break;
    }
    instr->setFunc3(func3);
    instr->setFunc7(func7);
    break;

  case InstType::I: {
    switch (op) {
    case Opcode::TCU: {
      instr->setDestReg(rs1, RegType::Integer);
      instr->addSrcReg(rs1, RegType::Integer);
      instr->setFunc3(func3);
      instr->setFunc7(func7);
      auto imm = code >> shift_rs2;
      instr->setImm(sext(imm, width_i_imm));
    } break;
    case Opcode::I:
    case Opcode::I_W:
    case Opcode::JALR:
      instr->setDestReg(rd, RegType::Integer);
      instr->addSrcReg(rs1, RegType::Integer);
      instr->setFunc3(func3);
      if (func3 == 0x1 || func3 == 0x5) {
        // Shift instructions
        auto shamt = rs2; // uint5
      #if (XLEN == 64)
        if (op == Opcode::I) {
          // uint6
          shamt |= ((func7 & 0x1) << 5);
        }
      #endif
        instr->setImm(shamt);
        instr->setFunc7(func7);
      } else {
        auto imm = code >> shift_rs2;
        instr->setImm(sext(imm, width_i_imm));
      }
      break;
    case Opcode::L:
    case Opcode::FL: {
      instr->setDestReg(rd, (op == Opcode::FL) ? RegType::Float : RegType::Integer);
      instr->addSrcReg(rs1, RegType::Integer);
      instr->setFunc3(func3);
      auto imm = code >> shift_rs2;
      instr->setImm(sext(imm, width_i_imm));
    } break;
    case Opcode::FENCE:
      instr->setFunc3(func3);
      instr->setImm(code >> shift_rs2);
      break;
    case Opcode::SYS:
      if (func3 != 0) {
        // CSR instructions
        instr->setDestReg(rd, RegType::Integer);
        instr->setFunc3(func3);
        if (func3 < 5) {
          instr->addSrcReg(rs1, RegType::Integer);
        } else {
          // zimm
          instr->addSrcReg(rs1, RegType::None);
        }
        instr->setImm(code >> shift_rs2);
      } else {
        // ECALL/EBREACK instructions
        instr->setImm(code >> shift_rs2);
      }
      break;
    default:
      std::abort();
      break;
    }
  } break;
  case InstType::S: {
    instr->addSrcReg(rs1, RegType::Integer);
    instr->addSrcReg(rs2, (op == Opcode::FS) ? RegType::Float : RegType::Integer);
    instr->setFunc3(func3);
    auto imm = (func7 << width_reg) | rd;
    instr->setImm(sext(imm, width_i_imm));
  } break;

  case InstType::B: {
    instr->addSrcReg(rs1, RegType::Integer);
    instr->addSrcReg(rs2, RegType::Integer);
    instr->setFunc3(func3);
    auto bit_11   = rd & 0x1;
    auto bits_4_1 = rd >> 1;
    auto bit_10_5 = func7 & 0x3f;
    auto bit_12   = func7 >> 6;
    auto imm = (bits_4_1 << 1) | (bit_10_5 << 5) | (bit_11 << 11) | (bit_12 << 12);
    instr->setImm(sext(imm, width_i_imm+1));
  } break;

  case InstType::U: {
    instr->setDestReg(rd, RegType::Integer);
    auto imm = (code >> shift_func3) << shift_func3;
    instr->setImm(imm);
  } break;

  case InstType::J: {
    instr->setDestReg(rd, RegType::Integer);
    auto unordered  = code >> shift_func3;
    auto bits_19_12 = unordered & 0xff;
    auto bit_11     = (unordered >> 8) & 0x1;
    auto bits_10_1  = (unordered >> 9) & 0x3ff;
    auto bit_20     = (unordered >> 19) & 0x1;
    auto imm = (bits_10_1 << 1) | (bit_11 << 11) | (bits_19_12 << 12) | (bit_20 << 20);
    instr->setImm(sext(imm, width_j_imm+1));
  } break;

  case InstType::R4: {
    instr->setDestReg(rd, RegType::Float);
    instr->addSrcReg(rs1, RegType::Float);
    instr->addSrcReg(rs2, RegType::Float);
    instr->addSrcReg(rs3, RegType::Float);
    instr->setFunc2(func2);
    instr->setFunc3(func3);
  } break;

#ifdef EXT_V_ENABLE
  case InstType::V:
    switch (op) {
    case Opcode::VSET: {
      instr->setDestReg(rd, RegType::Integer);
      instr->setFunc3(func3);
      switch (func3) {
        case 7: {
          if (code >> (shift_vset - 1) == 0b10) { // vsetvl
            instr->addSrcReg(rs1, RegType::Integer);
            instr->addSrcReg(rs2, RegType::Integer);
          } else {
            auto zimm = (code >> shift_rs2) & mask_v_zimm;
            instr->setZimm(true);
            instr->setVlmul(zimm & mask_v_lmul);
            instr->setVsew((zimm >> shift_v_sew) & mask_v_sew);
            instr->setVta((zimm >> shift_v_ta) & mask_v_ta);
            instr->setVma((zimm >> shift_v_ma) & mask_v_ma);
            if ((code >> shift_vset)) { // vsetivli
              instr->setImm(rs1);
            } else { // vsetvli
              instr->addSrcReg(rs1, RegType::Integer);
            }
          }
        } break;
        case 3: { // Vector - immediate arithmetic instructions
          instr->setDestReg(rd, RegType::Vector);
          instr->addSrcReg(rs2, RegType::Vector);
          instr->setImm(rs1);
          instr->setVmask((code >> shift_func7) & 0x1);
          instr->setFunc6(func6);
        } break;
        default: { // Vector - vector/scalar arithmetic instructions
          if (func3 == 1 && func6 == 16) {
            instr->setDestReg(rd, RegType::Float);
          } else if (func3 == 2 && func6 == 16) {
            instr->setDestReg(rd, RegType::Integer);
          } else {
            instr->setDestReg(rd, RegType::Vector);
          }
          instr->addSrcReg(rs1, RegType::Vector);
          instr->addSrcReg(rs2, RegType::Vector);
          instr->setVmask((code >> shift_func7) & 0x1);
          instr->setFunc6(func6);
        }
      }
    } break;
    case Opcode::FL:
      instr->addSrcReg(rs1, RegType::Integer);
      instr->setVmop((code >> shift_vmop) & 0b11);
      switch (instr->getVmop()) {
        case 0b00:
          instr->setVumop(rs2);
          break;
        case 0b10:
          instr->addSrcReg(rs2, RegType::Integer);
          break;
        case 0b01:
        case 0b11:
          instr->addSrcReg(rs2, RegType::Vector);
          break;
      }
      instr->setVsew(func3 & 0x3);
      instr->setDestReg(rd, RegType::Vector);
      instr->setVlsWidth(func3);
      instr->setVmask((code >> shift_func7) & 0x1);
      instr->setVnf((code >> shift_vnf) & mask_func3);
      break;

    case Opcode::FS:
      instr->addSrcReg(rs1, RegType::Integer);
      instr->setVmop((code >> shift_vmop) & 0b11);
      switch (instr->getVmop()) {
        case 0b00:
          instr->setVumop(rs2);
          break;
        case 0b10:
          instr->addSrcReg(rs2, RegType::Integer);
          break;
        case 0b01:
        case 0b11:
          instr->addSrcReg(rs2, RegType::Vector);
          break;
      }
      instr->setVsew(func3 & 0x3);
      instr->addSrcReg(rd, RegType::Vector);
      instr->setVlsWidth(func3);
      instr->setVmask((code >> shift_func7) & 0x1);
      instr->setVmop((code >> shift_vmop) & 0b11);
      instr->setVnf((code >> shift_vnf) & mask_func3);
      break;

    default:
      std::abort();
    }
    break;
  #endif

  default:
    std::abort();
  }

  return instr;
}
// --- End of content from sim/simx/decode.cpp ---

// --- Start of content from sim/simx/emulator.cpp ---
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#include <iostream>
#include <stdlib.h>
#include <unistd.h>
#include <math.h>
#include <assert.h>
#include <util.h>

// MERGED_LOCALLY: #include "emulator.h"
// MERGED_LOCALLY: #include "instr_trace.h"
// MERGED_LOCALLY: #include "instr.h"
// MERGED_LOCALLY: #include "dcrs.h"
// MERGED_LOCALLY: #include "core.h"
// MERGED_LOCALLY: #include "socket.h"
// MERGED_LOCALLY: #include "cluster.h"
// MERGED_LOCALLY: #include "processor_impl.h"
// MERGED_LOCALLY: #include "local_mem.h"

using namespace vortex;

Emulator::warp_t::warp_t(const Arch& arch)
  : ireg_file(arch.num_threads(), std::vector<Word>(MAX_NUM_REGS))
  , freg_file(arch.num_threads(), std::vector<uint64_t>(MAX_NUM_REGS))
#ifdef EXT_V_ENABLE
  , vreg_file(MAX_NUM_REGS, std::vector<Byte>(MAX_NUM_REGS))
#endif
  , uuid(0)
{}

void Emulator::warp_t::clear(uint64_t startup_addr) {
  this->PC = startup_addr;
  this->tmask.reset();
  this->uuid = 0;
  this->fcsr = 0;

  for (auto& reg_file : this->ireg_file) {
    for (auto& reg : reg_file) {
    #ifndef NDEBUG
      reg = 0;
    #else
      reg = std::rand();
    #endif
    }
    reg_file.at(0) = 0; // r0 = 0
  }

  for (auto& reg_file : this->freg_file) {
    for (auto& reg : reg_file) {
    #ifndef NDEBUG
      reg = 0;
    #else
      reg = std::rand();
    #endif
    }
  }

#ifdef EXT_V_ENABLE
  for (auto& reg_file : this->vreg_file) {
    for (auto& reg : reg_file) {
    #ifndef NDEBUG
      reg = 0;
    #else
      reg = std::rand();
    #endif
    }
  }
  this->vtype = {0, 0, 0, 0, 0};
  this->vl = 0;
  this->vlmax = 0;
#endif
}

///////////////////////////////////////////////////////////////////////////////

Emulator::Emulator(const Arch &arch, const DCRS &dcrs, Core* core)
    : arch_(arch)
    , dcrs_(dcrs)
    , core_(core)
    , warps_(arch.num_warps(), arch)
    , barriers_(arch.num_barriers(), 0)
    , ipdom_size_(arch.num_threads()-1)
    // [TBC] Currently, tradeoff between scratchpad size & performance has not been evaluated. Scratchpad is
    // considered to be big enough to hold input tiles for one output tile.
    // In future versions, scratchpad size should be fixed to an appropriate value.
    , scratchpad(std::vector<Word>(32 * 32 * 32768))
  #ifdef EXT_V_ENABLE
    , csrs_(arch.num_warps())
  #endif
{
  std::srand(50);

#ifdef EXT_V_ENABLE
  for (uint32_t i = 0; i < arch_.num_warps(); ++i) {
    csrs_.at(i).resize(arch.num_threads());
  }
#endif

  this->clear();
}

Emulator::~Emulator() {
  this->cout_flush();
}

void Emulator::clear() {
  uint64_t startup_addr = dcrs_.base_dcrs.read(VX_DCR_BASE_STARTUP_ADDR0);
#if (XLEN == 64)
  startup_addr |= (uint64_t(dcrs_.base_dcrs.read(VX_DCR_BASE_STARTUP_ADDR1)) << 32);
#endif

  uint64_t startup_arg = dcrs_.base_dcrs.read(VX_DCR_BASE_STARTUP_ARG0);
#if (XLEN == 64)
  startup_arg |= (uint64_t(dcrs_.base_dcrs.read(VX_DCR_BASE_STARTUP_ARG1)) << 32);
#endif

  for (auto& warp : warps_) {
    warp.clear(startup_addr);
  }

  for (auto& barrier : barriers_) {
    barrier.reset();
  }

  csr_mscratch_ = startup_arg;

  stalled_warps_.reset();
  active_warps_.reset();

  // activate first warp and thread
  active_warps_.set(0);
  warps_[0].tmask.set(0);
  wspawn_.valid = false;

  for (auto& reg : scratchpad) {
    reg = 0;
  }
}

void Emulator::attach_ram(RAM* ram) {
  // bind RAM to memory unit
#if (XLEN == 64)
  mmu_.attach(*ram, 0, 0x7FFFFFFFFF); //39bit SV39
#else
  mmu_.attach(*ram, 0, 0xFFFFFFFF);
#endif
}

instr_trace_t* Emulator::step() {
  int scheduled_warp = -1;

  // process pending wspawn
  if (wspawn_.valid && active_warps_.count() == 1) {
    DP(3, "*** Activate " << (wspawn_.num_warps-1) << " warps at PC: " << std::hex << wspawn_.nextPC << std::dec);
    for (uint32_t i = 1; i < wspawn_.num_warps; ++i) {
      auto& warp = warps_.at(i);
      warp.PC = wspawn_.nextPC;
      warp.tmask.set(0);
      active_warps_.set(i);
    }
    wspawn_.valid = false;
    stalled_warps_.reset(0);
  }

  // find next ready warp
  for (size_t wid = 0, nw = arch_.num_warps(); wid < nw; ++wid) {
    bool warp_active = active_warps_.test(wid);
    bool warp_stalled = stalled_warps_.test(wid);
    if (warp_active && !warp_stalled) {
      scheduled_warp = wid;
      break;
    }
  }
  if (scheduled_warp == -1)
    return nullptr;

  // suspend warp until decode
  auto& warp = warps_.at(scheduled_warp);
  assert(warp.tmask.any());

#ifndef NDEBUG
  // generate unique universal instruction ID
  uint32_t instr_uuid = warp.uuid++;
  uint32_t g_wid = core_->id() * arch_.num_warps() + scheduled_warp;
  uint64_t uuid = (uint64_t(g_wid) << 32) | instr_uuid;
#else
  uint64_t uuid = 0;
#endif

  DP(1, "Fetch: cid=" << core_->id() << ", wid=" << scheduled_warp << ", tmask=" << ThreadMaskOS(warp.tmask, arch_.num_threads())
         << ", PC=0x" << std::hex << warp.PC << " (#" << std::dec << uuid << ")");

  // Fetch
  uint32_t instr_code = 0;
  this->icache_read(&instr_code, warp.PC, sizeof(uint32_t));

  // Decode
  auto instr = this->decode(instr_code);
  if (!instr) {
    std::cout << "Error: invalid instruction 0x" << std::hex << instr_code << ", at PC=0x" << warp.PC << " (#" << std::dec << uuid << ")" << std::endl;
    std::abort();
  }

  DP(1, "Instr 0x" << std::hex << instr_code << ": " << std::dec << *instr);

  // Create trace
  auto trace = new instr_trace_t(uuid, arch_);

  // Execute
  this->execute(*instr, scheduled_warp, trace);

  DP(5, "Register state:");
  for (uint32_t i = 0; i < MAX_NUM_REGS; ++i) {
    DPN(5, "  %r" << std::setfill('0') << std::setw(2) << i << ':' << std::hex);
    // Integer register file
    for (uint32_t j = 0; j < arch_.num_threads(); ++j) {
      DPN(5, ' ' << std::setfill('0') << std::setw(XLEN/4) << warp.ireg_file.at(j).at(i) << std::setfill(' ') << ' ');
    }
    DPN(5, '|');
    // Floating point register file
    for (uint32_t j = 0; j < arch_.num_threads(); ++j) {
      DPN(5, ' ' << std::setfill('0') << std::setw(16) << warp.freg_file.at(j).at(i) << std::setfill(' ') << ' ');
    }
    DPN(5, std::dec << std::endl);
  }

  return trace;
}

bool Emulator::running() const {
  return active_warps_.any();
}

int Emulator::get_exitcode() const {
  return warps_.at(0).ireg_file.at(0).at(3);
}

void Emulator::suspend(uint32_t wid) {
  assert(!stalled_warps_.test(wid));
  stalled_warps_.set(wid);
}

void Emulator::resume(uint32_t wid) {
  if (wid != 0xffffffff) {
    assert(stalled_warps_.test(wid));
    stalled_warps_.reset(wid);
  } else {
    stalled_warps_.reset();
  }
}

bool Emulator::wspawn(uint32_t num_warps, Word nextPC) {
  num_warps = std::min<uint32_t>(num_warps, arch_.num_warps());
  if (num_warps < 2 && active_warps_.count() == 1)
    return true;
  wspawn_.valid = true;
  wspawn_.num_warps = num_warps;
  wspawn_.nextPC = nextPC;
  return false;
}

bool Emulator::barrier(uint32_t bar_id, uint32_t count, uint32_t wid) {
  if (count < 2)
    return true;

  uint32_t bar_idx = bar_id & 0x7fffffff;
  bool is_global = (bar_id >> 31);

  auto& barrier = barriers_.at(bar_idx);
  barrier.set(wid);
  DP(3, "*** Suspend core #" << core_->id() << ", warp #" << wid << " at barrier #" << bar_idx);

  if (is_global) {
    // global barrier handling
    if (barrier.count() == active_warps_.count()) {
      core_->socket()->barrier(bar_idx, count, core_->id());
      barrier.reset();
    }
  } else {
    // local barrier handling
    if (barrier.count() == (size_t)count) {
      // resume suspended warps
      for (uint32_t i = 0; i < arch_.num_warps(); ++i) {
        if (barrier.test(i)) {
          DP(3, "*** Resume core #" << core_->id() << ", warp #" << i << " at barrier #" << bar_idx);
          stalled_warps_.reset(i);
        }
      }
      barrier.reset();
    }
  }
  return false;
}

#ifdef VM_ENABLE
void Emulator::icache_read(void *data, uint64_t addr, uint32_t size) {
  DP(3, "*** icache_read 0x" << std::hex << addr << ", size = 0x "  << size);
  try
  {
    mmu_.read(data, addr, size, ACCESS_TYPE::FETCH);
  }
  catch (Page_Fault_Exception& page_fault)
  {
    std::cout<<page_fault.what()<<std::endl;
    throw;
  }
}
#else
void Emulator::icache_read(void *data, uint64_t addr, uint32_t size) {
  mmu_.read(data, addr, size, 0);
}
#endif

#ifdef VM_ENABLE
void Emulator::set_satp(uint64_t satp) {
  DPH(3, "set satp 0x" << std::hex << satp << " in emulator module\n");
  set_csr(VX_CSR_SATP,satp,0,0);
}
#endif


#ifdef VM_ENABLE
void Emulator::dcache_read(void *data, uint64_t addr, uint32_t size) {
  DP(1, "*** dcache_read 0x" << std::hex << addr << ", size = 0x "  << size);
  auto type = get_addr_type(addr);
  if (type == AddrType::Shared) {
    core_->local_mem()->read(data, addr, size);
  } else {
    try
    {
      mmu_.read(data, addr, size, ACCESS_TYPE::LOAD);
    }
    catch (Page_Fault_Exception& page_fault)
    {
      std::cout<<page_fault.what()<<std::endl;
      throw;
    }
  }
  DPH(2, "Mem Read: addr=0x" << std::hex << addr << ", data=0x" << ByteStream(data, size) << " (size=" << size << ", type=" << type << ")" << std::endl);
}
#else
void Emulator::dcache_read(void *data, uint64_t addr, uint32_t size) {
  auto type = get_addr_type(addr);
  if (type == AddrType::Shared) {
    core_->local_mem()->read(data, addr, size);
  } else {
    mmu_.read(data, addr, size, 0);
  }
  DPH(2, "Mem Read: addr=0x" << std::hex << addr << ", data=0x" << ByteStream(data, size) << std::dec << " (size=" << size << ", type=" << type << ")" << std::endl);
}
#endif

#ifdef VM_ENABLE
void Emulator::dcache_write(const void* data, uint64_t addr, uint32_t size) {
  DP(1, "*** dcache_write 0x" << std::hex << addr << ", size = 0x "  << size);
  auto type = get_addr_type(addr);
  if (addr >= uint64_t(IO_COUT_ADDR)
   && addr < (uint64_t(IO_COUT_ADDR) + IO_COUT_SIZE)) {
     this->writeToStdOut(data, addr, size);
  } else {
    if (type == AddrType::Shared) {
      core_->local_mem()->write(data, addr, size);
    } else {
      try
      {
        // mmu_.write(data, addr, size, 0);
        mmu_.write(data, addr, size, ACCESS_TYPE::STORE);
      }
      catch (Page_Fault_Exception& page_fault)
      {
        std::cout<<page_fault.what()<<std::endl;
        throw;
      }
    }
  }
  DPH(2, "Mem Write: addr=0x" << std::hex << addr << ", data=0x" << ByteStream(data, size) << " (size=" << size << ", type=" << type << ")" << std::endl);
}
#else
void Emulator::dcache_write(const void* data, uint64_t addr, uint32_t size) {
  auto type = get_addr_type(addr);
  if (addr >= uint64_t(IO_COUT_ADDR)
   && addr < (uint64_t(IO_COUT_ADDR) + IO_COUT_SIZE)) {
    this->writeToStdOut(data, addr, size);
  } else {
    if (type == AddrType::Shared) {
      core_->local_mem()->write(data, addr, size);
    } else {
      mmu_.write(data, addr, size, 0);
    }
  }
  DPH(2, "Mem Write: addr=0x" << std::hex << addr << ", data=0x" << ByteStream(data, size) << std::dec << " (size=" << size << ", type=" << type << ")" << std::endl);
}
#endif

void Emulator::dcache_amo_reserve(uint64_t addr) {
  auto type = get_addr_type(addr);
  if (type == AddrType::Global) {
    mmu_.amo_reserve(addr);
  }
}

bool Emulator::dcache_amo_check(uint64_t addr) {
  auto type = get_addr_type(addr);
  if (type == AddrType::Global) {
    return mmu_.amo_check(addr);
  }
  return false;
}

void Emulator::writeToStdOut(const void* data, uint64_t addr, uint32_t size) {
  if (size != 1)
    std::abort();
  uint32_t tid = (addr - IO_COUT_ADDR) & (IO_COUT_SIZE-1);
  auto& ss_buf = print_bufs_[tid];
  char c = *(char*)data;
  ss_buf << c;
  if (c == '\n') {
    std::cout << "#" << tid << ": " << ss_buf.str() << std::flush;
    ss_buf.str("");
  }
}

void Emulator::cout_flush() {
  for (auto& buf : print_bufs_) {
    auto str = buf.second.str();
    if (!str.empty()) {
      std::cout << "#" << buf.first << ": " << str << std::endl;
    }
  }
}

#ifdef XLEN_64
  #define CSR_READ_64(addr, value) \
    case addr: return value
#else
  #define CSR_READ_64(addr, value) \
    case addr : return (uint32_t)value; \
    case (addr + (VX_CSR_MPM_BASE_H-VX_CSR_MPM_BASE)) : return ((value >> 32) & 0xFFFFFFFF)
#endif

Word Emulator::get_tiles() {
  return mat_size;
}

Word Emulator::get_tc_size() {
  return tc_size;
}

Word Emulator::get_tc_num() {
  return tc_num;
}

Word Emulator::get_csr(uint32_t addr, uint32_t tid, uint32_t wid) {
  auto core_perf = core_->perf_stats();
  switch (addr) {
  case VX_CSR_SATP:
#ifdef VM_ENABLE
    // return csrs_.at(wid).at(tid)[addr];
    return mmu_.get_satp();
#endif
  case VX_CSR_PMPCFG0:
  case VX_CSR_PMPADDR0:
  case VX_CSR_MSTATUS:
  case VX_CSR_MISA:
  case VX_CSR_MEDELEG:
  case VX_CSR_MIDELEG:
  case VX_CSR_MIE:
  case VX_CSR_MTVEC:
  case VX_CSR_MEPC:
  case VX_CSR_MNSTATUS:
  case VX_CSR_MCAUSE:
    return 0;

  case VX_CSR_FFLAGS:     return warps_.at(wid).fcsr & 0x1F;
  case VX_CSR_FRM:        return (warps_.at(wid).fcsr >> 5);
  case VX_CSR_FCSR:       return warps_.at(wid).fcsr;

#ifdef EXT_V_ENABLE
  // Vector CRSs
  case VX_CSR_VSTART:
    return csrs_.at(wid).at(tid)[VX_CSR_VSTART];
  case VX_CSR_VXSAT:
    return csrs_.at(wid).at(tid)[VX_CSR_VXSAT];
  case VX_CSR_VXRM:
    return csrs_.at(wid).at(tid)[VX_CSR_VXRM];
  case VX_CSR_VCSR: {
    Word vxsat = csrs_.at(wid).at(tid)[VX_CSR_VXSAT];
    Word vxrm = csrs_.at(wid).at(tid)[VX_CSR_VXRM];
    return (vxrm << 1) | vxsat;
  }
  case VX_CSR_VL:
    return csrs_.at(wid).at(tid)[VX_CSR_VL];
  case VX_CSR_VTYPE:
    return csrs_.at(wid).at(tid)[VX_CSR_VTYPE];
  case VX_CSR_VLENB:
    return VLEN / 8;
  case VX_CSR_VCYCLE:
    return csrs_.at(wid).at(tid)[VX_CSR_VCYCLE];
  case VX_CSR_VTIME:
    return csrs_.at(wid).at(tid)[VX_CSR_VTIME];
  case VX_CSR_VINSTRET:
    return csrs_.at(wid).at(tid)[VX_CSR_VINSTRET];
#endif

  case VX_CSR_MHARTID:    return (core_->id() * arch_.num_warps() + wid) * arch_.num_threads() + tid;
  case VX_CSR_THREAD_ID:  return tid;
  case VX_CSR_WARP_ID:    return wid;
  case VX_CSR_CORE_ID:    return core_->id();
  case VX_CSR_ACTIVE_THREADS:return warps_.at(wid).tmask.to_ulong();
  case VX_CSR_ACTIVE_WARPS:return active_warps_.to_ulong();
  case VX_CSR_NUM_THREADS:return arch_.num_threads();
  case VX_CSR_NUM_WARPS:  return arch_.num_warps();
  case VX_CSR_NUM_CORES:  return uint32_t(arch_.num_cores()) * arch_.num_clusters();
  case VX_CSR_LOCAL_MEM_BASE: return arch_.local_mem_base();
  case VX_CSR_MSCRATCH:   return csr_mscratch_;
  case VX_MAT_MUL_SIZE:   return mat_size;
  case VX_TC_NUM:         return tc_num;
  case VX_TC_SIZE:        return tc_size;

  CSR_READ_64(VX_CSR_MCYCLE, core_perf.cycles);
  CSR_READ_64(VX_CSR_MINSTRET, core_perf.instrs);
  default:
    if ((addr >= VX_CSR_MPM_BASE && addr < (VX_CSR_MPM_BASE + 32))
     || (addr >= VX_CSR_MPM_BASE_H && addr < (VX_CSR_MPM_BASE_H + 32))) {
      // user-defined MPM CSRs
      auto perf_class = dcrs_.base_dcrs.read(VX_DCR_BASE_MPM_CLASS);
      switch (perf_class) {
      case VX_DCR_MPM_CLASS_NONE:
        break;
      case VX_DCR_MPM_CLASS_CORE: {
        switch (addr) {
        CSR_READ_64(VX_CSR_MPM_SCHED_ID, core_perf.sched_idle);
        CSR_READ_64(VX_CSR_MPM_SCHED_ST, core_perf.sched_stalls);
        CSR_READ_64(VX_CSR_MPM_IBUF_ST, core_perf.ibuf_stalls);
        CSR_READ_64(VX_CSR_MPM_SCRB_ST, core_perf.scrb_stalls);
        CSR_READ_64(VX_CSR_MPM_OPDS_ST, core_perf.opds_stalls);
        CSR_READ_64(VX_CSR_MPM_SCRB_ALU, core_perf.scrb_alu);
        CSR_READ_64(VX_CSR_MPM_SCRB_FPU, core_perf.scrb_fpu);
        CSR_READ_64(VX_CSR_MPM_SCRB_LSU, core_perf.scrb_lsu);
        CSR_READ_64(VX_CSR_MPM_SCRB_SFU, core_perf.scrb_sfu);
        CSR_READ_64(VX_CSR_MPM_SCRB_CSRS, core_perf.scrb_csrs);
        CSR_READ_64(VX_CSR_MPM_SCRB_WCTL, core_perf.scrb_wctl);
        CSR_READ_64(VX_CSR_MPM_IFETCHES, core_perf.ifetches);
        CSR_READ_64(VX_CSR_MPM_LOADS, core_perf.loads);
        CSR_READ_64(VX_CSR_MPM_STORES, core_perf.stores);
        CSR_READ_64(VX_CSR_MPM_IFETCH_LT, core_perf.ifetch_latency);
        CSR_READ_64(VX_CSR_MPM_LOAD_LT, core_perf.load_latency);
        }
      } break;
      case VX_DCR_MPM_CLASS_MEM: {
        auto proc_perf = core_->socket()->cluster()->processor()->perf_stats();
        auto cluster_perf = core_->socket()->cluster()->perf_stats();
        auto socket_perf = core_->socket()->perf_stats();
        auto lmem_perf = core_->local_mem()->perf_stats();

        uint64_t coalescer_misses = 0;
        for (uint i = 0; i < NUM_LSU_BLOCKS; ++i) {
          coalescer_misses += core_->mem_coalescer(i)->perf_stats().misses;
        }

        switch (addr) {
        CSR_READ_64(VX_CSR_MPM_ICACHE_READS, socket_perf.icache.reads);
        CSR_READ_64(VX_CSR_MPM_ICACHE_MISS_R, socket_perf.icache.read_misses);
        CSR_READ_64(VX_CSR_MPM_ICACHE_MSHR_ST, socket_perf.icache.mshr_stalls);

        CSR_READ_64(VX_CSR_MPM_DCACHE_READS, socket_perf.dcache.reads);
        CSR_READ_64(VX_CSR_MPM_DCACHE_WRITES, socket_perf.dcache.writes);
        CSR_READ_64(VX_CSR_MPM_DCACHE_MISS_R, socket_perf.dcache.read_misses);
        CSR_READ_64(VX_CSR_MPM_DCACHE_MISS_W, socket_perf.dcache.write_misses);
        CSR_READ_64(VX_CSR_MPM_DCACHE_BANK_ST, socket_perf.dcache.bank_stalls);
        CSR_READ_64(VX_CSR_MPM_DCACHE_MSHR_ST, socket_perf.dcache.mshr_stalls);

        CSR_READ_64(VX_CSR_MPM_L2CACHE_READS, cluster_perf.l2cache.reads);
        CSR_READ_64(VX_CSR_MPM_L2CACHE_WRITES, cluster_perf.l2cache.writes);
        CSR_READ_64(VX_CSR_MPM_L2CACHE_MISS_R, cluster_perf.l2cache.read_misses);
        CSR_READ_64(VX_CSR_MPM_L2CACHE_MISS_W, cluster_perf.l2cache.write_misses);
        CSR_READ_64(VX_CSR_MPM_L2CACHE_BANK_ST, cluster_perf.l2cache.bank_stalls);
        CSR_READ_64(VX_CSR_MPM_L2CACHE_MSHR_ST, cluster_perf.l2cache.mshr_stalls);

        CSR_READ_64(VX_CSR_MPM_L3CACHE_READS, proc_perf.l3cache.reads);
        CSR_READ_64(VX_CSR_MPM_L3CACHE_WRITES, proc_perf.l3cache.writes);
        CSR_READ_64(VX_CSR_MPM_L3CACHE_MISS_R, proc_perf.l3cache.read_misses);
        CSR_READ_64(VX_CSR_MPM_L3CACHE_MISS_W, proc_perf.l3cache.write_misses);
        CSR_READ_64(VX_CSR_MPM_L3CACHE_BANK_ST, proc_perf.l3cache.bank_stalls);
        CSR_READ_64(VX_CSR_MPM_L3CACHE_MSHR_ST, proc_perf.l3cache.mshr_stalls);

        CSR_READ_64(VX_CSR_MPM_MEM_READS, proc_perf.mem_reads);
        CSR_READ_64(VX_CSR_MPM_MEM_WRITES, proc_perf.mem_writes);
        CSR_READ_64(VX_CSR_MPM_MEM_LT, proc_perf.mem_latency);
        CSR_READ_64(VX_CSR_MPM_MEM_BANK_ST, proc_perf.memsim.bank_stalls);

        CSR_READ_64(VX_CSR_MPM_COALESCER_MISS, coalescer_misses);

        CSR_READ_64(VX_CSR_MPM_LMEM_READS, lmem_perf.reads);
        CSR_READ_64(VX_CSR_MPM_LMEM_WRITES, lmem_perf.writes);
        CSR_READ_64(VX_CSR_MPM_LMEM_BANK_ST, lmem_perf.bank_stalls);
        }
      } break;
      case VX_DCR_MPM_CLASS_3 : {
        CSR_READ_64(VX_CSR_MPM_TOTAL_ISSUED_WARPS, core_perf.total_issued_warps);
        CSR_READ_64(VX_CSR_MPM_TOTAL_ACTIVE_THREADS, core_perf.total_active_threads);
      } break;
      default: {
        std::cout << "Error: invalid MPM CLASS: value=" << perf_class << std::endl;
        std::abort();
      } break;
      }
    } else {
      std::cout << "Error: invalid CSR read addr=0x"<< std::hex << addr << std::dec << std::endl;
      std::abort();
    }
  }
  return 0;
}

void Emulator::set_csr(uint32_t addr, Word value, uint32_t tid, uint32_t wid) {
  __unused (tid);
  switch (addr) {
  case VX_CSR_FFLAGS:
    warps_.at(wid).fcsr = (warps_.at(wid).fcsr & ~0x1F) | (value & 0x1F);
    break;
  case VX_CSR_FRM:
    warps_.at(wid).fcsr = (warps_.at(wid).fcsr & ~0xE0) | (value << 5);
    break;
  case VX_CSR_FCSR:
    warps_.at(wid).fcsr = value & 0xff;
    break;
  case VX_CSR_MSCRATCH:
    csr_mscratch_ = value;
    break;

#ifdef EXT_V_ENABLE
  // Vector CRSs
  case VX_CSR_VSTART:
    csrs_.at(wid).at(tid)[VX_CSR_VSTART] = value;
    break;
  case VX_CSR_VXSAT:
    csrs_.at(wid).at(tid)[VX_CSR_VXSAT] = value & 0b1;
    break;
  case VX_CSR_VXRM:
    csrs_.at(wid).at(tid)[VX_CSR_VXRM] = value & 0b11;
    break;
  case VX_CSR_VCSR:
    csrs_.at(wid).at(tid)[VX_CSR_VXSAT] = value & 0b1;
    csrs_.at(wid).at(tid)[VX_CSR_VXRM] = (value >> 1) & 0b11;
    break;
  case VX_CSR_VL: // read only, written by vset(i)vl(i)
    csrs_.at(wid).at(tid)[VX_CSR_VL] = value;
    break;
  case VX_CSR_VTYPE: // read only, written by vset(i)vl(i)
    csrs_.at(wid).at(tid)[VX_CSR_VTYPE] = value;
    break;
  case VX_CSR_VLENB: // read only, set to VLEN / 8
#endif

  case VX_CSR_SATP:
  #ifdef VM_ENABLE
    // warps_.at(wid).fcsr = (warps_.at(wid).fcsr & ~0x1F) | (value & 0x1F);
    // csrs_.at(wid).at(tid)[addr] = value; //what is wid and tid?
    mmu_.set_satp(value);
    break;
  #endif
  case VX_CSR_MSTATUS:
  case VX_CSR_MEDELEG:
  case VX_CSR_MIDELEG:
  case VX_CSR_MIE:
  case VX_CSR_MTVEC:
  case VX_CSR_MEPC:
  case VX_CSR_PMPCFG0:
  case VX_CSR_PMPADDR0:
  case VX_CSR_MNSTATUS:
  case VX_CSR_MCAUSE:
    break;
  case VX_MAT_MUL_SIZE:
    mat_size = value;
    break;
  case VX_TC_NUM:
    tc_num = value;
    break;
  case VX_TC_SIZE:
    tc_size = value;
    break;

  default: {
      std::cout << "Error: invalid CSR write addr=0x" << std::hex << addr << ", value=0x" << value << std::dec << std::endl;
      std::abort();
    }
  }
}

uint32_t Emulator::get_fpu_rm(uint32_t func3, uint32_t tid, uint32_t wid) {
  return (func3 == 0x7) ? this->get_csr(VX_CSR_FRM, tid, wid) : func3;
}

void Emulator::update_fcrs(uint32_t fflags, uint32_t tid, uint32_t wid) {
  if (fflags) {
    this->set_csr(VX_CSR_FCSR, this->get_csr(VX_CSR_FCSR, tid, wid) | fflags, tid, wid);
    this->set_csr(VX_CSR_FFLAGS, this->get_csr(VX_CSR_FFLAGS, tid, wid) | fflags, tid, wid);
  }
}

// For riscv-vector test functionality, ecall and ebreak must trap
// These instructions are used in the vector tests to stop execution of the test
// Therefore, without these instructions, undefined and incorrect behavior happens
//
// For now, we need these instructions to trap for testing the riscv-vector isa
void Emulator::trigger_ecall() {
  active_warps_.reset();
}
void Emulator::trigger_ebreak() {
  active_warps_.reset();
}
// --- End of content from sim/simx/emulator.cpp ---

// --- Start of content from sim/simx/execute.cpp ---
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#include <iostream>
#include <stdlib.h>
#include <unistd.h>
#include <math.h>
#include <bitset>
#include <climits>
#include <sys/types.h>
#include <sys/stat.h>
#include <assert.h>
#include <util.h>
#include <rvfloats.h>
// MERGED_LOCALLY: #include "emulator.h"
// MERGED_LOCALLY: #include "instr.h"
// MERGED_LOCALLY: #include "core.h"
#ifdef EXT_V_ENABLE
// MERGED_LOCALLY: #include "processor_impl.h"
#endif
// MERGED_LOCALLY: #include "VX_types.h"

using namespace vortex;

inline uint64_t nan_box(uint32_t value) {
  return value | 0xffffffff00000000;
}

inline bool is_nan_boxed(uint64_t value) {
  return (uint32_t(value >> 32) == 0xffffffff);
}

inline int64_t check_boxing(int64_t a) {
  if (is_nan_boxed(a))
    return a;
  return nan_box(0x7fc00000); // NaN
}

void Emulator::execute(const Instr &instr, uint32_t wid, instr_trace_t *trace) {
  auto& warp = warps_.at(wid);
  assert(warp.tmask.any());

  // initialize instruction trace
  trace->cid   = core_->id();
  trace->wid   = wid;
  trace->PC    = warp.PC;
  trace->tmask = warp.tmask;
  trace->dst_reg = {instr.getRDType(), instr.getRDest()};

  auto next_pc = warp.PC + 4;
  auto next_tmask = warp.tmask;

  auto opcode = instr.getOpcode();
  auto func2  = instr.getFunc2();
  auto func3  = instr.getFunc3();
  auto func7  = instr.getFunc7();
  auto rdest  = instr.getRDest();
  auto rsrc0  = instr.getRSrc(0);
  auto rsrc1  = instr.getRSrc(1);
  auto rsrc2  = instr.getRSrc(2);
  auto immsrc = sext((Word)instr.getImm(), 32);

  auto num_threads = arch_.num_threads();

  uint32_t thread_start = 0;
  for (; thread_start < num_threads; ++thread_start) {
      if (warp.tmask.test(thread_start))
        break;
  }

  int32_t thread_last = num_threads - 1;
  for (; thread_last >= 0; --thread_last) {
      if (warp.tmask.test(thread_last))
        break;
  }

  std::vector<reg_data_t[3]> rsdata(num_threads);
  std::vector<reg_data_t> rddata(num_threads);

  auto num_rsrcs = instr.getNRSrc();
  if (num_rsrcs) {
    for (uint32_t i = 0; i < num_rsrcs; ++i) {
      auto type = instr.getRSType(i);
      auto reg = instr.getRSrc(i);
      switch (type) {
      case RegType::Integer:
        DPH(2, "Src" << i << " Reg: " << type << reg << "={");
        for (uint32_t t = 0; t < num_threads; ++t) {
          if (t) DPN(2, ", ");
          if (!warp.tmask.test(t)) {
            DPN(2, "-");
            continue;
          }
          rsdata[t][i].u = warp.ireg_file.at(t)[reg];
          DPN(2, "0x" << std::hex << rsdata[t][i].i << std::dec);
        }
        DPN(2, "}" << std::endl);
        break;
      case RegType::Float:
        DPH(2, "Src" << i << " Reg: " << type << reg << "={");
        for (uint32_t t = 0; t < num_threads; ++t) {
          if (t) DPN(2, ", ");
          if (!warp.tmask.test(t)) {
            DPN(2, "-");
            continue;
          }
          rsdata[t][i].u64 = warp.freg_file.at(t)[reg];
          DPN(2, "0x" << std::hex << rsdata[t][i].f << std::dec);
        }
        DPN(2, "}" << std::endl);
        break;
    #ifdef EXT_V_ENABLE
      case RegType::Vector:
        break;
    #endif
      default:
        break;
      }
    }
  }

  bool rd_write = false;

  switch (opcode) {
  case Opcode::LUI: {
    // RV32I: LUI
    trace->fu_type = FUType::ALU;
    trace->alu_type = AluType::ARITH;
    for (uint32_t t = thread_start; t < num_threads; ++t) {
      if (!warp.tmask.test(t))
        continue;
      rddata[t].i = immsrc;
    }
    rd_write = true;
    break;
  }
  case Opcode::AUIPC: {
    // RV32I: AUIPC
    trace->fu_type = FUType::ALU;
    trace->alu_type = AluType::ARITH;
    for (uint32_t t = thread_start; t < num_threads; ++t) {
      if (!warp.tmask.test(t))
        continue;
      rddata[t].i = immsrc + warp.PC;
    }
    rd_write = true;
    break;
  }
  case Opcode::R: {
    trace->fu_type = FUType::ALU;
    trace->alu_type = AluType::ARITH;
    trace->src_regs[0] = {RegType::Integer, rsrc0};
    trace->src_regs[1] = {RegType::Integer, rsrc1};
    for (uint32_t t = thread_start; t < num_threads; ++t) {
      if (!warp.tmask.test(t))
        continue;
      if (func7 == 0x7) {
        auto value = rsdata[t][0].i;
        auto cond = rsdata[t][1].i;
        if (func3 == 0x5) {
          // CZERO.EQZ
          rddata[t].i = (cond == 0) ? 0 : value;
          trace->alu_type = AluType::ARITH;
        } else
        if (func3 == 0x7) {
          // CZERO.NEZ
          rddata[t].i = (cond != 0) ? 0 : value;
          trace->alu_type = AluType::ARITH;
        } else {
          std::abort();
        }
      } else
      if (func7 & 0x1) {
        switch (func3) {
        case 0: {
          // RV32M: MUL
          rddata[t].i = rsdata[t][0].i * rsdata[t][1].i;
          trace->alu_type = AluType::IMUL;
          break;
        }
        case 1: {
          // RV32M: MULH
          auto first = static_cast<DWordI>(rsdata[t][0].i);
          auto second = static_cast<DWordI>(rsdata[t][1].i);
          rddata[t].i = (first * second) >> XLEN;
          trace->alu_type = AluType::IMUL;
          break;
        }
        case 2: {
          // RV32M: MULHSU
          auto first = static_cast<DWordI>(rsdata[t][0].i);
          auto second = static_cast<DWord>(rsdata[t][1].u);
          rddata[t].i = (first * second) >> XLEN;
          trace->alu_type = AluType::IMUL;
          break;
        }
        case 3: {
          // RV32M: MULHU
          auto first = static_cast<DWord>(rsdata[t][0].u);
          auto second = static_cast<DWord>(rsdata[t][1].u);
          rddata[t].i = (first * second) >> XLEN;
          trace->alu_type = AluType::IMUL;
          break;
        }
        case 4: {
          // RV32M: DIV
          auto dividen = rsdata[t][0].i;
          auto divisor = rsdata[t][1].i;
          auto largest_negative = WordI(1) << (XLEN-1);
          if (divisor == 0) {
            rddata[t].i = -1;
          } else if (dividen == largest_negative && divisor == -1) {
            rddata[t].i = dividen;
          } else {
            rddata[t].i = dividen / divisor;
          }
          trace->alu_type = AluType::IDIV;
          break;
        }
        case 5: {
          // RV32M: DIVU
          auto dividen = rsdata[t][0].u;
          auto divisor = rsdata[t][1].u;
          if (divisor == 0) {
            rddata[t].i = -1;
          } else {
            rddata[t].i = dividen / divisor;
          }
          trace->alu_type = AluType::IDIV;
          break;
        }
        case 6: {
          // RV32M: REM
          auto dividen = rsdata[t][0].i;
          auto divisor = rsdata[t][1].i;
          auto largest_negative = WordI(1) << (XLEN-1);
          if (rsdata[t][1].i == 0) {
            rddata[t].i = dividen;
          } else if (dividen == largest_negative && divisor == -1) {
            rddata[t].i = 0;
          } else {
            rddata[t].i = dividen % divisor;
          }
          trace->alu_type = AluType::IDIV;
          break;
        }
        case 7: {
          // RV32M: REMU
          auto dividen = rsdata[t][0].u;
          auto divisor = rsdata[t][1].u;
          if (rsdata[t][1].i == 0) {
            rddata[t].i = dividen;
          } else {
            rddata[t].i = dividen % divisor;
          }
          trace->alu_type = AluType::IDIV;
          break;
        }
        default:
          std::abort();
        }
      } else {
        switch (func3) {
        case 0: {
          if (func7 & 0x20) {
            // RV32I: SUB
            rddata[t].i = rsdata[t][0].i - rsdata[t][1].i;
          } else {
            // RV32I: ADD
            rddata[t].i = rsdata[t][0].i + rsdata[t][1].i;
          }
          break;
        }
        case 1: {
          // RV32I: SLL
          Word shamt_mask = (Word(1) << log2up(XLEN)) - 1;
          Word shamt = rsdata[t][1].i & shamt_mask;
          rddata[t].i = rsdata[t][0].i << shamt;
          break;
        }
        case 2: {
          // RV32I: SLT
          rddata[t].i = rsdata[t][0].i < rsdata[t][1].i;
          break;
        }
        case 3: {
          // RV32I: SLTU
          rddata[t].i = rsdata[t][0].u < rsdata[t][1].u;
          break;
        }
        case 4: {
          // RV32I: XOR
          rddata[t].i = rsdata[t][0].i ^ rsdata[t][1].i;
          break;
        }
        case 5: {
          Word shamt_mask = ((Word)1 << log2up(XLEN)) - 1;
          Word shamt = rsdata[t][1].i & shamt_mask;
          if (func7 & 0x20) {
            // RV32I: SRA
            rddata[t].i = rsdata[t][0].i >> shamt;
          } else {
            // RV32I: SRL
            rddata[t].i = rsdata[t][0].u >> shamt;
          }
          break;
        }
        case 6: {
          // RV32I: OR
          rddata[t].i = rsdata[t][0].i | rsdata[t][1].i;
          break;
        }
        case 7: {
          // RV32I: AND
          rddata[t].i = rsdata[t][0].i & rsdata[t][1].i;
          break;
        }
        default:
          std::abort();
        }
      }
    }
    rd_write = true;
    break;
  }
  case Opcode::I: {
    trace->fu_type = FUType::ALU;
    trace->alu_type = AluType::ARITH;
    trace->src_regs[0] = {RegType::Integer, rsrc0};
    for (uint32_t t = thread_start; t < num_threads; ++t) {
      if (!warp.tmask.test(t))
        continue;
      switch (func3) {
      case 0: {
        // RV32I: ADDI
        rddata[t].i = rsdata[t][0].i + immsrc;
        break;
      }
      case 1: {
        // RV32I: SLLI
        rddata[t].i = rsdata[t][0].i << immsrc;
        break;
      }
      case 2: {
        // RV32I: SLTI
        rddata[t].i = rsdata[t][0].i < WordI(immsrc);
        break;
      }
      case 3: {
        // RV32I: SLTIU
        rddata[t].i = rsdata[t][0].u < immsrc;
        break;
      }
      case 4: {
        // RV32I: XORI
        rddata[t].i = rsdata[t][0].i ^ immsrc;
        break;
      }
      case 5: {
        if (func7 & 0x20) {
          // RV32I: SRAI
          Word result = rsdata[t][0].i >> immsrc;
          rddata[t].i = result;
        } else {
          // RV32I: SRLI
          Word result = rsdata[t][0].u >> immsrc;
          rddata[t].i = result;
        }
        break;
      }
      case 6: {
        // RV32I: ORI
        rddata[t].i = rsdata[t][0].i | immsrc;
        break;
      }
      case 7: {
        // RV32I: ANDI
        rddata[t].i = rsdata[t][0].i & immsrc;
        break;
      }
      }
    }
    rd_write = true;
    break;
  }
  case Opcode::R_W: {
    trace->fu_type = FUType::ALU;
    trace->alu_type = AluType::ARITH;
    trace->src_regs[0] = {RegType::Integer, rsrc0};
    trace->src_regs[1] = {RegType::Integer, rsrc1};
    for (uint32_t t = thread_start; t < num_threads; ++t) {
      if (!warp.tmask.test(t))
        continue;
      if (func7 & 0x1) {
        switch (func3) {
          case 0: {
            // RV64M: MULW
            int32_t product = (int32_t)rsdata[t][0].i * (int32_t)rsdata[t][1].i;
            rddata[t].i = sext((uint64_t)product, 32);
            trace->alu_type = AluType::IMUL;
            break;
          }
          case 4: {
            // RV64M: DIVW
            int32_t dividen = (int32_t)rsdata[t][0].i;
            int32_t divisor = (int32_t)rsdata[t][1].i;
            int32_t quotient;
            int32_t largest_negative = 0x80000000;
            if (divisor == 0){
              quotient = -1;
            } else if (dividen == largest_negative && divisor == -1) {
              quotient = dividen;
            } else {
              quotient = dividen / divisor;
            }
            rddata[t].i = sext((uint64_t)quotient, 32);
            trace->alu_type = AluType::IDIV;
            break;
          }
          case 5: {
            // RV64M: DIVUW
            uint32_t dividen = (uint32_t)rsdata[t][0].i;
            uint32_t divisor = (uint32_t)rsdata[t][1].i;
            uint32_t quotient;
            if (divisor == 0){
              quotient = -1;
            } else {
              quotient = dividen / divisor;
            }
            rddata[t].i = sext((uint64_t)quotient, 32);
            trace->alu_type = AluType::IDIV;
            break;
          }
          case 6: {
            // RV64M: REMW
            int32_t dividen = (uint32_t)rsdata[t][0].i;
            int32_t divisor = (uint32_t)rsdata[t][1].i;
            int32_t remainder;
            int32_t largest_negative = 0x80000000;
            if (divisor == 0){
              remainder = dividen;
            } else if (dividen == largest_negative && divisor == -1) {
              remainder = 0;
            } else {
              remainder = dividen % divisor;
            }
            rddata[t].i = sext((uint64_t)remainder, 32);
            trace->alu_type = AluType::IDIV;
            break;
          }
          case 7: {
            // RV64M: REMUW
            uint32_t dividen = (uint32_t)rsdata[t][0].i;
            uint32_t divisor = (uint32_t)rsdata[t][1].i;
            uint32_t remainder;
            if (divisor == 0){
              remainder = dividen;
            } else {
              remainder = dividen % divisor;
            }
            rddata[t].i = sext((uint64_t)remainder, 32);
            trace->alu_type = AluType::IDIV;
            break;
          }
          default:
            std::abort();
        }
      } else {
        switch (func3) {
        case 0: {
          if (func7 & 0x20){
            // RV64I: SUBW
            uint32_t result = (uint32_t)rsdata[t][0].i - (uint32_t)rsdata[t][1].i;
            rddata[t].i = sext((uint64_t)result, 32);
          }
          else{
            // RV64I: ADDW
            uint32_t result = (uint32_t)rsdata[t][0].i + (uint32_t)rsdata[t][1].i;
            rddata[t].i = sext((uint64_t)result, 32);
          }
          break;
        }
        case 1: {
          // RV64I: SLLW
          uint32_t shamt_mask = 0x1F;
          uint32_t shamt = rsdata[t][1].i & shamt_mask;
          uint32_t result = (uint32_t)rsdata[t][0].i << shamt;
          rddata[t].i = sext((uint64_t)result, 32);
          break;
        }
        case 5: {
          uint32_t shamt_mask = 0x1F;
          uint32_t shamt = rsdata[t][1].i & shamt_mask;
          uint32_t result;
          if (func7 & 0x20) {
            // RV64I: SRAW
            result = (int32_t)rsdata[t][0].i >> shamt;
          } else {
            // RV64I: SRLW
            result = (uint32_t)rsdata[t][0].i >> shamt;
          }
          rddata[t].i = sext((uint64_t)result, 32);
          break;
        }
        default:
          std::abort();
        }
      }
    }
    rd_write = true;
    break;
  }
  case Opcode::I_W: {
    trace->fu_type = FUType::ALU;
    trace->alu_type = AluType::ARITH;
    trace->src_regs[0] = {RegType::Integer, rsrc0};
    for (uint32_t t = thread_start; t < num_threads; ++t) {
      if (!warp.tmask.test(t))
        continue;
      switch (func3) {
        case 0: {
          // RV64I: ADDIW
          uint32_t result = (uint32_t)rsdata[t][0].i + (uint32_t)immsrc;
          rddata[t].i = sext((uint64_t)result, 32);
          break;
        }
        case 1: {
          // RV64I: SLLIW
          uint32_t shamt_mask = 0x1F;
          uint32_t shamt = immsrc & shamt_mask;
          uint32_t result = rsdata[t][0].i << shamt;
          rddata[t].i = sext((uint64_t)result, 32);
          break;
        }
        case 5: {
          uint32_t shamt_mask = 0x1F;
          uint32_t shamt = immsrc & shamt_mask;
          uint32_t result;
          if (func7 & 0x20) {
            // RV64I: SRAIW
            result = (int32_t)rsdata[t][0].i >> shamt;
          } else {
            // RV64I: SRLIW
            result = (uint32_t)rsdata[t][0].i >> shamt;
          }
          rddata[t].i = sext((uint64_t)result, 32);
          break;
        }
        default:
          std::abort();
      }
    }
    rd_write = true;
    break;
  }
  case Opcode::B: {
    trace->fu_type = FUType::ALU;
    trace->alu_type = AluType::BRANCH;
    trace->src_regs[0] = {RegType::Integer, rsrc0};
    trace->src_regs[1] = {RegType::Integer, rsrc1};
    bool all_taken = false;
    for (uint32_t t = thread_start; t < num_threads; ++t) {
      if (!warp.tmask.test(t))
        continue;
      bool curr_taken = false;
      switch (func3) {
      case 0: {
        // RV32I: BEQ
        if (rsdata[t][0].i == rsdata[t][1].i) {
          next_pc = warp.PC + immsrc;
          curr_taken = true;
        }
        break;
      }
      case 1: {
        // RV32I: BNE
        if (rsdata[t][0].i != rsdata[t][1].i) {
          next_pc = warp.PC + immsrc;
          curr_taken = true;
        }
        break;
      }
      case 4: {
        // RV32I: BLT
        if (rsdata[t][0].i < rsdata[t][1].i) {
          next_pc = warp.PC + immsrc;
          curr_taken = true;
        }
        break;
      }
      case 5: {
        // RV32I: BGE
        if (rsdata[t][0].i >= rsdata[t][1].i) {
          next_pc = warp.PC + immsrc;
          curr_taken = true;
        }
        break;
      }
      case 6: {
        // RV32I: BLTU
        if (rsdata[t][0].u < rsdata[t][1].u) {
          next_pc = warp.PC + immsrc;
          curr_taken = true;
        }
        break;
      }
      case 7: {
        // RV32I: BGEU
        if (rsdata[t][0].u >= rsdata[t][1].u) {
          next_pc = warp.PC + immsrc;
          curr_taken = true;
        }
        break;
      }
      default:
        std::abort();
      }
      if (t == thread_start) {
        all_taken = curr_taken;
      } else {
        if (all_taken != curr_taken) {
          std::cout << "divergent branch! PC=0x" << std::hex << warp.PC << std::dec << " (#" << trace->uuid << ")\n" << std::flush;
          std::abort();
        }
      }
    }
    trace->fetch_stall = true;
    break;
  }
  case Opcode::JAL: {
    // RV32I: JAL
    trace->fu_type = FUType::ALU;
    trace->alu_type = AluType::BRANCH;
    for (uint32_t t = thread_start; t < num_threads; ++t) {
      if (!warp.tmask.test(t))
        continue;
      rddata[t].i = next_pc;
    }
    next_pc = warp.PC + immsrc;
    trace->fetch_stall = true;
    rd_write = true;
    break;
  }
  case Opcode::JALR: {
    // RV32I: JALR
    trace->fu_type = FUType::ALU;
    trace->alu_type = AluType::BRANCH;
    trace->src_regs[0] = {RegType::Integer, rsrc0};
    for (uint32_t t = thread_start; t < num_threads; ++t) {
      if (!warp.tmask.test(t))
        continue;
      rddata[t].i = next_pc;
    }
    next_pc = rsdata[thread_last][0].i + immsrc;
    trace->fetch_stall = true;
    rd_write = true;
    break;
  }
  case Opcode::L:
  case Opcode::FL: {
    trace->fu_type = FUType::LSU;
    trace->lsu_type = LsuType::LOAD;
    trace->src_regs[0] = {RegType::Integer, rsrc0};
    auto trace_data = std::make_shared<LsuTraceData>(num_threads);
    trace->data = trace_data;
    if ((opcode == Opcode::L )
     || (opcode == Opcode::FL && func3 == 2)
     || (opcode == Opcode::FL && func3 == 3)) {
      uint32_t data_bytes = 1 << (func3 & 0x3);
      uint32_t data_width = 8 * data_bytes;
      for (uint32_t t = thread_start; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        uint64_t mem_addr = rsdata[t][0].i + immsrc;
        uint64_t read_data = 0;
        this->dcache_read(&read_data, mem_addr, data_bytes);
        trace_data->mem_addrs.at(t) = {mem_addr, data_bytes};
        switch (func3) {
        case 0: // RV32I: LB
        case 1: // RV32I: LH
          rddata[t].i = sext((Word)read_data, data_width);
          break;
        case 2:
          if (opcode == Opcode::L) {
            // RV32I: LW
            rddata[t].i = sext((Word)read_data, data_width);
          } else {
            // RV32F: FLW
            rddata[t].u64 = nan_box((uint32_t)read_data);
          }
          break;
        case 3: // RV64I: LD
                // RV32D: FLD
        case 4: // RV32I: LBU
        case 5: // RV32I: LHU
        case 6: // RV64I: LWU
          rddata[t].u64 = read_data;
          break;
        default:
          std::abort();
        }
      }
      rd_write = true;
    }
  #ifdef EXT_V_ENABLE
    else {
      this->loadVector(instr, wid, rsdata);
    }
  #endif
    break;
  }
  case Opcode::S:
  case Opcode::FS: {
    trace->fu_type = FUType::LSU;
    trace->lsu_type = LsuType::STORE;
    auto data_type = (opcode == Opcode::FS) ? RegType::Float : RegType::Integer;
    trace->src_regs[0] = {RegType::Integer, rsrc0};
    trace->src_regs[1] = {data_type, rsrc1};
    auto trace_data = std::make_shared<LsuTraceData>(num_threads);
    trace->data = trace_data;
    if ((opcode == Opcode::S)
     || (opcode == Opcode::FS && func3 == 2)
     || (opcode == Opcode::FS && func3 == 3)) {
      uint32_t data_bytes = 1 << (func3 & 0x3);
      for (uint32_t t = thread_start; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        uint64_t mem_addr = rsdata[t][0].i + immsrc;
        uint64_t write_data = rsdata[t][1].u64;
        trace_data->mem_addrs.at(t) = {mem_addr, data_bytes};
        switch (func3) {
        case 0:
        case 1:
        case 2:
        case 3:
          this->dcache_write(&write_data, mem_addr, data_bytes);
          break;
        default:
          std::abort();
        }
      }
    }
  #ifdef EXT_V_ENABLE
    else {
      this->storeVector(instr, wid, rsdata);
    }
  #endif
    break;
  }
  case Opcode::AMO: {
    trace->fu_type = FUType::LSU;
    trace->lsu_type = LsuType::LOAD;
    trace->src_regs[0] = {RegType::Integer, rsrc0};
    trace->src_regs[1] = {RegType::Integer, rsrc1};
    auto trace_data = std::make_shared<LsuTraceData>(num_threads);
    trace->data = trace_data;
    auto amo_type = func7 >> 2;
    uint32_t data_bytes = 1 << (func3 & 0x3);
    uint32_t data_width = 8 * data_bytes;
    for (uint32_t t = thread_start; t < num_threads; ++t) {
      if (!warp.tmask.test(t))
        continue;
      uint64_t mem_addr = rsdata[t][0].u;
      trace_data->mem_addrs.at(t) = {mem_addr, data_bytes};
      if (amo_type == 0x02) { // LR
        uint64_t read_data = 0;
        this->dcache_read(&read_data, mem_addr, data_bytes);
        this->dcache_amo_reserve(mem_addr);
        rddata[t].i = sext((Word)read_data, data_width);
      } else
      if (amo_type == 0x03) { // SC
        if (this->dcache_amo_check(mem_addr)) {
          this->dcache_write(&rsdata[t][1].u64, mem_addr, data_bytes);
          rddata[t].i = 0;
        } else {
          rddata[t].i = 1;
        }
      } else {
        uint64_t read_data = 0;
        this->dcache_read(&read_data, mem_addr, data_bytes);
        auto read_data_i = sext((WordI)read_data, data_width);
        auto rs1_data_i  = sext((WordI)rsdata[t][1].u64, data_width);
        auto read_data_u = zext((Word)read_data, data_width);
        auto rs1_data_u  = zext((Word)rsdata[t][1].u64, data_width);
        uint64_t result;
        switch (amo_type) {
        case 0x00:  // AMOADD
          result = read_data_i + rs1_data_i;
          break;
        case 0x01:  // AMOSWAP
          result = rs1_data_u;
          break;
        case 0x04:  // AMOXOR
          result = read_data_u ^ rs1_data_u;
          break;
        case 0x08:  // AMOOR
          result = read_data_u | rs1_data_u;
          break;
        case 0x0c:  // AMOAND
          result = read_data_u & rs1_data_u;
          break;
        case 0x10:  // AMOMIN
          result = std::min(read_data_i, rs1_data_i);
          break;
        case 0x14:  // AMOMAX
          result = std::max(read_data_i, rs1_data_i);
          break;
        case 0x18:  // AMOMINU
          result = std::min(read_data_u, rs1_data_u);
          break;
        case 0x1c:  // AMOMAXU
          result = std::max(read_data_u, rs1_data_u);
          break;
        default:
          std::abort();
        }
        this->dcache_write(&result, mem_addr, data_bytes);
        rddata[t].i = read_data_i;
      }
    }
    rd_write = true;
    break;
  }
  case Opcode::SYS: {
    for (uint32_t t = thread_start; t < num_threads; ++t) {
      if (!warp.tmask.test(t))
        continue;
      uint32_t csr_addr = immsrc;
      Word csr_value;
      if (func3 == 0) {
        trace->fu_type = FUType::ALU;
        trace->alu_type = AluType::SYSCALL;
        trace->fetch_stall = true;
        switch (csr_addr) {
        case 0x000: // RV32I: ECALL
          this->trigger_ecall(); // Re-added for riscv-vector test functionality
          break;
        case 0x001: // RV32I: EBREAK
          this->trigger_ebreak(); // Re-added for riscv-vector test functionality
          break;
        case 0x002: // RV32I: URET
        case 0x102: // RV32I: SRET
        case 0x302: // RV32I: MRET
          break;
        default:
          std::abort();
        }
      } else {
        trace->fu_type = FUType::SFU;
        // stall the fetch stage for FPU CSRs
        trace->fetch_stall = (csr_addr <= VX_CSR_FCSR);
        csr_value = this->get_csr(csr_addr, t, wid);
        switch (func3) {
        case 1: {
          // RV32I: CSRRW
          rddata[t].i = csr_value;
          this->set_csr(csr_addr, rsdata[t][0].i, t, wid);
          trace->src_regs[0] = {RegType::Integer, rsrc0};
          trace->sfu_type = SfuType::CSRRW;
          rd_write = true;
          break;
        }
        case 2: {
          // RV32I: CSRRS
          rddata[t].i = csr_value;
          if (rsdata[t][0].i != 0) {
            this->set_csr(csr_addr, csr_value | rsdata[t][0].i, t, wid);
          }
          trace->src_regs[0] = {RegType::Integer, rsrc0};
          trace->sfu_type = SfuType::CSRRS;
          rd_write = true;
          break;
        }
        case 3: {
          // RV32I: CSRRC
          rddata[t].i = csr_value;
          if (rsdata[t][0].i != 0) {
            this->set_csr(csr_addr, csr_value & ~rsdata[t][0].i, t, wid);
          }
          trace->src_regs[0] = {RegType::Integer, rsrc0};
          trace->sfu_type = SfuType::CSRRC;
          rd_write = true;
          break;
        }
        case 5: {
          // RV32I: CSRRWI
          rddata[t].i = csr_value;
          this->set_csr(csr_addr, rsrc0, t, wid);
          trace->sfu_type = SfuType::CSRRW;
          rd_write = true;
          break;
        }
        case 6: {
          // RV32I: CSRRSI;
          rddata[t].i = csr_value;
          if (rsrc0 != 0) {
            this->set_csr(csr_addr, csr_value | rsrc0, t, wid);
          }
          trace->sfu_type = SfuType::CSRRS;
          rd_write = true;
          break;
        }
        case 7: {
          // RV32I: CSRRCI
          rddata[t].i = csr_value;
          if (rsrc0 != 0) {
            this->set_csr(csr_addr, csr_value & ~rsrc0, t, wid);
          }
          trace->sfu_type = SfuType::CSRRC;
          rd_write = true;
          break;
        }
        default:
          break;
        }
      }
    }
    break;
  }
  case Opcode::FENCE: {
    // RV32I: FENCE
    trace->fu_type = FUType::LSU;
    trace->lsu_type = LsuType::FENCE;
    break;
  }
  case Opcode::FCI: {
    trace->fu_type = FUType::FPU;
    for (uint32_t t = thread_start; t < num_threads; ++t) {
      if (!warp.tmask.test(t))
        continue;
      uint32_t frm = this->get_fpu_rm(func3, t, wid);
      uint32_t fflags = 0;
      switch (func7) {
      case 0x00: { // RV32F: FADD.S
        rddata[t].u64 = nan_box(rv_fadd_s(check_boxing(rsdata[t][0].u64), check_boxing(rsdata[t][1].u64), frm, &fflags));
        trace->fpu_type = FpuType::FMA;
        trace->src_regs[0] = {RegType::Float, rsrc0};
        trace->src_regs[1] = {RegType::Float, rsrc1};
        break;
      }
      case 0x01: { // RV32D: FADD.D
        rddata[t].u64 = rv_fadd_d(rsdata[t][0].u64, rsdata[t][1].u64, frm, &fflags);
        trace->fpu_type = FpuType::FMA;
        trace->src_regs[0] = {RegType::Float, rsrc0};
        trace->src_regs[1] = {RegType::Float, rsrc1};
        break;
      }
      case 0x04: { // RV32F: FSUB.S
        rddata[t].u64 = nan_box(rv_fsub_s(check_boxing(rsdata[t][0].u64), check_boxing(rsdata[t][1].u64), frm, &fflags));
        trace->fpu_type = FpuType::FMA;
        trace->src_regs[0] = {RegType::Float, rsrc0};
        trace->src_regs[1] = {RegType::Float, rsrc1};
        break;
      }
      case 0x05: { // RV32D: FSUB.D
        rddata[t].u64 = rv_fsub_d(rsdata[t][0].u64, rsdata[t][1].u64, frm, &fflags);
        trace->fpu_type = FpuType::FMA;
        trace->src_regs[0] = {RegType::Float, rsrc0};
        trace->src_regs[1] = {RegType::Float, rsrc1};
        break;
      }
      case 0x08: { // RV32F: FMUL.S
        rddata[t].u64 = nan_box(rv_fmul_s(check_boxing(rsdata[t][0].u64), check_boxing(rsdata[t][1].u64), frm, &fflags));
        trace->fpu_type = FpuType::FMA;
        trace->src_regs[0] = {RegType::Float, rsrc0};
        trace->src_regs[1] = {RegType::Float, rsrc1};
        break;
      }
      case 0x09: { // RV32D: FMUL.D
        rddata[t].u64 = rv_fmul_d(rsdata[t][0].u64, rsdata[t][1].u64, frm, &fflags);
        trace->fpu_type = FpuType::FMA;
        trace->src_regs[0] = {RegType::Float, rsrc0};
        trace->src_regs[1] = {RegType::Float, rsrc1};
        break;
      }
      case 0x0c: { // RV32F: FDIV.S
        rddata[t].u64 = nan_box(rv_fdiv_s(check_boxing(rsdata[t][0].u64), check_boxing(rsdata[t][1].u64), frm, &fflags));
        trace->fpu_type = FpuType::FDIV;
        trace->src_regs[0] = {RegType::Float, rsrc0};
        trace->src_regs[1] = {RegType::Float, rsrc1};
        break;
      }
      case 0x0d: { // RV32D: FDIV.D
        rddata[t].u64 = rv_fdiv_d(rsdata[t][0].u64, rsdata[t][1].u64, frm, &fflags);
        trace->fpu_type = FpuType::FDIV;
        trace->src_regs[0] = {RegType::Float, rsrc0};
        trace->src_regs[1] = {RegType::Float, rsrc1};
        break;
      }
      case 0x10: {
        switch (func3) {
        case 0: // RV32F: FSGNJ.S
          rddata[t].u64 = nan_box(rv_fsgnj_s(check_boxing(rsdata[t][0].u64), check_boxing(rsdata[t][1].u64)));
          break;
        case 1: // RV32F: FSGNJN.S
          rddata[t].u64 = nan_box(rv_fsgnjn_s(check_boxing(rsdata[t][0].u64), check_boxing(rsdata[t][1].u64)));
          break;
        case 2: // RV32F: FSGNJX.S
          rddata[t].u64 = nan_box(rv_fsgnjx_s(check_boxing(rsdata[t][0].u64), check_boxing(rsdata[t][1].u64)));
          break;
        }
        trace->fpu_type = FpuType::FNCP;
        trace->src_regs[0] = {RegType::Float, rsrc0};
        trace->src_regs[1] = {RegType::Float, rsrc1};
        break;
      }
      case 0x11: {
        switch (func3) {
        case 0: // RV32D: FSGNJ.D
          rddata[t].u64 = rv_fsgnj_d(rsdata[t][0].u64, rsdata[t][1].u64);
          break;
        case 1: // RV32D: FSGNJN.D
          rddata[t].u64 = rv_fsgnjn_d(rsdata[t][0].u64, rsdata[t][1].u64);
          break;
        case 2: // RV32D: FSGNJX.D
          rddata[t].u64 = rv_fsgnjx_d(rsdata[t][0].u64, rsdata[t][1].u64);
          break;
        }
        trace->fpu_type = FpuType::FNCP;
        trace->src_regs[0] = {RegType::Float, rsrc0};
        trace->src_regs[1] = {RegType::Float, rsrc1};
        break;
      }
      case 0x14: {
        if (func3) {
          // RV32F: FMAX.S
          rddata[t].u64 = nan_box(rv_fmax_s(check_boxing(rsdata[t][0].u64), check_boxing(rsdata[t][1].u64), &fflags));
        } else {
          // RV32F: FMIN.S
          rddata[t].u64 = nan_box(rv_fmin_s(check_boxing(rsdata[t][0].u64), check_boxing(rsdata[t][1].u64), &fflags));
        }
        trace->fpu_type = FpuType::FNCP;
        trace->src_regs[0] = {RegType::Float, rsrc0};
        trace->src_regs[1] = {RegType::Float, rsrc1};
        break;
      }
      case 0x15: {
        if (func3) {
          // RV32D: FMAX.D
          rddata[t].u64 = rv_fmax_d(rsdata[t][0].u64, rsdata[t][1].u64, &fflags);
        } else {
          // RV32D: FMIN.D
          rddata[t].u64 = rv_fmin_d(rsdata[t][0].u64, rsdata[t][1].u64, &fflags);
        }
        trace->fpu_type = FpuType::FNCP;
        trace->src_regs[0] = {RegType::Float, rsrc0};
        trace->src_regs[1] = {RegType::Float, rsrc1};
        break;
      }
      case 0x20: {
        // RV32D: FCVT.S.D
        rddata[t].u64 = nan_box(rv_dtof(rsdata[t][0].u64));
        trace->fpu_type = FpuType::FNCP;
        trace->src_regs[0] = {RegType::Float, rsrc0};
        break;
      }
      case 0x21: {
        // RV32D: FCVT.D.S
        rddata[t].u64 = rv_ftod(check_boxing(rsdata[t][0].u64));
        trace->fpu_type = FpuType::FNCP;
        trace->src_regs[0] = {RegType::Float, rsrc0};
        break;
      }
      case 0x2c: { // RV32F: FSQRT.S
        rddata[t].u64 = nan_box(rv_fsqrt_s(check_boxing(rsdata[t][0].u64), frm, &fflags));
        trace->fpu_type = FpuType::FSQRT;
        trace->src_regs[0] = {RegType::Float, rsrc0};
        break;
      }
      case 0x2d: { // RV32D: FSQRT.D
        rddata[t].u64 = rv_fsqrt_d(rsdata[t][0].u64, frm, &fflags);
        trace->fpu_type = FpuType::FSQRT;
        trace->src_regs[0] = {RegType::Float, rsrc0};
        break;
      }
      case 0x50: {
        switch (func3) {
        case 0:
          // RV32F: FLE.S
          rddata[t].i = rv_fle_s(check_boxing(rsdata[t][0].u64), check_boxing(rsdata[t][1].u64), &fflags);
          break;
        case 1:
          // RV32F: FLT.S
          rddata[t].i = rv_flt_s(check_boxing(rsdata[t][0].u64), check_boxing(rsdata[t][1].u64), &fflags);
          break;
        case 2:
          // RV32F: FEQ.S
          rddata[t].i = rv_feq_s(check_boxing(rsdata[t][0].u64), check_boxing(rsdata[t][1].u64), &fflags);
          break;
        }
        trace->fpu_type = FpuType::FNCP;
        trace->src_regs[0] = {RegType::Float, rsrc0};
        trace->src_regs[1] = {RegType::Float, rsrc1};
        break;
      }
      case 0x51: {
        switch (func3) {
        case 0:
          // RV32D: FLE.D
          rddata[t].i = rv_fle_d(rsdata[t][0].u64, rsdata[t][1].u64, &fflags);
          break;
        case 1:
          // RV32D: FLT.D
          rddata[t].i = rv_flt_d(rsdata[t][0].u64, rsdata[t][1].u64, &fflags);
          break;
        case 2:
          // RV32D: FEQ.D
          rddata[t].i = rv_feq_d(rsdata[t][0].u64, rsdata[t][1].u64, &fflags);
          break;
        }
        trace->fpu_type = FpuType::FNCP;
        trace->src_regs[0] = {RegType::Float, rsrc0};
        trace->src_regs[1] = {RegType::Float, rsrc1};
        break;
      }
      case 0x60: {
        switch (rsrc1) {
        case 0:
          // RV32F: FCVT.W.S
          rddata[t].i = sext((uint64_t)rv_ftoi_s(check_boxing(rsdata[t][0].u64), frm, &fflags), 32);
          break;
        case 1:
          // RV32F: FCVT.WU.S
          rddata[t].i = sext((uint64_t)rv_ftou_s(check_boxing(rsdata[t][0].u64), frm, &fflags), 32);
          break;
        case 2:
          // RV64F: FCVT.L.S
          rddata[t].i = rv_ftol_s(check_boxing(rsdata[t][0].u64), frm, &fflags);
          break;
        case 3:
          // RV64F: FCVT.LU.S
          rddata[t].i = rv_ftolu_s(check_boxing(rsdata[t][0].u64), frm, &fflags);
          break;
        }
        trace->fpu_type = FpuType::FCVT;
        trace->src_regs[0] = {RegType::Float, rsrc0};
        break;
      }
      case 0x61: {
        switch (rsrc1) {
        case 0:
          // RV32D: FCVT.W.D
          rddata[t].i = sext((uint64_t)rv_ftoi_d(rsdata[t][0].u64, frm, &fflags), 32);
          break;
        case 1:
          // RV32D: FCVT.WU.D
          rddata[t].i = sext((uint64_t)rv_ftou_d(rsdata[t][0].u64, frm, &fflags), 32);
          break;
        case 2:
          // RV64D: FCVT.L.D
          rddata[t].i = rv_ftol_d(rsdata[t][0].u64, frm, &fflags);
          break;
        case 3:
          // RV64D: FCVT.LU.D
          rddata[t].i = rv_ftolu_d(rsdata[t][0].u64, frm, &fflags);
          break;
        }
        trace->fpu_type = FpuType::FCVT;
        trace->src_regs[0] = {RegType::Float, rsrc0};
        break;
      }
      case 0x68: {
        switch (rsrc1) {
        case 0:
          // RV32F: FCVT.S.W
          rddata[t].u64 = nan_box(rv_itof_s(rsdata[t][0].i, frm, &fflags));
          break;
        case 1:
          // RV32F: FCVT.S.WU
          rddata[t].u64 = nan_box(rv_utof_s(rsdata[t][0].i, frm, &fflags));
          break;
        case 2:
          // RV64F: FCVT.S.L
          rddata[t].u64 = nan_box(rv_ltof_s(rsdata[t][0].i, frm, &fflags));
          break;
        case 3:
          // RV64F: FCVT.S.LU
          rddata[t].u64 = nan_box(rv_lutof_s(rsdata[t][0].i, frm, &fflags));
          break;
        }
        trace->fpu_type = FpuType::FCVT;
        trace->src_regs[0] = {RegType::Integer, rsrc0};
        break;
      }
      case 0x69: {
        switch (rsrc1) {
        case 0:
          // RV32D: FCVT.D.W
          rddata[t].u64 = rv_itof_d(rsdata[t][0].i, frm, &fflags);
          break;
        case 1:
          // RV32D: FCVT.D.WU
          rddata[t].u64 = rv_utof_d(rsdata[t][0].i, frm, &fflags);
          break;
        case 2:
          // RV64D: FCVT.D.L
          rddata[t].u64 = rv_ltof_d(rsdata[t][0].i, frm, &fflags);
          break;
        case 3:
          // RV64D: FCVT.D.LU
          rddata[t].u64 = rv_lutof_d(rsdata[t][0].i, frm, &fflags);
          break;
        }
        trace->fpu_type = FpuType::FCVT;
        trace->src_regs[0] = {RegType::Integer, rsrc0};
        break;
      }
      case 0x70: {
        if (func3) {
          // RV32F: FCLASS.S
          rddata[t].i = rv_fclss_s(check_boxing(rsdata[t][0].u64));
        } else {
          // RV32F: FMV.X.S
          uint32_t result = (uint32_t)rsdata[t][0].u64;
          rddata[t].i = sext((uint64_t)result, 32);
        }
        trace->fpu_type = FpuType::FNCP;
        trace->src_regs[0] = {RegType::Float, rsrc0};
        break;
      }
      case 0x71: {
        if (func3) {
          // RV32D: FCLASS.D
          rddata[t].i = rv_fclss_d(rsdata[t][0].u64);
        } else {
          // RV64D: FMV.X.D
          rddata[t].i = rsdata[t][0].u64;
        }
        trace->fpu_type = FpuType::FNCP;
        trace->src_regs[0] = {RegType::Float, rsrc0};
        break;
      }
      case 0x78: { // RV32F: FMV.S.X
        rddata[t].u64 = nan_box((uint32_t)rsdata[t][0].i);
        trace->fpu_type = FpuType::FNCP;
        trace->src_regs[0] = {RegType::Integer, rsrc0};
        break;
      }
      case 0x79: { // RV64D: FMV.D.X
        rddata[t].u64 = rsdata[t][0].i;
        trace->fpu_type = FpuType::FNCP;
        trace->src_regs[0] = {RegType::Integer, rsrc0};
        break;
      }
      }
      this->update_fcrs(fflags, t, wid);
    }
    rd_write = true;
    break;
  }
  case Opcode::FMADD:
  case Opcode::FMSUB:
  case Opcode::FMNMADD:
  case Opcode::FMNMSUB: {
    trace->fpu_type = FpuType::FMA;
    trace->src_regs[0] = {RegType::Float, rsrc0};
    trace->src_regs[1] = {RegType::Float, rsrc1};
    trace->src_regs[2] = {RegType::Float, rsrc2};
    for (uint32_t t = thread_start; t < num_threads; ++t) {
      if (!warp.tmask.test(t))
        continue;
      uint32_t frm = this->get_fpu_rm(func3, t, wid);
      uint32_t fflags = 0;
      switch (opcode) {
      case Opcode::FMADD:
        if (func2)
          // RV32D: FMADD.D
          rddata[t].u64 = rv_fmadd_d(rsdata[t][0].u64, rsdata[t][1].u64, rsdata[t][2].u64, frm, &fflags);
        else
          // RV32F: FMADD.S
          rddata[t].u64 = nan_box(rv_fmadd_s(check_boxing(rsdata[t][0].u64), check_boxing(rsdata[t][1].u64), check_boxing(rsdata[t][2].u64), frm, &fflags));
        break;
      case Opcode::FMSUB:
        if (func2)
          // RV32D: FMSUB.D
          rddata[t].u64 = rv_fmsub_d(rsdata[t][0].u64, rsdata[t][1].u64, rsdata[t][2].u64, frm, &fflags);
        else
          // RV32F: FMSUB.S
          rddata[t].u64 = nan_box(rv_fmsub_s(check_boxing(rsdata[t][0].u64), check_boxing(rsdata[t][1].u64), check_boxing(rsdata[t][2].u64), frm, &fflags));
        break;
      case Opcode::FMNMADD:
        if (func2)
          // RV32D: FNMADD.D
          rddata[t].u64 = rv_fnmadd_d(rsdata[t][0].u64, rsdata[t][1].u64, rsdata[t][2].u64, frm, &fflags);
        else
          // RV32F: FNMADD.S
          rddata[t].u64 = nan_box(rv_fnmadd_s(check_boxing(rsdata[t][0].u64), check_boxing(rsdata[t][1].u64), check_boxing(rsdata[t][2].u64), frm, &fflags));
        break;
      case Opcode::FMNMSUB:
        if (func2)
          // RV32D: FNMSUB.D
          rddata[t].u64 = rv_fnmsub_d(rsdata[t][0].u64, rsdata[t][1].u64, rsdata[t][2].u64, frm, &fflags);
        else
          // RV32F: FNMSUB.S
          rddata[t].u64 = nan_box(rv_fnmsub_s(check_boxing(rsdata[t][0].u64), check_boxing(rsdata[t][1].u64), check_boxing(rsdata[t][2].u64), frm, &fflags));
        break;
      default:
        break;
      }
      this->update_fcrs(fflags, t, wid);
    }
    rd_write = true;
    break;
  }
  case Opcode::EXT1: {
    switch (func7) {
    case 0: {
      switch (func3) {
      case 0: {
        // TMC
        trace->fu_type = FUType::SFU;
        trace->sfu_type = SfuType::TMC;
        trace->src_regs[0] = {RegType::Integer, rsrc0};
        trace->fetch_stall = true;
        next_tmask.reset();
        for (uint32_t t = 0; t < num_threads; ++t) {
          next_tmask.set(t, rsdata.at(thread_last)[0].i & (1 << t));
        }
      } break;
      case 1: {
        // WSPAWN
        trace->fu_type = FUType::SFU;
        trace->sfu_type = SfuType::WSPAWN;
        trace->src_regs[0] = {RegType::Integer, rsrc0};
        trace->src_regs[1] = {RegType::Integer, rsrc1};
        trace->fetch_stall = true;
        trace->data = std::make_shared<SFUTraceData>(rsdata.at(thread_last)[0].i, rsdata.at(thread_last)[1].i);
      } break;
      case 2: {
        // SPLIT
        trace->fu_type = FUType::SFU;
        trace->sfu_type = SfuType::SPLIT;
        trace->src_regs[0] = {RegType::Integer, rsrc0};
        trace->fetch_stall = true;

        auto stack_size = warp.ipdom_stack.size();

        ThreadMask then_tmask, else_tmask;
        auto not_pred = (rsrc1 != 0);
        for (uint32_t t = 0; t < num_threads; ++t) {
          auto cond = (warp.ireg_file.at(t).at(rsrc0) & 0x1) ^ not_pred;
          then_tmask[t] = warp.tmask.test(t) && cond;
          else_tmask[t] = warp.tmask.test(t) && !cond;
        }

        bool is_divergent = then_tmask.any() && else_tmask.any();
        if (is_divergent) {
          if (stack_size == ipdom_size_) {
            std::cout << "IPDOM stack is full! size=" << stack_size << ", PC=0x" << std::hex << warp.PC << std::dec << " (#" << trace->uuid << ")\n" << std::flush;
            std::abort();
          }
          // set new thread mask to the larger set
          if (then_tmask.count() >= else_tmask.count()) {
            next_tmask = then_tmask;
          } else {
            next_tmask = else_tmask;
          }
          // push reconvergence and not-taken thread mask onto the stack
          auto ntaken_tmask = ~next_tmask & warp.tmask;
          warp.ipdom_stack.emplace(warp.tmask, ntaken_tmask, next_pc);
        }
        // return divergent state
        for (uint32_t t = thread_start; t < num_threads; ++t) {
          rddata[t].i = stack_size;
        }
        rd_write = true;
      } break;
      case 3: {
        // JOIN
        trace->fu_type = FUType::SFU;
        trace->sfu_type = SfuType::JOIN;
        trace->src_regs[0] = {RegType::Integer, rsrc0};
        trace->fetch_stall = true;

        auto stack_ptr = warp.ireg_file.at(thread_last).at(rsrc0);
        if (stack_ptr != warp.ipdom_stack.size()) {
          if (warp.ipdom_stack.empty()) {
            std::cout << "IPDOM stack is empty!\n" << std::flush;
            std::abort();
          }
          if (warp.ipdom_stack.top().fallthrough) {
            next_tmask = warp.ipdom_stack.top().orig_tmask;
            warp.ipdom_stack.pop();
          } else {
            next_tmask = warp.ipdom_stack.top().else_tmask;
            next_pc = warp.ipdom_stack.top().PC;
            warp.ipdom_stack.top().fallthrough = true;
          }
        }
      } break;
      case 4: {
        // BAR
        trace->fu_type = FUType::SFU;
        trace->sfu_type = SfuType::BAR;
        trace->src_regs[0] = {RegType::Integer, rsrc0};
        trace->src_regs[1] = {RegType::Integer, rsrc1};
        trace->fetch_stall = true;
        trace->data = std::make_shared<SFUTraceData>(rsdata[thread_last][0].i, rsdata[thread_last][1].i);
      } break;
      case 5: {
        // PRED
        trace->fu_type = FUType::SFU;
        trace->sfu_type = SfuType::PRED;
        trace->src_regs[0] = {RegType::Integer, rsrc0};
        trace->src_regs[1] = {RegType::Integer, rsrc1};
        trace->fetch_stall = true;
        ThreadMask pred;
        auto not_pred = rdest & 0x1;
        for (uint32_t t = 0; t < num_threads; ++t) {
          auto cond = (warp.ireg_file.at(t).at(rsrc0) & 0x1) ^ not_pred;
          pred[t] = warp.tmask.test(t) && cond;
        }
        if (pred.any()) {
          next_tmask &= pred;
        } else {
          next_tmask = warp.ireg_file.at(thread_last).at(rsrc1);
        }
      } break;
      default:
        std::abort();
      }
    } break;
    default:
      std::abort();
    }
  } break;
  case Opcode::TCU:
  { //TODO - make it data-type flexible
    uint32_t mem_bytes = 1;
    DP(3, "mem_bytes=" << mem_bytes << std::endl);
    uint16_t tc_size = this->get_csr(VX_TC_SIZE, 0, wid);
    uint32_t TC_per_warp = this->get_csr(VX_TC_NUM, 0, wid);

    DP(3, "tc_size=" << tc_size << std::endl);
    DP(3, "TC_per_warp=" << TC_per_warp << std::endl);

    //Number of loads - dependant on the thread config
    uint32_t n_tiles = this->get_csr(VX_MAT_MUL_SIZE, 0, wid);  //CSR instruction before MLOAD will ensure that this csr has value
    int num_data_per_thread;
    int num_data_per_thread_st;
    uint32_t num_threads_actv;
    uint32_t num_threads_actv_st;
    uint32_t data_bytes_load;
    uint32_t data_bytes_store;
    uint32_t num_threads_per_tc = MAX (1, num_threads/TC_per_warp);

    //LOAD
    if(num_threads > tc_size*tc_size*n_tiles*TC_per_warp)
    {
      num_threads_actv = tc_size*tc_size*n_tiles*TC_per_warp;
      num_data_per_thread = 1;
    }
    else
    {
      num_threads_actv = num_threads;
      num_data_per_thread = (tc_size*tc_size*n_tiles)/num_threads_per_tc;
    }
    data_bytes_load = mem_bytes*num_data_per_thread;

    //STORE
    if(num_threads > tc_size*tc_size*TC_per_warp)
    {
      num_threads_actv_st = tc_size*tc_size*TC_per_warp;
      num_data_per_thread_st = 1;
    }
    else
    {
      num_threads_actv_st = num_threads;
      num_data_per_thread_st = (tc_size*tc_size)/num_threads_per_tc;
    }
    data_bytes_store = mem_bytes*num_data_per_thread_st;

    DP(3, "Num Tiles=" << n_tiles << std::endl);

    switch (func3) {
      case 0:
      { //Matrix Load

        DP (4, "TCU LOAD");
        trace->fu_type = FUType::LSU;
        trace->lsu_type = LsuType::TCU_LOAD;

        trace->src_regs[0] = {RegType::Integer, rsrc0};
        auto trace_data = std::make_shared<LsuTraceData>(num_threads);
        trace->data = trace_data;

        for (uint32_t t = thread_start; t < num_threads_actv; ++t)
        {
          if (!warp.tmask.test(t))
            continue;
          DP(3, "Thread ID" << t);

          uint32_t base_addr = rsdata[t][0].i ;
          trace_data->mem_addrs.at(t) = {base_addr, data_bytes_load};

          //Load A or B (depends on immsrc)
          int loop_offset = 0;
          DP(3, "n_tiles = " << n_tiles << "; num_data_per_thread = " << num_data_per_thread <<std::endl);
            for (int n=0; n<num_data_per_thread; n++)
            {
              Word* temp_ref = &(warp.ireg_file.at(t).at(rsrc0));
              this->dcache_read(temp_ref, (base_addr+(n*mem_bytes)+(loop_offset*mem_bytes)), mem_bytes);

              scratchpad[loop_offset + (immsrc*(n_tiles)*tc_size*tc_size) + (t*num_data_per_thread) + n] = *temp_ref;
              DP(3, "Scratchpad Index: " << loop_offset + (immsrc*(n_tiles)*tc_size*tc_size) + (t*num_data_per_thread) + n << ", Value: " << scratchpad[loop_offset + (immsrc*(n_tiles)*tc_size*tc_size) + (t*num_data_per_thread) + n]);
            }
        }
        rd_write = true;
      } break;
      case 1:
      {
        DP(4, "TCU STORE");
        trace->fu_type = FUType::LSU;
        trace->lsu_type = LsuType::TCU_STORE;

        auto trace_data = std::make_shared<LsuTraceData>(num_threads);
        trace->data = trace_data;

        for (uint32_t t = thread_start; t < num_threads_actv_st; ++t)
        {
          if (!warp.tmask.test(t))
            continue;

          DP(3, "Thread ID" << t);
          uint32_t base_addr = rsdata[t][0].i ;

          trace_data->mem_addrs.at(t) = {base_addr, data_bytes_store};

          //Store C
          for (int n=0; n<num_data_per_thread_st; n++)
          {
            Word* temp_ref = &(warp.ireg_file.at(t).at(rsrc0));
            *temp_ref = scratchpad[(n_tiles*tc_size*tc_size*2) + (t*num_data_per_thread_st) + n];

            this->dcache_write(temp_ref, base_addr+(n*mem_bytes), mem_bytes);
          }
        }
        //Clear the scratchpad
        for(long unsigned int i=0 ; i < scratchpad.size(); i++)
        {
          scratchpad[i] = 0;
        }
      }
      break;
      case 2:
      { //Matrix Multiply
        DP(4, "TCU MULTIPLY MAT");
        trace->fu_type = FUType::TCU;
        trace->tcu_type = TCUType::TCU_MUL;
        uint32_t threads_per_tc = MAX (1, num_threads/TC_per_warp);
        for (uint32_t t = thread_start; t < num_threads_actv; ++t)
        {
          if (!warp.tmask.test(t))
            continue;

          DP(3, "Thread ID" << t);
          //TC operation [only 1 thread in 1 warp needs to do this]
          if (t%threads_per_tc == 0)
          {
            /*
            // TODO : Fix needed for functional correctness
            // TODO : change to systolic array implementation
            uint32_t thread_offset = t*(tc_size*tc_size);

            int loop_offset = 0;
            int offset_b = n_tiles*n_tiles*n_tiles*tc_size*tc_size;
            uint32_t accu_offset = (n_tiles)*(n_tiles)*(n_tiles)*tc_size*tc_size*2;
            for(int tiles = 0 ; tiles < n_tiles ; tiles++)  //What's the HW implication of this?? A counter implementation?
            {
              for (int i = 0; i < tc_size; i++) { //ROW-1
                for (int j = 0; j < tc_size; j++) { //COL-2
                  int sum = 0;
                  for (int k = 0; k < tc_size; k++)
                  { //COL-1
                    sum = sum + scratchpad[loop_offset + thread_offset*n_tiles + i * tc_size + k] *scratchpad[loop_offset + thread_offset*n_tiles + offset_b + (k * tc_size + j)];
                  }
                  scratchpad[accu_offset + thread_offset +(i * tc_size + j)] += sum; //[i * col2 + j] = sum
                  DP(3, "Scratchpad Index: " << accu_offset + (i * tc_size + j) << " , Value=" << scratchpad[accu_offset + (i * tc_size + j)]);
                }
              }
              loop_offset += tc_size*tc_size; //Move to the next tiled matmul fragment
            }
            */
          }
        }

      }break;
      default:
        std::abort();
    }
  } break;
#ifdef EXT_V_ENABLE
  case Opcode::VSET: {
    auto func6 = instr.getFunc6();
    if ((func3 == 0x7) || (func3 == 0x2 && func6 == 16) || (func3 == 0x1 && func6 == 16)) {
      rd_write = true;
    }
    executeVector(instr, wid, rsdata, rddata);
  } break;
#endif
  default:
    std::abort();
  }

  if (rd_write) {
    trace->wb = true;
    auto type = instr.getRDType();
    switch (type) {
    case RegType::Integer:
      if (rdest) {
        DPH(2, "Dest Reg: " << type << rdest << "={");
        for (uint32_t t = 0; t < num_threads; ++t) {
          if (t) DPN(2, ", ");
          if (!warp.tmask.test(t)) {
            DPN(2, "-");
            continue;
          }
          warp.ireg_file.at(t)[rdest] = rddata[t].i;
          DPN(2, "0x" << std::hex << rddata[t].i << std::dec);
        }
        DPN(2, "}" << std::endl);
        trace->dst_reg = {type, rdest};
        assert(rdest != 0);
      } else {
        // disable writes to x0
        trace->wb = false;
      }
      break;
    case RegType::Float:
      DPH(2, "Dest Reg: " << type << rdest << "={");
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (t) DPN(2, ", ");
        if (!warp.tmask.test(t)) {
          DPN(2, "-");
          continue;
        }
        warp.freg_file.at(t)[rdest] = rddata[t].u64;
        DPN(2, "0x" << std::hex << rddata[t].f << std::dec);
      }
      DPN(2, "}" << std::endl);
      trace->dst_reg = {type, rdest};
      break;
    default:
      std::cout << "Unrecognized register write back type: " << type << std::endl;
      std::abort();
      break;
    }
  }

  warp.PC += 4;

  if (warp.PC != next_pc) {
    DP(3, "*** Next PC=0x" << std::hex << next_pc << std::dec);
    warp.PC = next_pc;
  }

  if (warp.tmask != next_tmask) {
    DP(3, "*** New Tmask=" << ThreadMaskOS(next_tmask, num_threads));
    warp.tmask = next_tmask;
    if (!next_tmask.any()) {
      active_warps_.reset(wid);
    }
  }
}
// --- End of content from sim/simx/execute.cpp ---

// --- Start of content from sim/simx/func_unit.cpp ---
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// MERGED_LOCALLY: #include "func_unit.h"
#include <iostream>
#include <iomanip>
#include <string.h>
#include <assert.h>
#include <util.h>
// MERGED_LOCALLY: #include "debug.h"
// MERGED_LOCALLY: #include "core.h"
// MERGED_LOCALLY: #include "constants.h"
// MERGED_LOCALLY: #include "cache_sim.h"
// MERGED_LOCALLY: #include "VX_types.h"

using namespace vortex;

AluUnit::AluUnit(const SimContext& ctx, Core* core) : FuncUnit(ctx, core, "alu-unit") {}

void AluUnit::tick() {
  for (uint32_t iw = 0; iw < ISSUE_WIDTH; ++iw) {
		auto& input = Inputs.at(iw);
		if (input.empty())
			continue;
		auto& output = Outputs.at(iw);
		auto trace = input.front();
		int delay = 2;
		switch (trace->alu_type) {
		case AluType::ARITH:
		case AluType::BRANCH:
		case AluType::SYSCALL:
			output.push(trace, 2+delay);
			break;
		case AluType::IMUL:
			output.push(trace, LATENCY_IMUL+delay);
			break;
		case AluType::IDIV:
			output.push(trace, XLEN+delay);
			break;
		default:
			std::abort();
		}
		DT(3, this->name() << ": op=" << trace->alu_type << ", " << *trace);
		if (trace->eop && trace->fetch_stall) {
			core_->resume(trace->wid);
		}
		input.pop();
	}
}

///////////////////////////////////////////////////////////////////////////////

FpuUnit::FpuUnit(const SimContext& ctx, Core* core) : FuncUnit(ctx, core, "fpu-unit") {}

void FpuUnit::tick() {
	for (uint32_t iw = 0; iw < ISSUE_WIDTH; ++iw) {
		auto& input = Inputs.at(iw);
		if (input.empty())
			continue;
		auto& output = Outputs.at(iw);
		auto trace = input.front();
		int delay = 2;
		switch (trace->fpu_type) {
		case FpuType::FNCP:
			output.push(trace, 2+delay);
			break;
		case FpuType::FMA:
			output.push(trace, LATENCY_FMA+delay);
			break;
		case FpuType::FDIV:
			output.push(trace, LATENCY_FDIV+delay);
			break;
		case FpuType::FSQRT:
			output.push(trace, LATENCY_FSQRT+delay);
			break;
		case FpuType::FCVT:
			output.push(trace, LATENCY_FCVT+delay);
			break;
		default:
			std::abort();
		}
		DT(3,this->name() << ": op=" << trace->fpu_type << ", " << *trace);
		input.pop();
	}
}

///////////////////////////////////////////////////////////////////////////////

LsuUnit::LsuUnit(const SimContext& ctx, Core* core)
	: FuncUnit(ctx, core, "lsu-unit")
	, pending_loads_(0)
{}

LsuUnit::~LsuUnit()
{}

void LsuUnit::reset() {
	for (auto& state : states_) {
		state.clear();
	}
	pending_loads_ = 0;
}

void LsuUnit::tick() {
	core_->perf_stats_.load_latency += pending_loads_;

	// handle memory responses
	for (uint32_t b = 0; b < NUM_LSU_BLOCKS; ++b) {
		auto& lsu_rsp_port = core_->lmem_switch_.at(b)->RspIn;
		if (lsu_rsp_port.empty())
			continue;
		auto& state = states_.at(b);
		auto& lsu_rsp = lsu_rsp_port.front();
		DT(3, this->name() << "-mem-rsp: " << lsu_rsp);
		auto& entry = state.pending_rd_reqs.at(lsu_rsp.tag);
		auto trace = entry.trace;
		assert(!entry.mask.none());
		entry.mask &= ~lsu_rsp.mask; // track remaining
		if (entry.mask.none()) {
			// whole response received, release trace
			int iw = trace->wid % ISSUE_WIDTH;
			Outputs.at(iw).push(trace, 1);
			state.pending_rd_reqs.release(lsu_rsp.tag);
		}
		pending_loads_ -= lsu_rsp.mask.count();
		lsu_rsp_port.pop();
	}

	// handle LSU requests
	for (uint32_t iw = 0; iw < ISSUE_WIDTH; ++iw) {
		uint32_t block_idx = iw % NUM_LSU_BLOCKS;
		auto& state = states_.at(block_idx);
		if (state.fence_lock) {
			// wait for all pending memory operations to complete
			if (!state.pending_rd_reqs.empty())
				continue;
			Outputs.at(iw).push(state.fence_trace, 1);
			state.fence_lock = false;
			DT(3, this->name() << "-fence-unlock: " << state.fence_trace);
		}

		// check input queue
		auto& input = Inputs.at(iw);
		if (input.empty())
			continue;

		auto trace = input.front();

		if (trace->lsu_type == LsuType::FENCE) {
			// schedule fence lock
			state.fence_trace = trace;
			state.fence_lock = true;
			DT(3, this->name() << "-fence-lock: " << *trace);
			// remove input
			input.pop();
			continue;
		}

		bool is_write = ((trace->lsu_type == LsuType::STORE) || (trace->lsu_type == LsuType::TCU_STORE));

		// check pending queue capacity
		if (!is_write && state.pending_rd_reqs.full()) {
			if (!trace->log_once(true)) {
				DT(4, "*** " << this->name() << "-queue-full: " << *trace);
			}
			continue;
		} else {
			trace->log_once(false);
		}

		// build memory request
		LsuReq lsu_req(NUM_LSU_LANES);
		lsu_req.write = is_write;
		{
			auto trace_data = std::dynamic_pointer_cast<LsuTraceData>(trace->data);
			auto t0 = trace->pid * NUM_LSU_LANES;
			for (uint32_t i = 0; i < NUM_LSU_LANES; ++i) {
				if (trace->tmask.test(t0 + i)) {
					lsu_req.mask.set(i);
					lsu_req.addrs.at(i) = trace_data->mem_addrs.at(t0 + i).addr;
				}
			}
		}
		uint32_t tag = 0;

		if (!is_write) {
			tag = state.pending_rd_reqs.allocate({trace, lsu_req.mask});
		}
		lsu_req.tag  = tag;
		lsu_req.cid  = trace->cid;
		lsu_req.uuid = trace->uuid;

		// send memory request
		core_->lmem_switch_.at(block_idx)->ReqIn.push(lsu_req);
		DT(3, this->name() << "-mem-req: " << lsu_req);

		// update stats
		auto num_addrs = lsu_req.mask.count();
		if (is_write) {
			core_->perf_stats_.stores += num_addrs;
		} else {
			core_->perf_stats_.loads += num_addrs;
			pending_loads_ += num_addrs;
		}

		// do not wait on writes
		if (is_write) {
			Outputs.at(iw).push(trace, 1);
		}

		// remove input
		input.pop();
	}
}
/*  TO BE FIXED:Tensor_core code
    send_request is not used anymore. Need to be modified number of load
*/
/*
int LsuUnit::send_requests(instr_trace_t* trace, int block_idx, int tag) {
	int count = 0;

	auto trace_data = std::dynamic_pointer_cast<LsuTraceData>(trace->data);
	bool is_write = ((trace->lsu_type == LsuType::STORE) || (trace->lsu_type == LsuType::TCU_STORE));

	uint16_t req_per_thread = 1;
	if ((trace->lsu_type == LsuType::TCU_LOAD) || (trace->lsu_type == LsuType::TCU_STORE))
	{
 		req_per_thread= (1>(trace_data->mem_addrs.at(0).size)/4)? 1: ((trace_data->mem_addrs.at(0).size)/4);
	}

	auto t0 = trace->pid * NUM_LSU_LANES;

	for (uint32_t i = 0; i < NUM_LSU_LANES; ++i) {
		uint32_t t = t0 + i;
		if (!trace->tmask.test(t))
			continue;

		int req_idx = block_idx * LSU_CHANNELS + (i % LSU_CHANNELS);
		auto& dcache_req_port = core_->lmem_switch_.at(req_idx)->ReqIn;

		auto mem_addr = trace_data->mem_addrs.at(t);
		auto type = get_addr_type(mem_addr.addr);
		// DT(3, "addr_type = " << type << ", " << *trace);
		uint32_t mem_bytes = 1;
		for (int i = 0; i < req_per_thread; i++)
		{
			MemReq mem_req;
			mem_req.addr  = mem_addr.addr + (i*mem_bytes);
			mem_req.write = is_write;
			mem_req.type  = type;
			mem_req.tag   = tag;
			mem_req.cid   = trace->cid;
			mem_req.uuid  = trace->uuid;

			dcache_req_port.push(mem_req, 1);
			DT(3, "mem-req: addr=0x" << std::hex << mem_req.addr << ", tag=" << tag
				<< ", lsu_type=" << trace->lsu_type << ", rid=" << req_idx << ", addr_type=" << mem_req.type << ", " << *trace);

			if (is_write) {
				++core_->perf_stats_.stores;
			} else {
				++core_->perf_stats_.loads;
				++pending_loads_;
			}

			++count;
		}
	}
	return count;
}
*/

///////////////////////////////////////////////////////////////////////////////

TcuUnit::TcuUnit(const SimContext& ctx, Core* core)
    : FuncUnit(ctx, core, "TCU")
    {}

void TcuUnit::tick() {

	for (uint32_t i = 0; i < ISSUE_WIDTH; ++i) {
        auto& input = Inputs.at(i);
        if (input.empty())
            continue;
        auto& output = Outputs.at(i);
        auto trace = input.front();
        uint32_t n_tiles = core_->emulator_.get_tiles();
		uint32_t tc_size = core_->emulator_.get_tc_size();

        switch (trace->tcu_type) {
            case TCUType::TCU_MUL:
            {    //mat size = n_tiles * tc_size
                int matmul_latency = (n_tiles * tc_size) + tc_size + tc_size;
                output.push(trace, matmul_latency);
				DT(3, "matmul_latency = " << matmul_latency << ", " << *trace);
                break;
            }
            default:
                std::abort();
        }
        DT(3, "pipeline-execute: op=" << trace->tcu_type << ", " << *trace);
        input.pop();
    }
}

///////////////////////////////////////////////////////////////////////////////

SfuUnit::SfuUnit(const SimContext& ctx, Core* core)
	: FuncUnit(ctx, core, "sfu-unit")
{}

void SfuUnit::tick() {
	// check input queue
	for (uint32_t iw = 0; iw < ISSUE_WIDTH; ++iw) {
		auto& input = Inputs.at(iw);
		if (input.empty())
			continue;
		auto& output = Outputs.at(iw);
		auto trace = input.front();
		auto sfu_type = trace->sfu_type;
		bool release_warp = trace->fetch_stall;
		int delay = 2;
		switch  (sfu_type) {
		case SfuType::WSPAWN:
			output.push(trace, 2+delay);
			if (trace->eop) {
				auto trace_data = std::dynamic_pointer_cast<SFUTraceData>(trace->data);
				release_warp = core_->wspawn(trace_data->arg1, trace_data->arg2);
			}
			break;
		case SfuType::TMC:
		case SfuType::SPLIT:
		case SfuType::JOIN:
		case SfuType::PRED:
		case SfuType::CSRRW:
		case SfuType::CSRRS:
		case SfuType::CSRRC:
			output.push(trace, 2+delay);
			break;
		case SfuType::BAR: {
			output.push(trace, 2+delay);
			if (trace->eop) {
				auto trace_data = std::dynamic_pointer_cast<SFUTraceData>(trace->data);
				release_warp = core_->barrier(trace_data->arg1, trace_data->arg2, trace->wid);
			}
		} break;
		default:
			std::abort();
		}

		DT(3, this->name() << ": op=" << trace->sfu_type << ", " << *trace);
		if (trace->eop && release_warp)  {
			core_->resume(trace->wid);
		}

		input.pop();
	}
}
// --- End of content from sim/simx/func_unit.cpp ---

// --- Start of content from sim/simx/local_mem.cpp ---
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// MERGED_LOCALLY: #include "local_mem.h"
// MERGED_LOCALLY: #include "core.h"
#include <bitmanip.h>
#include <vector>
// MERGED_LOCALLY: #include "types.h"

using namespace vortex;

class LocalMem::Impl {
protected:
	LocalMem* simobject_;
	Config    config_;
	RAM       ram_;
	uint32_t 	line_bits_;
	MemCrossBar::Ptr mem_xbar_;
	mutable PerfStats perf_stats_;

	uint64_t to_local_addr(uint64_t addr) {
		return bit_getw(addr, 0, line_bits_-1);
	}

public:
	Impl(LocalMem* simobject, const Config& config)
		: simobject_(simobject)
		, config_(config)
		, ram_(config.capacity)
	{
		uint32_t total_lines = config.capacity / config.line_size;
		line_bits_ = log2ceil(total_lines);

		char sname[100];
		snprintf(sname, 100, "%s-xbar", simobject->name().c_str());
		uint32_t lg2_line_size = log2ceil(config_.line_size);
		uint32_t num_banks = 1 << config.B;
		mem_xbar_ = MemCrossBar::Create(sname, ArbiterType::Priority, config.num_reqs, num_banks, 1,
		 [lg2_line_size, num_banks](const MemCrossBar::ReqType& req) {
    	// Custom logic to calculate the output index using bank interleaving
			return (uint32_t)((req.addr >> lg2_line_size) & (num_banks-1));
		});
		for (uint32_t i = 0; i < config.num_reqs; ++i) {
			simobject->Inputs.at(i).bind(&mem_xbar_->ReqIn.at(i));
			mem_xbar_->RspIn.at(i).bind(&simobject->Outputs.at(i));
		}
	}

	virtual ~Impl() {}

	void reset() {
		perf_stats_ = PerfStats();
	}

	void read(void* data, uint64_t addr, uint32_t size) {
		auto l_addr = to_local_addr(addr);
		DPH(3, "Local Mem addr=0x" << std::hex << l_addr << std::dec << std::endl);
		ram_.read(data, l_addr, size);
	}

	void write(const void* data, uint64_t addr, uint32_t size) {
		auto l_addr = to_local_addr(addr);
		DPH(3, "Local Mem addr=0x" << std::hex << l_addr << std::dec << std::endl);
		ram_.write(data, l_addr, size);
	}

	void tick() {
		// process bank requets from xbar
		uint32_t num_banks = (1 << config_.B);
		for (uint32_t i = 0; i < num_banks; ++i) {
			auto& xbar_req_out = mem_xbar_->ReqOut.at(i);
			if (xbar_req_out.empty())
				continue;

			auto& bank_req = xbar_req_out.front();
			DT(4, simobject_->name() << "-bank" << i << "-req : " << bank_req);

			if (!bank_req.write || config_.write_reponse) {
				// send xbar response
				MemRsp bank_rsp{bank_req.tag, bank_req.cid, bank_req.uuid};
				mem_xbar_->RspOut.at(i).push(bank_rsp, 1);
			}

			// update perf counters
			perf_stats_.reads += !bank_req.write;
			perf_stats_.writes += bank_req.write;

			// remove input
			xbar_req_out.pop();
		}
	}

	const PerfStats& perf_stats() const {
		perf_stats_.bank_stalls = mem_xbar_->req_collisions();
		return perf_stats_;
	}
};

///////////////////////////////////////////////////////////////////////////////

LocalMem::LocalMem(const SimContext& ctx, const char* name, const Config& config)
	: SimObject<LocalMem>(ctx, name)
	, Inputs(config.num_reqs, this)
	, Outputs(config.num_reqs, this)
	, impl_(new Impl(this, config))
{}

LocalMem::~LocalMem() {
  delete impl_;
}

void LocalMem::reset() {
  impl_->reset();
}

void LocalMem::read(void* data, uint64_t addr, uint32_t size) {
  impl_->read(data, addr, size);
}

void LocalMem::write(const void* data, uint64_t addr, uint32_t size) {
  impl_->write(data, addr, size);
}

void LocalMem::tick() {
  impl_->tick();
}

const LocalMem::PerfStats& LocalMem::perf_stats() const {
  return impl_->perf_stats();
}
// --- End of content from sim/simx/local_mem.cpp ---

// --- Start of content from sim/simx/main.cpp ---
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#include <iostream>
#include <iomanip>
#include <string>
#include <sstream>
#include <fstream>
#include <stdlib.h>
#include <unistd.h>
#include <sys/stat.h>
// MERGED_LOCALLY: #include "processor.h"
// MERGED_LOCALLY: #include "mem.h"
// MERGED_LOCALLY: #include "constants.h"
#include <util.h>
// MERGED_LOCALLY: #include "core.h"
// MERGED_LOCALLY: #include "VX_types.h"

using namespace vortex;

static void show_usage() {
   std::cout << "Usage: [-c <cores>] [-w <warps>] [-t <threads>] [-v: vector-test] [-s: stats] [-h: help] <program>" << std::endl;
}

uint32_t num_threads = NUM_THREADS;
uint32_t num_warps = NUM_WARPS;
uint32_t num_cores = NUM_CORES;
bool showStats = false;
bool vector_test = false;
const char* program = nullptr;

static void parse_args(int argc, char **argv) {
  	int c;
  	while ((c = getopt(argc, argv, "t:w:c:vsh")) != -1) {
    	switch (c) {
      case 't':
        num_threads = atoi(optarg);
        break;
      case 'w':
        num_warps = atoi(optarg);
        break;
		  case 'c':
        num_cores = atoi(optarg);
        break;
      case 'v':
        vector_test = true;
        break;
      case 's':
        showStats = true;
        break;
    	case 'h':
      	show_usage();
      	exit(0);
    		break;
    	default:
      	show_usage();
      	exit(-1);
    	}
	}

	if (optind < argc) {
		program = argv[optind];
    std::cout << "Running " << program << "..." << std::endl;
	} else {
		show_usage();
    exit(-1);
	}
}

int main(int argc, char **argv) {
  int exitcode = 0;

  parse_args(argc, argv);

  {
    // create processor configuation
    Arch arch(num_threads, num_warps, num_cores);

    // create memory module
    RAM ram(0, MEM_PAGE_SIZE);

    // create processor
    Processor processor(arch);

    // attach memory module
    processor.attach_ram(&ram);

	  // setup base DCRs
    const uint64_t startup_addr(STARTUP_ADDR);
    processor.dcr_write(VX_DCR_BASE_STARTUP_ADDR0, startup_addr & 0xffffffff);
  #if (XLEN == 64)
    processor.dcr_write(VX_DCR_BASE_STARTUP_ADDR1, startup_addr >> 32);
  #endif
	  processor.dcr_write(VX_DCR_BASE_MPM_CLASS, 0);

    // load program
    {
      std::string program_ext(fileExtension(program));
      if (program_ext == "bin") {
        ram.loadBinImage(program, startup_addr);
      } else if (program_ext == "hex") {
        ram.loadHexImage(program);
      } else {
        std::cout << "*** error: only *.bin or *.hex images supported." << std::endl;
        return -1;
      }
    }
#ifndef NDEBUG
    std::cout << "[VXDRV] START: program=" << program << std::endl;
#endif
    // run simulation
    // vector test exitcode is a special case
  #ifdef EXT_V_ENABLE
    if (vector_test) return processor.run();
  #endif
    // else continue as normal
    processor.run();

    // read exitcode from @MPM.1
    ram.read(&exitcode, (IO_MPM_ADDR + 8), 4);
  }

  return exitcode;
}
// --- End of content from sim/simx/main.cpp ---

// --- Start of content from sim/simx/mem_coalescer.cpp ---
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// MERGED_LOCALLY: #include "mem_coalescer.h"

using namespace vortex;

MemCoalescer::MemCoalescer(
  const SimContext& ctx,
  const char* name,
  uint32_t input_size,
  uint32_t output_size,
  uint32_t line_size,
  uint32_t queue_size,
  uint32_t delay
) : SimObject<MemCoalescer>(ctx, name)
  , ReqIn(this)
  , RspIn(this)
  , ReqOut(this)
  , RspOut(this)
  , input_size_(input_size)
  , output_size_(output_size)
  , output_ratio_(input_size / output_size)
  , pending_rd_reqs_(queue_size)
  , sent_mask_(input_size)
  , line_size_(line_size)
  , delay_(delay)
{}

void MemCoalescer::reset() {
  sent_mask_.reset();
}

void MemCoalescer::tick() {
  // process outgoing responses
  if (!RspOut.empty()) {
    auto& out_rsp = RspOut.front();
    DT(4, this->name() << "-mem-rsp: " << out_rsp);
    auto& entry = pending_rd_reqs_.at(out_rsp.tag);

    BitVector<> rsp_mask(input_size_);
    for (uint32_t o = 0; o < output_size_; ++o) {
      if (!out_rsp.mask.test(o))
        continue;
      for (uint32_t r = 0; r < output_ratio_; ++r) {
        uint32_t i = o * output_ratio_ + r;
        if (entry.mask.test(i))
          rsp_mask.set(i);
      }
    }

    // build memory response
    LsuRsp in_rsp(input_size_);
    in_rsp.mask = rsp_mask;
    in_rsp.tag = entry.tag;
    in_rsp.cid = out_rsp.cid;
    in_rsp.uuid = out_rsp.uuid;

    // send memory response
    RspIn.push(in_rsp, 1);

    // track remaining responses
    assert(!entry.mask.none());
		entry.mask &= ~rsp_mask;
		if (entry.mask.none()) {
      // whole response received, release tag
			pending_rd_reqs_.release(out_rsp.tag);
		}
    RspOut.pop();
  }

  // process incoming requests
  if (ReqIn.empty())
    return;

  auto& in_req = ReqIn.front();
  assert(in_req.mask.size() == input_size_);
  assert(!in_req.mask.none());

  // ensure we can allocate a response tag
  if (pending_rd_reqs_.full()) {
    DT(4, "*** " << this->name() << "-queue-full: " << in_req);
    return;
  }

  uint64_t addr_mask = ~uint64_t(line_size_-1);

  BitVector<> out_mask(output_size_);
  std::vector<uint64_t> out_addrs(output_size_);

  BitVector<> cur_mask(input_size_);

  for (uint32_t o = 0; o < output_size_; ++o) {
    for (uint32_t r = 0; r < output_ratio_; ++r) {
      uint32_t i = o * output_ratio_ + r;
      if (sent_mask_.test(i) || !in_req.mask.test(i))
        continue;

      uint64_t seed_addr = in_req.addrs.at(i) & addr_mask;
      cur_mask.set(i);

      // coalesce matching requests
      for (uint32_t s = r + 1; s < output_ratio_; ++s) {
        uint32_t j = o * output_ratio_ + s;
        if (sent_mask_.test(j) || !in_req.mask.test(j))
          continue;
        uint64_t match_addr = in_req.addrs.at(j) & addr_mask;
        if (match_addr == seed_addr) {
          cur_mask.set(j);
        }
      }

      out_mask.set(o);
      out_addrs.at(o) = seed_addr;
      break;
    }
  }

  assert(!out_mask.none());

  uint32_t tag = 0;
  if (!in_req.write) {
    // allocate a response tag for read requests
    tag = pending_rd_reqs_.allocate(pending_req_t{in_req.tag, cur_mask});
  }

  // build memory request
  LsuReq out_req{output_size_};
  out_req.mask = out_mask;
  out_req.tag = tag;
  out_req.write = in_req.write;
  out_req.addrs = out_addrs;
  out_req.cid = in_req.cid;
  out_req.uuid = in_req.uuid;

  // send memory request
  ReqOut.push(out_req, delay_);
  DT(4, this->name() << "-mem-req: coalesced=" << cur_mask.count() << ", " << out_req);

  // track partial responses
  perf_stats_.misses += (cur_mask.count() != in_req.mask.count());

  // update sent mask
  sent_mask_ |= cur_mask;
  if (sent_mask_ == in_req.mask) {
    ReqIn.pop();
    sent_mask_.reset();
  }
}

const MemCoalescer::PerfStats& MemCoalescer::perf_stats() const {
  return perf_stats_;
}
// --- End of content from sim/simx/mem_coalescer.cpp ---

// --- Start of content from sim/simx/mem_sim.cpp ---
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// MERGED_LOCALLY: #include "mem_sim.h"
#include <vector>
#include <queue>
#include <stdlib.h>
#include <dram_sim.h>

// MERGED_LOCALLY: #include "constants.h"
// MERGED_LOCALLY: #include "types.h"
// MERGED_LOCALLY: #include "debug.h"

using namespace vortex;

class MemSim::Impl {
private:
	MemSim*   simobject_;
	Config    config_;
	MemCrossBar::Ptr mem_xbar_;
	DramSim   dram_sim_;
	mutable PerfStats perf_stats_;
	struct DramCallbackArgs {
		MemSim::Impl* memsim;
		MemReq request;
		uint32_t bank_id;
	};

public:
	Impl(MemSim* simobject, const Config& config)
		: simobject_(simobject)
		, config_(config)
		, dram_sim_(config.num_banks, config.block_size, config.clock_ratio)
	{
		char sname[100];
		snprintf(sname, 100, "%s-xbar", simobject->name().c_str());
		mem_xbar_ = MemCrossBar::Create(sname, ArbiterType::RoundRobin, config.num_ports, config.num_banks, 1,
			[lg2_block_size = log2ceil(config.block_size), num_banks = config.num_banks](const MemCrossBar::ReqType& req) {
    	// Custom logic to calculate the output index using bank interleaving
			return (uint32_t)((req.addr >> lg2_block_size) & (num_banks-1));
		});
		for (uint32_t i = 0; i < config.num_ports; ++i) {
			simobject->MemReqPorts.at(i).bind(&mem_xbar_->ReqIn.at(i));
			mem_xbar_->RspIn.at(i).bind(&simobject->MemRspPorts.at(i));
		}
	}

	~Impl() {
		//--
	}

	const PerfStats& perf_stats() const {
		perf_stats_.bank_stalls = mem_xbar_->req_collisions();
		return perf_stats_;
	}

	void reset() {
		dram_sim_.reset();
	}

	void tick() {
		dram_sim_.tick();

		for (uint32_t i = 0; i < config_.num_banks; ++i) {
			if (mem_xbar_->ReqOut.at(i).empty())
				continue;

			auto& mem_req = mem_xbar_->ReqOut.at(i).front();

			// enqueue the request to the memory system
			auto req_args = new DramCallbackArgs{this, mem_req, i};
			dram_sim_.send_request(
				mem_req.addr,
				mem_req.write,
				[](void* arg) {
					auto rsp_args = reinterpret_cast<const DramCallbackArgs*>(arg);
					if (!rsp_args->request.write) {
						// only send a response for read requests
						MemRsp mem_rsp{rsp_args->request.tag, rsp_args->request.cid, rsp_args->request.uuid};
						rsp_args->memsim->mem_xbar_->RspOut.at(rsp_args->bank_id).push(mem_rsp, 1);
						DT(3, rsp_args->memsim->simobject_->name() << "-mem-rsp[" << rsp_args->bank_id << "]: " << mem_rsp);
					}
					delete rsp_args;
				},
				req_args
			);

			DT(3, simobject_->name() << "-mem-req[" << i << "]: " << mem_req);
			mem_xbar_->ReqOut.at(i).pop();
		}
	}
};

///////////////////////////////////////////////////////////////////////////////

MemSim::MemSim(const SimContext& ctx, const char* name, const Config& config)
	: SimObject<MemSim>(ctx, name)
	, MemReqPorts(config.num_ports, this)
	, MemRspPorts(config.num_ports, this)
	, impl_(new Impl(this, config))
{}

MemSim::~MemSim() {
  delete impl_;
}

void MemSim::reset() {
  impl_->reset();
}

void MemSim::tick() {
  impl_->tick();
}

const MemSim::PerfStats &MemSim::perf_stats() const {
	return impl_->perf_stats();
}
// --- End of content from sim/simx/mem_sim.cpp ---

// --- Start of content from sim/simx/processor.cpp ---
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// MERGED_LOCALLY: #include "processor.h"
// MERGED_LOCALLY: #include "processor_impl.h"

using namespace vortex;

ProcessorImpl::ProcessorImpl(const Arch& arch)
  : arch_(arch)
  , clusters_(arch.num_clusters())
{
  SimPlatform::instance().initialize();

	assert(PLATFORM_MEMORY_DATA_SIZE == MEM_BLOCK_SIZE);

  // create memory simulator
  memsim_ = MemSim::Create("dram", MemSim::Config{
    PLATFORM_MEMORY_NUM_BANKS,
    L3_MEM_PORTS,
    MEM_BLOCK_SIZE,
    MEM_CLOCK_RATIO
  });

  // create clusters
  for (uint32_t i = 0; i < arch.num_clusters(); ++i) {
    clusters_.at(i) = Cluster::Create(i, this, arch, dcrs_);
  }

  // create L3 cache
  l3cache_ = CacheSim::Create("l3cache", CacheSim::Config{
    !L3_ENABLED,
    log2ceil(L3_CACHE_SIZE),  // C
    log2ceil(MEM_BLOCK_SIZE), // L
    log2ceil(L2_LINE_SIZE),   // W
    log2ceil(L3_NUM_WAYS),    // A
    log2ceil(L3_NUM_BANKS),   // B
    XLEN,                     // address bits
    1,                        // number of ports
    L3_NUM_REQS,              // request size
    L3_MEM_PORTS,             // memory ports
    L3_WRITEBACK,             // write-back
    false,                    // write response
    L3_MSHR_SIZE,             // mshr size
    2,                        // pipeline latency
    }
  );

  // connect L3 core interfaces
  for (uint32_t i = 0; i < arch.num_clusters(); ++i) {
    for (uint32_t j = 0; j < L2_MEM_PORTS; ++j) {
      clusters_.at(i)->mem_req_ports.at(j).bind(&l3cache_->CoreReqPorts.at(i * L2_MEM_PORTS + j));
      l3cache_->CoreRspPorts.at(i * L2_MEM_PORTS + j).bind(&clusters_.at(i)->mem_rsp_ports.at(j));
    }
  }

  // connect L3 memory interfaces
  for (uint32_t i = 0; i < L3_MEM_PORTS; ++i) {
    l3cache_->MemReqPorts.at(i).bind(&memsim_->MemReqPorts.at(i));
    memsim_->MemRspPorts.at(i).bind(&l3cache_->MemRspPorts.at(i));
  }

  // set up memory profiling
  for (uint32_t i = 0; i < L3_MEM_PORTS; ++i) {
    memsim_->MemReqPorts.at(i).tx_callback([&](const MemReq& req, uint64_t cycle){
      __unused (cycle);
      perf_mem_reads_  += !req.write;
      perf_mem_writes_ += req.write;
      perf_mem_pending_reads_ += !req.write;
    });
    memsim_->MemRspPorts.at(i).tx_callback([&](const MemRsp&, uint64_t cycle){
      __unused (cycle);
      --perf_mem_pending_reads_;
    });
  }

#ifndef NDEBUG
  // dump device configuration
  std::cout << "CONFIGS:"
            << " num_threads=" << arch.num_threads()
            << ", num_warps=" << arch.num_warps()
            << ", num_cores=" << arch.num_cores()
            << ", num_clusters=" << arch.num_clusters()
            << ", socket_size=" << arch.socket_size()
            << ", local_mem_base=0x" << std::hex << arch.local_mem_base() << std::dec
            << ", num_barriers=" << arch.num_barriers()
            << std::endl;
#endif
  // reset the device
  this->reset();
}

ProcessorImpl::~ProcessorImpl() {
  SimPlatform::instance().finalize();
}

void ProcessorImpl::attach_ram(RAM* ram) {
  for (auto cluster : clusters_) {
    cluster->attach_ram(ram);
  }
}
#ifdef VM_ENABLE
void ProcessorImpl::set_satp(uint64_t satp) {
  for (auto cluster : clusters_) {
    cluster->set_satp(satp);
  }
}
#endif

int ProcessorImpl::run() {
  SimPlatform::instance().reset();
  this->reset();

  bool done;
  int exitcode = 0;
  do {
    SimPlatform::instance().tick();
    done = true;
    for (auto cluster : clusters_) {
      if (cluster->running()) {
        done = false;
        continue;
      }
    #ifdef EXT_V_ENABLE
      exitcode |= cluster->get_exitcode();
    #endif
    }
    perf_mem_latency_ += perf_mem_pending_reads_;
  } while (!done);

  return exitcode;
}

void ProcessorImpl::reset() {
  perf_mem_reads_ = 0;
  perf_mem_writes_ = 0;
  perf_mem_latency_ = 0;
  perf_mem_pending_reads_ = 0;
}

void ProcessorImpl::dcr_write(uint32_t addr, uint32_t value) {
  dcrs_.write(addr, value);
}

ProcessorImpl::PerfStats ProcessorImpl::perf_stats() const {
  ProcessorImpl::PerfStats perf;
  perf.mem_reads   = perf_mem_reads_;
  perf.mem_writes  = perf_mem_writes_;
  perf.mem_latency = perf_mem_latency_;
  perf.l3cache     = l3cache_->perf_stats();
  perf.memsim      = memsim_->perf_stats();
  return perf;
}

///////////////////////////////////////////////////////////////////////////////

Processor::Processor(const Arch& arch)
  : impl_(new ProcessorImpl(arch))
{
#ifdef VM_ENABLE
  satp_ = NULL;
#endif
}

Processor::~Processor() {
  delete impl_;
#ifdef VM_ENABLE
  if (satp_ != NULL)
    delete satp_;
#endif
}

void Processor::attach_ram(RAM* mem) {
  impl_->attach_ram(mem);
}

int Processor::run() {
  return impl_->run();
}

void Processor::dcr_write(uint32_t addr, uint32_t value) {
  return impl_->dcr_write(addr, value);
}

#ifdef VM_ENABLE
int16_t Processor::set_satp_by_addr(uint64_t base_addr) {
  uint16_t asid = 0;
  satp_ = new SATP_t (base_addr,asid);
  if (satp_ == NULL)
    return 1;
  uint64_t satp = satp_->get_satp();
  impl_->set_satp(satp);
  return 0;
}
bool Processor::is_satp_unset() {
  return (satp_== NULL);
}
uint8_t Processor::get_satp_mode() {
  assert (satp_!=NULL);
  return satp_->get_mode();
}
uint64_t Processor::get_base_ppn() {
  assert (satp_!=NULL);
  return satp_->get_base_ppn();
}
#endif
// --- End of content from sim/simx/processor.cpp ---

// --- Start of content from sim/simx/socket.cpp ---
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// MERGED_LOCALLY: #include "socket.h"
// MERGED_LOCALLY: #include "cluster.h"

using namespace vortex;

Socket::Socket(const SimContext& ctx,
                uint32_t socket_id,
                Cluster* cluster,
                const Arch &arch,
                const DCRS &dcrs)
  : SimObject(ctx, StrFormat("socket%d", socket_id))
  , mem_req_ports(L1_MEM_PORTS, this)
  , mem_rsp_ports(L1_MEM_PORTS, this)
  , socket_id_(socket_id)
  , cluster_(cluster)
  , cores_(arch.socket_size())
{
  auto cores_per_socket = cores_.size();

  char sname[100];
  snprintf(sname, 100, "%s-icaches", this->name().c_str());
  icaches_ = CacheCluster::Create(sname, cores_per_socket, NUM_ICACHES, CacheSim::Config{
    !ICACHE_ENABLED,
    log2ceil(ICACHE_SIZE),  // C
    log2ceil(L1_LINE_SIZE), // L
    log2ceil(sizeof(uint32_t)), // W
    log2ceil(ICACHE_NUM_WAYS),// A
    1,                      // B
    XLEN,                   // address bits
    1,                      // number of ports
    1,                      // number of inputs
    ICACHE_MEM_PORTS,       // memory ports
    false,                  // write-back
    false,                  // write response
    (uint8_t)arch.num_warps(), // mshr size
    2,                      // pipeline latency
  });

  snprintf(sname, 100, "%s-dcaches", this->name().c_str());
  dcaches_ = CacheCluster::Create(sname, cores_per_socket, NUM_DCACHES, CacheSim::Config{
    !DCACHE_ENABLED,
    log2ceil(DCACHE_SIZE),  // C
    log2ceil(L1_LINE_SIZE), // L
    log2ceil(DCACHE_WORD_SIZE), // W
    log2ceil(DCACHE_NUM_WAYS),// A
    log2ceil(DCACHE_NUM_BANKS), // B
    XLEN,                   // address bits
    1,                      // number of ports
    DCACHE_NUM_REQS,        // number of inputs
    L1_MEM_PORTS,           // memory ports
    DCACHE_WRITEBACK,       // write-back
    false,                  // write response
    DCACHE_MSHR_SIZE,       // mshr size
    2,                      // pipeline latency
  });

  // find overlap
  uint32_t overlap = MIN(ICACHE_MEM_PORTS, L1_MEM_PORTS);

  // connect l1 caches to outgoing memory interfaces
  for (uint32_t i = 0; i < L1_MEM_PORTS; ++i) {
    snprintf(sname, 100, "%s-l1_arb%d", this->name().c_str(), i);
    auto l1_arb = MemArbiter::Create(sname, ArbiterType::RoundRobin, 2 * overlap, overlap);

    if (i < overlap) {
      icaches_->MemReqPorts.at(i).bind(&l1_arb->ReqIn.at(i));
      l1_arb->RspIn.at(i).bind(&icaches_->MemRspPorts.at(i));

      dcaches_->MemReqPorts.at(i).bind(&l1_arb->ReqIn.at(overlap + i));
      l1_arb->RspIn.at(overlap + i).bind(&dcaches_->MemRspPorts.at(i));

      l1_arb->ReqOut.at(i).bind(&this->mem_req_ports.at(i));
      this->mem_rsp_ports.at(i).bind(&l1_arb->RspOut.at(i));
    } else {
      if (L1_MEM_PORTS > ICACHE_MEM_PORTS) {
        // if more dcache ports
        dcaches_->MemReqPorts.at(i).bind(&this->mem_req_ports.at(i));
        this->mem_rsp_ports.at(i).bind(&dcaches_->MemRspPorts.at(i));
      } else {
        // if more icache ports
        icaches_->MemReqPorts.at(i).bind(&this->mem_req_ports.at(i));
        this->mem_rsp_ports.at(i).bind(&icaches_->MemRspPorts.at(i));
      }
    }
  }

  // create cores
  for (uint32_t i = 0; i < cores_per_socket; ++i) {
    uint32_t core_id = socket_id * cores_per_socket + i;
    cores_.at(i) = Core::Create(core_id, this, arch, dcrs);
  }

  // connect cores to caches
  for (uint32_t i = 0; i < cores_per_socket; ++i) {
    cores_.at(i)->icache_req_ports.at(0).bind(&icaches_->CoreReqPorts.at(i).at(0));
    icaches_->CoreRspPorts.at(i).at(0).bind(&cores_.at(i)->icache_rsp_ports.at(0));

    for (uint32_t j = 0; j < DCACHE_NUM_REQS; ++j) {
      cores_.at(i)->dcache_req_ports.at(j).bind(&dcaches_->CoreReqPorts.at(i).at(j));
      dcaches_->CoreRspPorts.at(i).at(j).bind(&cores_.at(i)->dcache_rsp_ports.at(j));
    }
  }
}

Socket::~Socket() {
  //--
}

void Socket::reset() {
  //--
}

void Socket::tick() {
  //--
}

void Socket::attach_ram(RAM* ram) {
  for (auto core : cores_) {
    core->attach_ram(ram);
  }
}

#ifdef VM_ENABLE
void Socket::set_satp(uint64_t satp) {
  for (auto core : cores_) {
    core->set_satp(satp);
  }
}
#endif

bool Socket::running() const {
  for (auto& core : cores_) {
    if (core->running())
      return true;
  }
  return false;
}

int Socket::get_exitcode() const {
  int exitcode = 0;
  for (auto& core : cores_) {
    exitcode |= core->get_exitcode();
  }
  return exitcode;
}

void Socket::barrier(uint32_t bar_id, uint32_t count, uint32_t core_id) {
  cluster_->barrier(bar_id, count, socket_id_ * cores_.size() + core_id);
}

void Socket::resume(uint32_t core_index) {
  cores_.at(core_index)->resume(-1);
}

Socket::PerfStats Socket::perf_stats() const {
  PerfStats perf_stats;
  perf_stats.icache = icaches_->perf_stats();
  perf_stats.dcache = dcaches_->perf_stats();
  return perf_stats;
}
// --- End of content from sim/simx/socket.cpp ---

// --- Start of content from sim/simx/types.cpp ---
// Copyright © 2019-2023
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
// http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// MERGED_LOCALLY: #include "types.h"

using namespace vortex;

LocalMemSwitch::LocalMemSwitch(
  const SimContext& ctx,
  const char* name,
  uint32_t delay
) : SimObject<LocalMemSwitch>(ctx, name)
  , ReqIn(this)
  , RspIn(this)
  , ReqLmem(this)
  , RspLmem(this)
  , ReqDC(this)
  , RspDC(this)
  , delay_(delay)
{}

void LocalMemSwitch::reset() {}

void LocalMemSwitch::tick() {
  // process outgoing responses
  if (!RspLmem.empty()) {
    auto& out_rsp = RspLmem.front();
    DT(4, this->name() << "-lmem-rsp: " << out_rsp);
    RspIn.push(out_rsp, 1);
    RspLmem.pop();
  }
  if (!RspDC.empty()) {
    auto& out_rsp = RspDC.front();
    DT(4, this->name() << "-dc-rsp: " << out_rsp);
    RspIn.push(out_rsp, 1);
    RspDC.pop();
  }

  // process incoming requests
  if (!ReqIn.empty()) {
    auto& in_req = ReqIn.front();

    LsuReq out_dc_req(in_req.mask.size());
    out_dc_req.write = in_req.write;
    out_dc_req.tag   = in_req.tag;
    out_dc_req.cid   = in_req.cid;
    out_dc_req.uuid  = in_req.uuid;

    LsuReq out_lmem_req(out_dc_req);

    for (uint32_t i = 0; i < in_req.mask.size(); ++i) {
      if (in_req.mask.test(i)) {
        auto type = get_addr_type(in_req.addrs.at(i));
        if (type == AddrType::Shared) {
          out_lmem_req.mask.set(i);
          out_lmem_req.addrs.at(i) = in_req.addrs.at(i);
        } else {
          out_dc_req.mask.set(i);
          out_dc_req.addrs.at(i) = in_req.addrs.at(i);
        }
      }
    }

    if (!out_dc_req.mask.none()) {
      ReqDC.push(out_dc_req, delay_);
      DT(4, this->name() << "-dc-req: " << out_dc_req);
    }

    if (!out_lmem_req.mask.none()) {
      ReqLmem.push(out_lmem_req, delay_);
      DT(4, this->name() << "-lmem-req: " << out_lmem_req);
    }
    ReqIn.pop();
  }
}

///////////////////////////////////////////////////////////////////////////////

LsuMemAdapter::LsuMemAdapter(
  const SimContext& ctx,
  const char* name,
  uint32_t num_inputs,
  uint32_t delay
) : SimObject<LsuMemAdapter>(ctx, name)
  , ReqIn(this)
  , RspIn(this)
  , ReqOut(num_inputs, this)
  , RspOut(num_inputs, this)
  , delay_(delay)
{}

void LsuMemAdapter::reset() {}

void LsuMemAdapter::tick() {
  uint32_t input_size = ReqOut.size();

  // process outgoing responses
  for (uint32_t i = 0; i < input_size; ++i) {
    if (RspOut.at(i).empty())
      continue;
    auto& out_rsp = RspOut.at(i).front();
    DT(4, this->name() << "-rsp" << i << ": " << out_rsp);

    // build memory response
    LsuRsp in_rsp(input_size);
    in_rsp.mask.set(i);
    in_rsp.tag = out_rsp.tag;
    in_rsp.cid = out_rsp.cid;
    in_rsp.uuid = out_rsp.uuid;

    // include other responses with the same tag
    for (uint32_t j = i + 1; j < input_size; ++j) {
      if (RspOut.at(j).empty())
        continue;
      auto& other_rsp = RspOut.at(j).front();
      if (out_rsp.tag == other_rsp.tag) {
        in_rsp.mask.set(j);
        RspOut.at(j).pop();
      }
    }

    // send memory response
    RspIn.push(in_rsp, 1);

    // remove input
    RspOut.at(i).pop();
    break;
  }

  // process incoming requests
  if (!ReqIn.empty()) {
    auto& in_req = ReqIn.front();
    assert(in_req.mask.size() == input_size);
    for (uint32_t i = 0; i < input_size; ++i) {
      if (in_req.mask.test(i)) {
        // build memory request
        MemReq out_req;
        out_req.write = in_req.write;
        out_req.addr  = in_req.addrs.at(i);
        out_req.type  = get_addr_type(in_req.addrs.at(i));
        out_req.tag   = in_req.tag;
        out_req.cid   = in_req.cid;
        out_req.uuid  = in_req.uuid;
        // send memory request
        ReqOut.at(i).push(out_req, delay_);
        DT(4, this->name() << "-req" << i << ": " << out_req);
      }
    }
    ReqIn.pop();
  }
}
// --- End of content from sim/simx/types.cpp ---

// --- Start of content from sim/simx/vpu.cpp ---
// This is a fork of https://github.com/troibe/vortex/tree/simx-v2-vector
// The purpose of this fork is to make simx-v2-vector up to date with master
// Thanks to Troibe for his amazing work

#ifdef EXT_V_ENABLE
// MERGED_LOCALLY: #include "emulator.h"
// MERGED_LOCALLY: #include "instr.h"
// MERGED_LOCALLY: #include "processor_impl.h"
#include <iostream>
#include <limits>
#include <math.h>
#include <rvfloats.h>
#include <stdlib.h>
// MERGED_LOCALLY: #include "vpu.h"

using namespace vortex;

void Emulator::loadVector(const Instr &instr, uint32_t wid, std::vector<reg_data_t[3]> &rsdata) {
  auto &warp = warps_.at(wid);
  auto vmask = instr.getVmask();
  auto rdest = instr.getRDest();
  auto mop = instr.getVmop();
  switch (mop) {
  case 0b00: { // unit-stride
    auto lumop = instr.getVumop();
    switch (lumop) {
    case 0b10000:  // vle8ff.v, vle16ff.v, vle32ff.v, vle64ff.v - we do not support exceptions -> treat like regular unit stride
                   // vlseg2e8ff.v, vlseg2e16ff.v, vlseg2e32ff.v, vlseg2e64ff.v
                   // vlseg3e8ff.v, vlseg3e16ff.v, vlseg3e32ff.v, vlseg3e64ff.v
                   // vlseg4e8ff.v, vlseg4e16ff.v, vlseg4e32ff.v, vlseg4e64ff.v
                   // vlseg5e8ff.v, vlseg5e16ff.v, vlseg5e32ff.v, vlseg5e64ff.v
                   // vlseg6e8ff.v, vlseg6e16ff.v, vlseg6e32ff.v, vlseg6e64ff.v
                   // vlseg7e8ff.v, vlseg7e16ff.v, vlseg7e32ff.v, vlseg7e64ff.v
                   // vlseg8e8ff.v, vlseg8e16ff.v, vlseg8e32ff.v, vlseg8e64ff.v
    case 0b0000: { // vle8.v, vle16.v, vle32.v, vle64.v
                   // vlseg2e8.v, vlseg2e16.v, vlseg2e32.v, vlseg2e64.v
                   // vlseg3e8.v, vlseg3e16.v, vlseg3e32.v, vlseg3e64.v
                   // vlseg4e8.v, vlseg4e16.v, vlseg4e32.v, vlseg4e64.v
                   // vlseg5e8.v, vlseg5e16.v, vlseg5e32.v, vlseg5e64.v
                   // vlseg6e8.v, vlseg6e16.v, vlseg6e32.v, vlseg6e64.v
                   // vlseg7e8.v, vlseg7e16.v, vlseg7e32.v, vlseg7e64.v
                   // vlseg8e8.v, vlseg8e16.v, vlseg8e32.v, vlseg8e64.v
      WordI stride = warp.vtype.vsew / 8;
      uint32_t nfields = instr.getVnf() + 1;
      vector_op_vix_load(warp.vreg_file, this, rsdata[0][0].i, rdest, warp.vtype.vsew, warp.vl, false, stride, nfields, warp.vtype.vlmul, vmask);
      break;
    }
    case 0b1000: { // vl1r.v, vl2r.v, vl4r.v, vl8r.v
      uint32_t nreg = instr.getVnf() + 1;
      if (nreg != 1 && nreg != 2 && nreg != 4 && nreg != 8) {
        std::cout << "Whole vector register load - reserved value for nreg: " << nreg << std::endl;
        std::abort();
      }
      DP(4, "Whole vector register load with nreg: " << nreg);
      uint32_t stride = 1 << instr.getVsew();
      uint32_t vsew_bits = stride * 8;
      uint32_t vl = nreg * VLEN / vsew_bits;
      vector_op_vix_load(warp.vreg_file, this, rsdata[0][0].i, rdest, vsew_bits, vl, false, stride, 1, 0, vmask);
      break;
    }
    case 0b1011: { // vlm.v
      if (warp.vtype.vsew != 8) {
        std::cout << "vlm.v only supports SEW=8, but SEW was: " << warp.vtype.vsew << std::endl;
        std::abort();
      }
      WordI stride = warp.vtype.vsew / 8;
      vector_op_vix_load(warp.vreg_file, this, rsdata[0][0].i, rdest, warp.vtype.vsew, (warp.vl + 7) / 8, false, stride, 1, 0, true);
      break;
    }
    default:
      std::cout << "Load vector - unsupported lumop: " << lumop << std::endl;
      std::abort();
    }
    break;
  }
  case 0b10: { // strided: vlse8.v, vlse16.v, vlse32.v, vlse64.v
               // vlsseg2e8.v, vlsseg2e16.v, vlsseg2e32.v, vlsseg2e64.v
               // vlsseg3e8.v, vlsseg3e16.v, vlsseg3e32.v, vlsseg3e64.v
               // vlsseg4e8.v, vlsseg4e16.v, vlsseg4e32.v, vlsseg4e64.v
               // vlsseg5e8.v, vlsseg5e16.v, vlsseg5e32.v, vlsseg5e64.v
               // vlsseg6e8.v, vlsseg6e16.v, vlsseg6e32.v, vlsseg6e64.v
               // vlsseg7e8.v, vlsseg7e16.v, vlsseg7e32.v, vlsseg7e64.v
               // vlsseg8e8.v, vlsseg8e16.v, vlsseg8e32.v, vlsseg8e64.v
    auto rsrc1 = instr.getRSrc(1);
    auto rdest = instr.getRDest();
    WordI stride = warp.ireg_file.at(0).at(rsrc1);
    uint32_t nfields = instr.getVnf() + 1;
    vector_op_vix_load(warp.vreg_file, this, rsdata[0][0].i, rdest, warp.vtype.vsew, warp.vl, true, stride, nfields, warp.vtype.vlmul, vmask);
    break;
  }
  case 0b01:   // indexed - unordered, vluxei8.v, vluxei16.v, vluxei32.v, vluxei64.v
               // vluxseg2e8.v, vluxseg2e16.v, vluxseg2e32.v, vluxseg2e64.v
               // vluxseg3e8.v, vluxseg3e16.v, vluxseg3e32.v, vluxseg3e64.v
               // vluxseg4e8.v, vluxseg4e16.v, vluxseg4e32.v, vluxseg4e64.v
               // vluxseg5e8.v, vluxseg5e16.v, vluxseg5e32.v, vluxseg5e64.v
               // vluxseg6e8.v, vluxseg6e16.v, vluxseg6e32.v, vluxseg6e64.v
               // vluxseg7e8.v, vluxseg7e16.v, vluxseg7e32.v, vluxseg7e64.v
               // vluxseg8e8.v, vluxseg8e16.v, vluxseg8e32.v, vluxseg8e64.v
  case 0b11: { // indexed - ordered, vloxei8.v, vloxei16.v, vloxei32.v, vloxei64.v
               // vloxseg2e8.v, vloxseg2e16.v, vloxseg2e32.v, vloxseg2e64.v
               // vloxseg3e8.v, vloxseg3e16.v, vloxseg3e32.v, vloxseg3e64.v
               // vloxseg4e8.v, vloxseg4e16.v, vloxseg4e32.v, vloxseg4e64.v
               // vloxseg5e8.v, vloxseg5e16.v, vloxseg5e32.v, vloxseg5e64.v
               // vloxseg6e8.v, vloxseg6e16.v, vloxseg6e32.v, vloxseg6e64.v
               // vloxseg7e8.v, vloxseg7e16.v, vloxseg7e32.v, vloxseg7e64.v
               // vloxseg8e8.v, vloxseg8e16.v, vloxseg8e32.v, vloxseg8e64.v
    uint32_t nfields = instr.getVnf() + 1;
    uint32_t vsew_bits = 1 << (3 + instr.getVsew());
    vector_op_vv_load(warp.vreg_file, this, rsdata[0][0].i, instr.getRSrc(1), rdest, warp.vtype.vsew, vsew_bits, warp.vl, nfields, warp.vtype.vlmul, vmask);
    break;
  }
  default:
    std::cout << "Load vector - unsupported mop: " << mop << std::endl;
    std::abort();
  }
}

void Emulator::storeVector(const Instr &instr, uint32_t wid, std::vector<reg_data_t[3]> &rsdata) {
  auto &warp = warps_.at(wid);
  auto vmask = instr.getVmask();
  auto mop = instr.getVmop();
  switch (mop) {
  case 0b00: { // unit-stride
    auto vs3 = instr.getRSrc(1);
    auto sumop = instr.getVumop();
    WordI stride = warp.vtype.vsew / 8;
    switch (sumop) {
    case 0b0000: { // vse8.v, vse16.v, vse32.v, vse64.v
      uint32_t nfields = instr.getVnf() + 1;
      vector_op_vix_store(warp.vreg_file, this, rsdata[0][0].i, vs3, warp.vtype.vsew, warp.vl, false, stride, nfields, warp.vtype.vlmul, vmask);
      break;
    }
    case 0b1000: { // vs1r.v, vs2r.v, vs4r.v, vs8r.v
      uint32_t nreg = instr.getVnf() + 1;
      if (nreg != 1 && nreg != 2 && nreg != 4 && nreg != 8) {
        std::cout << "Whole vector register store - reserved value for nreg: " << nreg << std::endl;
        std::abort();
      }
      DP(4, "Whole vector register store with nreg: " << nreg);
      uint32_t vl = nreg * VLEN / 8;
      vector_op_vix_store<uint8_t>(warp.vreg_file, this, rsdata[0][0].i, vs3, vl, false, stride, 1, 0, vmask);
      break;
    }
    case 0b1011: { // vsm.v
      if (warp.vtype.vsew != 8) {
        std::cout << "vsm.v only supports EEW=8, but EEW was: " << warp.vtype.vsew << std::endl;
        std::abort();
      }
      vector_op_vix_store(warp.vreg_file, this, rsdata[0][0].i, vs3, warp.vtype.vsew, (warp.vl + 7) / 8, false, stride, 1, 0, true);
      break;
    }
    default:
      std::cout << "Store vector - unsupported sumop: " << sumop << std::endl;
      std::abort();
    }
    break;
  }
  case 0b10: { // strided: vsse8.v, vsse16.v, vsse32.v, vsse64.v
               // vssseg2e8.v, vssseg2e16.v, vssseg2e32.v, vssseg2e64.v
               // vssseg3e8.v, vssseg3e16.v, vssseg3e32.v, vssseg3e64.v
               // vssseg4e8.v, vssseg4e16.v, vssseg4e32.v, vssseg4e64.v
               // vssseg5e8.v, vssseg5e16.v, vssseg5e32.v, vssseg5e64.v
               // vssseg6e8.v, vssseg6e16.v, vssseg6e32.v, vssseg6e64.v
               // vssseg7e8.v, vssseg7e16.v, vssseg7e32.v, vssseg7e64.v
               // vssseg8e8.v, vssseg8e16.v, vssseg8e32.v, vssseg8e64.v
    auto rsrc1 = instr.getRSrc(1);
    auto vs3 = instr.getRSrc(2);
    WordI stride = warp.ireg_file.at(0).at(rsrc1);
    uint32_t nfields = instr.getVnf() + 1;
    vector_op_vix_store(warp.vreg_file, this, rsdata[0][0].i, vs3, warp.vtype.vsew, warp.vl, true, stride, nfields, warp.vtype.vlmul, vmask);
    break;
  }
  case 0b01:   // indexed - unordered, vsuxei8.v, vsuxei16.v, vsuxei32.v, vsuxei64.v
               // vsuxseg2ei8.v, vsuxseg2ei16.v, vsuxseg2ei32.v, vsuxseg2ei64.v
               // vsuxseg3ei8.v, vsuxseg3ei16.v, vsuxseg3ei32.v, vsuxseg3ei64.v
               // vsuxseg4ei8.v, vsuxseg4ei16.v, vsuxseg4ei32.v, vsuxseg4ei64.v
               // vsuxseg5ei8.v, vsuxseg5ei16.v, vsuxseg5ei32.v, vsuxseg5ei64.v
               // vsuxseg6ei8.v, vsuxseg6ei16.v, vsuxseg6ei32.v, vsuxseg6ei64.v
               // vsuxseg7ei8.v, vsuxseg7ei16.v, vsuxseg7ei32.v, vsuxseg7ei64.v
               // vsuxseg8ei8.v, vsuxseg8ei16.v, vsuxseg8ei32.v, vsuxseg8ei64.v
  case 0b11: { // indexed - ordered, vsoxei8.v, vsoxei16.v, vsoxei32.v, vsoxei64.v
               // vsoxseg2ei8.v, vsoxseg2ei16.v, vsoxseg2ei32.v, vsoxseg2ei64.v
               // vsoxseg3ei8.v, vsoxseg3ei16.v, vsoxseg3ei32.v, vsoxseg3ei64.v
               // vsoxseg4ei8.v, vsoxseg4ei16.v, vsoxseg4ei32.v, vsoxseg4ei64.v
               // vsoxseg5ei8.v, vsoxseg5ei16.v, vsoxseg5ei32.v, vsoxseg5ei64.v
               // vsoxseg6ei8.v, vsoxseg6ei16.v, vsoxseg6ei32.v, vsoxseg6ei64.v
               // vsoxseg7ei8.v, vsoxseg7ei16.v, vsoxseg7ei32.v, vsoxseg7ei64.v
               // vsoxseg8ei8.v, vsoxseg8ei16.v, vsoxseg8ei32.v, vsoxseg8ei64.v
    uint32_t nfields = instr.getVnf() + 1;
    uint32_t vsew_bits = 1 << (3 + instr.getVsew());
    vector_op_vv_store(warp.vreg_file, this, rsdata[0][0].i, instr.getRSrc(1), instr.getRSrc(2), warp.vtype.vsew, vsew_bits, warp.vl, nfields, warp.vtype.vlmul, vmask);
    break;
  }
  default:
    std::cout << "Store vector - unsupported mop: " << mop << std::endl;
    std::abort();
  }
}

void Emulator::executeVector(const Instr &instr, uint32_t wid, std::vector<reg_data_t[3]> &rsdata, std::vector<reg_data_t> &rddata) {
  auto &warp = warps_.at(wid);
  auto func3 = instr.getFunc3();
  auto func6 = instr.getFunc6();

  auto rdest = instr.getRDest();
  auto rsrc0 = instr.getRSrc(0);
  auto rsrc1 = instr.getRSrc(1);
  auto immsrc = sext((Word)instr.getImm(), width_reg);
  auto uimmsrc = (Word)instr.getImm();
  auto vmask = instr.getVmask();
  auto num_threads = arch_.num_threads();

  switch (func3) {
  case 0: { // vector - vector
    switch (func6) {
    case 0: { // vadd.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Add, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 2: { // vsub.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Sub, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 4: { // vminu.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Min, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 5: { // vmin.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Min, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 6: { // vmaxu.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Max, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 7: { // vmax.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Max, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 9: { // vand.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<And, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 10: { // vor.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Or, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 11: { // vxor.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Xor, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 12: { // vrgather.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_gather<uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, false, warp.vlmax, vmask);
      }
    } break;
    case 14: { // vrgatherei16.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_gather<uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, true, warp.vlmax, vmask);
      }
    } break;
    case 16: { // vadc.vvm
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_carry<Adc, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl);
      }
    } break;
    case 17: { // vmadc.vv, vmadc.vvm
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_carry_out<Madc, uint8_t, uint16_t, uint32_t, uint64_t, __uint128_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 18: { // vsbc.vvm
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_carry<Sbc, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl);
      }
    } break;
    case 19: { // vmsbc.vv, vmsbc.vvm
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_carry_out<Msbc, uint8_t, uint16_t, uint32_t, uint64_t, __uint128_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 23: {
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        if (vmask) { // vmv.v.v
          if (rsrc1 != 0) {
            std::cout << "For vmv.v.v vs2 must contain v0." << std::endl;
            std::abort();
          }
          vector_op_vv<Mv, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
        } else { // vmerge.vvm
          vector_op_vv_merge<int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
        }
      }
    } break;
    case 24: { // vmseq.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_mask<Eq, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 25: { // vmsne.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_mask<Ne, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 26: { // vmsltu.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_mask<Lt, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 27: { // vmslt.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_mask<Lt, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 28: { // vmsleu.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_mask<Le, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 29: { // vmsle.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_mask<Le, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 30: { // vmsgtu.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_mask<Gt, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 31: { // vmsgt.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_mask<Gt, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 32: { // vsaddu.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        uint32_t vxsat = this->get_csr(VX_CSR_VXSAT, t, wid);
        vector_op_vv_sat<Sadd, uint8_t, uint16_t, uint32_t, uint64_t, __uint128_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, 2, vxsat);
        this->set_csr(VX_CSR_VXSAT, vxsat, t, wid);
      }
    } break;
    case 33: { // vsadd.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        uint32_t vxsat = this->get_csr(VX_CSR_VXSAT, t, wid);
        vector_op_vv_sat<Sadd, int8_t, int16_t, int32_t, int64_t, __int128_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, 2, vxsat);
        this->set_csr(VX_CSR_VXSAT, vxsat, t, wid);
      }
    } break;
    case 34: { // vssubu.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        uint32_t vxsat = this->get_csr(VX_CSR_VXSAT, t, wid);
        vector_op_vv_sat<Ssubu, uint8_t, uint16_t, uint32_t, uint64_t, __uint128_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, 2, vxsat);
        this->set_csr(VX_CSR_VXSAT, vxsat, t, wid);
      }
    } break;
    case 35: { // vssub.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        uint32_t vxsat = this->get_csr(VX_CSR_VXSAT, t, wid);
        vector_op_vv_sat<Ssub, int8_t, int16_t, int32_t, int64_t, __int128_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, 2, vxsat);
        this->set_csr(VX_CSR_VXSAT, vxsat, t, wid);
      }
    } break;
    case 37: { // vsll.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Sll, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 39: { // vsmul.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        uint32_t vxrm = this->get_csr(VX_CSR_VXRM, t, wid);
        uint32_t vxsat = this->get_csr(VX_CSR_VXSAT, t, wid);
        vector_op_vv_sat<Smul, int8_t, int16_t, int32_t, int64_t, __int128_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, vxrm, vxsat);
        this->set_csr(VX_CSR_VXSAT, vxsat, t, wid);
      }
    } break;
    case 40: { // vsrl.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<SrlSra, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 41: { // vsra.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<SrlSra, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 42: { // vssrl.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        uint32_t vxrm = this->get_csr(VX_CSR_VXRM, t, wid);
        uint32_t vxsat = 0; // saturation is not relevant for this operation
        vector_op_vv_scale<SrlSra, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, vxrm, vxsat);
      }
    } break;
    case 43: { // vssra.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        uint32_t vxrm = this->get_csr(VX_CSR_VXRM, t, wid);
        uint32_t vxsat = 0; // saturation is not relevant for this operation
        vector_op_vv_scale<SrlSra, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, vxrm, vxsat);
      }
    } break;
    case 44: { // vnsrl.wv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        uint32_t vxsat = 0; // saturation is not relevant for this operation
        vector_op_vv_n<SrlSra, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, 2, vxsat);
      }
    } break;
    case 45: { // vnsra.wv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        uint32_t vxsat = 0; // saturation is not relevant for this operation
        vector_op_vv_n<SrlSra, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, 2, vxsat);
      }
    } break;
    case 46: { // vnclipu.wv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        uint32_t vxrm = this->get_csr(VX_CSR_VXRM, t, wid);
        uint32_t vxsat = this->get_csr(VX_CSR_VXSAT, t, wid);
        vector_op_vv_n<Clip, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, vxrm, vxsat);
        this->set_csr(VX_CSR_VXSAT, vxsat, t, wid);
      }
    } break;
    case 47: { // vnclip.wv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        uint32_t vxrm = this->get_csr(VX_CSR_VXRM, t, wid);
        uint32_t vxsat = this->get_csr(VX_CSR_VXSAT, t, wid);
        vector_op_vv_n<Clip, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, vxrm, vxsat);
        this->set_csr(VX_CSR_VXSAT, vxsat, t, wid);
      }
    } break;
    case 48: { // vwredsumu.vs
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_red_w<Add, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 49: { // vwredsum.vs
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_red_w<Add, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    default:
      std::cout << "Unrecognised vector - vector instruction func3: " << func3 << " func6: " << func6 << std::endl;
      std::abort();
    }
  } break;
  case 1: { // float vector - vector
    switch (func6) {
    case 0: { // vfadd.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Fadd, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 2: { // vfsub.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Fsub, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 1:   // vfredusum.vs - treated the same as vfredosum.vs
    case 3: { // vfredosum.vs
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_red<Fadd, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 4: { // vfmin.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Fmin, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 5: { // vfredmin.vs
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_red<Fmin, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 6: { // vfmax.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Fmax, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 7: { // vfredmax.vs
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_red<Fmax, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 8: { // vfsgnj.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Fsgnj, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 9: { // vfsgnjn.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Fsgnjn, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 10: { // vfsgnjx.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Fsgnjx, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 16: { // vfmv.f.s
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &dest = rddata[t].u64;
        vector_op_scalar(dest, warp.vreg_file, rsrc0, rsrc1, warp.vtype.vsew);
        DP(4, "Moved " << +dest << " from: " << +rsrc1 << " to: " << +rdest);
      }
    } break;
    case 18: {
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        switch (rsrc0 >> 3) {
        case 0b00: // vfcvt.xu.f.v, vfcvt.x.f.v, vfcvt.f.xu.v, vfcvt.f.x.v, vfcvt.rtz.xu.f.v, vfcvt.rtz.x.f.v
          vector_op_vix<Fcvt, uint8_t, uint16_t, uint32_t, uint64_t>(rsrc0, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
          break;
        case 0b01: // vfwcvt.xu.f.v, vfwcvt.x.f.v, vfwcvt.f.xu.v, vfwcvt.f.x.v, vfwcvt.f.f.v, vfwcvt.rtz.xu.f.v, vfwcvt.rtz.x.f.v
          vector_op_vix_w<Fcvt, uint8_t, uint16_t, uint32_t, uint64_t>(rsrc0, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
          break;
        case 0b10: { // vfncvt.xu.f.w, vfncvt.x.f.w, vfncvt.f.xu.w, vfncvt.f.x.w, vfncvt.f.f.w, vfncvt.rod.f.f.w, vfncvt.rtz.xu.f.w, vfncvt.rtz.x.f.w
          uint32_t vxrm = this->get_csr(VX_CSR_VXRM, t, wid);
          uint32_t vxsat = 0; // saturation argument is unused
          vector_op_vix_n<Fcvt, uint8_t, uint16_t, uint32_t, uint64_t>(rsrc0, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, vxrm, vxsat);
          break;
        }
        default:
          std::cout << "Fcvt unsupported value for rsrc0: " << rsrc0 << std::endl;
          std::abort();
        }
      }
    } break;
    case 19: { // vfsqrt.v, vfrsqrt7.v, vfrec7.v, vfclass.v
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vix<Funary1, uint8_t, uint16_t, uint32_t, uint64_t>(rsrc0, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 24: { // vmfeq.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_mask<Feq, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 25: { // vmfle.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_mask<Fle, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 27: { // vmflt.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_mask<Flt, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 28: { // vmfne.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_mask<Fne, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 32: { // vfdiv.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Fdiv, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 36: { // vfmul.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Fmul, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 40: { // vfmadd.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Fmadd, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 41: { // vfnmadd.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Fnmadd, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 42: { // vfmsub.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Fmsub, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 43: { // vfnmsub.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Fnmsub, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 44: { // vfmacc.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Fmacc, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 45: { // vfnmacc.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Fnmacc, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 46: { // vfmsac.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Fmsac, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 47: { // vfnmsac.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Fnmsac, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 48: { // vfwadd.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_w<Fadd, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 51:   // vfwredosum.vs - treated the same as vfwredosum.vs
    case 49: { // vfwredusum.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_red_wf<Fadd, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 50: { // vfwsub.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_w<Fsub, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 52: { // vfwadd.wv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_wfv<Fadd, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 54: { // vfwsub.wv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_wfv<Fsub, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 56: { // vfwmul.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_w<Fmul, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 60: { // vfwmacc.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_w<Fmacc, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 61: { // vfwnmacc.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_w<Fnmacc, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 62: { // vfwmsac.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_w<Fmsac, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 63: { // vfwnmsac.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_w<Fnmsac, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    default:
      std::cout << "Unrecognised float vector - vector instruction func3: " << func3 << " func6: " << func6 << std::endl;
      std::abort();
    }
  } break;
  case 2: { // mask vector - vector
    switch (func6) {
    case 0: { // vredsum.vs
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_red<Add, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 1: { // vredand.vs
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_red<And, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 2: { // vredor.vs
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_red<Or, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 3: { // vredxor.vs
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_red<Xor, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 4: { // vredminu.vs
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_red<Min, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 5: { // vredmin.vs
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_red<Min, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 6: { // vredmaxu.vs
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_red<Max, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 7: { // vredmax.vs
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_red<Max, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 8: { // vaaddu.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        uint32_t vxrm = this->get_csr(VX_CSR_VXRM, t, wid);
        uint32_t vxsat = 0; // saturation is not relevant for this operation
        vector_op_vv_sat<Aadd, uint8_t, uint16_t, uint32_t, uint64_t, __uint128_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, vxrm, vxsat);
      }
    } break;
    case 9: { // vaadd.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        uint32_t vxrm = this->get_csr(VX_CSR_VXRM, t, wid);
        uint32_t vxsat = 0; // saturation is not relevant for this operation
        vector_op_vv_sat<Aadd, int8_t, int16_t, int32_t, int64_t, __int128_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, vxrm, vxsat);
      }
    } break;
    case 10: { // vasubu.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        uint32_t vxrm = this->get_csr(VX_CSR_VXRM, t, wid);
        uint32_t vxsat = 0; // saturation is not relevant for this operation
        vector_op_vv_sat<Asub, uint8_t, uint16_t, uint32_t, uint64_t, __uint128_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, vxrm, vxsat);
      }
    } break;
    case 11: { // vasub.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        uint32_t vxrm = this->get_csr(VX_CSR_VXRM, t, wid);
        uint32_t vxsat = 0; // saturation is not relevant for this operation
        vector_op_vv_sat<Asub, int8_t, int16_t, int32_t, int64_t, __int128_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, vxrm, vxsat);
      }
    } break;
    case 16: { // vmv.x.s
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &dest = rddata[t].i;
        vector_op_scalar(dest, warp.vreg_file, rsrc0, rsrc1, warp.vtype.vsew);
        DP(4, "Moved " << +dest << " from: " << +rsrc1 << " to: " << +rdest);
      }
    } break;
    case 18: { // vzext.vf8, vsext.vf8, vzext.vf4, vsext.vf4, vzext.vf2, vsext.vf2
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        bool negativeLmul = warp.vtype.vlmul >> 2;
        uint32_t illegalLmul = negativeLmul && !((8 >> (0x8 - warp.vtype.vlmul)) >> (0x4 - (rsrc0 >> 1)));
        if (illegalLmul) {
          std::cout << "Lmul*vf<1/8 is not supported by vzext and vsext." << std::endl;
          std::abort();
        }
        vector_op_vix_ext<Xunary0>(rsrc0, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 20: { // vid.v
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vid(warp.vreg_file, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 23: { // vcompress.vm
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_compress<uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl);
      }
    } break;
    case 24: { // vmandn.mm
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_mask<AndNot>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vl);
      }
    } break;
    case 25: { // vmand.mm
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_mask<And>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vl);
      }
    } break;
    case 26: { // vmor.mm
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_mask<Or>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vl);
      }
    } break;
    case 27: { // vmxor.mm
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_mask<Xor>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vl);
      }
    } break;
    case 28: { // vmorn.mm
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_mask<OrNot>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vl);
      }
    } break;
    case 29: { // vmnand.mm
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_mask<Nand>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vl);
      }
    } break;
    case 30: { // vmnor.mm
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_mask<Nor>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vl);
      }
    } break;
    case 31: { // vmxnor.mm
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_mask<Xnor>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vl);
      }
    } break;
    case 32: { // vdivu.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Div, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 33: { // vdiv.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Div, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 34: { // vremu.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Rem, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 35: { // vrem.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Rem, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 36: { // vmulhu.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Mulhu, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 37: { // vmul.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Mul, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 38: { // vmulhsu.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Mulhsu, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 39: { // vmulh.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Mulh, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 41: { // vmadd.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Madd, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 43: { // vnmsub.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Nmsub, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 45: { // vmacc.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Macc, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 47: { // vnmsac.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Nmsac, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 48: { // vwaddu.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_w<Add, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 49: { // vwadd.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_w<Add, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 50: { // vwsubu.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_w<Sub, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 51: { // vwsub.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_w<Sub, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 52: { // vwaddu.wv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_wv<Add, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 53: { // vwadd.wv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_wv<Add, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 54: { // vwsubu.wv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_wv<Sub, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 55: { // vwsub.wv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_wv<Sub, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 56: { // vwmulu.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_w<Mul, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 58: { // vwmulsu.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_w<Mulsu, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 59: { // vwmul.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_w<Mul, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 60: { // vwmaccu.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_w<Macc, uint8_t, uint16_t, uint32_t, uint64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 61: { // vwmacc.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_w<Macc, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 63: { // vwmaccsu.vv
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv_w<Maccsu, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    default:
      std::cout << "Unrecognised mask vector - vector instruction func3: " << func3 << " func6: " << func6 << std::endl;
      std::abort();
    }
  } break;
  case 3: { // vector - immidiate
    switch (func6) {
    case 0: { // vadd.vi
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vix<Add, int8_t, int16_t, int32_t, int64_t>(immsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 3: { // vrsub.vi
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vix<Rsub, int8_t, int16_t, int32_t, int64_t>(immsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 9: { // vand.vi
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vix<And, int8_t, int16_t, int32_t, int64_t>(immsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 10: { // vor.vi
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vix<Or, int8_t, int16_t, int32_t, int64_t>(immsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 11: { // vxor.vi
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vix<Xor, int8_t, int16_t, int32_t, int64_t>(immsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 12: { // vrgather.vi
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vix_gather<uint8_t, uint16_t, uint32_t, uint64_t>(uimmsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, warp.vlmax, vmask);
      }
    } break;
    case 14: { // vslideup.vi
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vix_slide<uint8_t, uint16_t, uint32_t, uint64_t>(uimmsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, 0, vmask, false);
      }
    } break;
    case 15: { // vslidedown.vi
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vix_slide<uint8_t, uint16_t, uint32_t, uint64_t>(uimmsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, warp.vlmax, vmask, false);
      }
    } break;
    case 16: { // vadc.vim
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vix_carry<Adc, uint8_t, uint16_t, uint32_t, uint64_t>(immsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl);
      }
    } break;
    case 17: { // vmadc.vi, vmadc.vim
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vix_carry_out<Madc, uint8_t, uint16_t, uint32_t, uint64_t, __uint128_t>(immsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 23: { // vmv.v.i
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        if (vmask) { // vmv.v.i
          if (rsrc0 != 0) {
            std::cout << "For vmv.v.i vs2 must contain v0." << std::endl;
            std::abort();
          }
          vector_op_vix<Mv, int8_t, int16_t, int32_t, int64_t>(immsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, vmask);
        } else { // vmerge.vim
          vector_op_vix_merge<int8_t, int16_t, int32_t, int64_t>(immsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, vmask);
        }
      }
    } break;
    case 24: { // vmseq.vi
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vix_mask<Eq, int8_t, int16_t, int32_t, int64_t>(immsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 25: { // vmsne.vi
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vix_mask<Ne, int8_t, int16_t, int32_t, int64_t>(immsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 26: { // vmsltu.vi
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vix_mask<Lt, uint8_t, uint16_t, uint32_t, uint64_t>(immsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 27: { // vmslt.vi
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vix_mask<Lt, int8_t, int16_t, int32_t, int64_t>(immsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 28: { // vmsleu.vi
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vix_mask<Le, uint8_t, uint16_t, uint32_t, uint64_t>(immsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 29: { // vmsle.vi
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vix_mask<Le, int8_t, int16_t, int32_t, int64_t>(immsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 30: { // vmsgtu.vi
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vix_mask<Gt, uint8_t, uint16_t, uint32_t, uint64_t>(immsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 31: { // vmsgt.vi
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vix_mask<Gt, int8_t, int16_t, int32_t, int64_t>(immsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 32: { // vsaddu.vi
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        uint32_t vxsat = this->get_csr(VX_CSR_VXSAT, t, wid);
        vector_op_vix_sat<Sadd, uint8_t, uint16_t, uint32_t, uint64_t, __uint128_t>(immsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, vmask, 2, vxsat);
        this->set_csr(VX_CSR_VXSAT, vxsat, t, wid);
      }
    } break;
    case 33: { // vsadd.vi
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        uint32_t vxsat = this->get_csr(VX_CSR_VXSAT, t, wid);
        vector_op_vix_sat<Sadd, int8_t, int16_t, int32_t, int64_t, __int128_t>(immsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, vmask, 2, vxsat);
        this->set_csr(VX_CSR_VXSAT, vxsat, t, wid);
      }
    } break;
    case 37: { // vsll.vi
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vix<Sll, int8_t, int16_t, int32_t, int64_t>(immsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 39: { // vmv1r.v, vmv2r.v, vmv4r.v, vmv8r.v
      for (uint32_t t = 0; t < num_threads; ++t) {
        uint32_t nreg = (immsrc & 0b111) + 1;
        if (nreg != 1 && nreg != 2 && nreg != 4 && nreg != 8) {
          std::cout << "Reserved value for nreg: " << nreg << std::endl;
          std::abort();
        }
        if (!warp.tmask.test(t))
          continue;
        vector_op_vv<Mv, int8_t, int16_t, int32_t, int64_t>(warp.vreg_file, rsrc0, rsrc1, rdest, warp.vtype.vsew, nreg * VLEN / warp.vtype.vsew, vmask);
      }
    } break;
    case 40: { // vsrl.vi
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vix<SrlSra, uint8_t, uint16_t, uint32_t, uint64_t>(immsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 41: { // vsra.vi
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        vector_op_vix<SrlSra, int8_t, int16_t, int32_t, int64_t>(immsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 42: { // vssrl.vi
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        uint32_t vxrm = this->get_csr(VX_CSR_VXRM, t, wid);
        uint32_t vxsat = 0; // saturation is not relevant for this operation
        vector_op_vix_scale<SrlSra, uint8_t, uint16_t, uint32_t, uint64_t>(immsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, vmask, vxrm, vxsat);
      }
    } break;
    case 43: { // vssra.vi
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        uint32_t vxrm = this->get_csr(VX_CSR_VXRM, t, wid);
        uint32_t vxsat = 0; // saturation is not relevant for this operation
        vector_op_vix_scale<SrlSra, int8_t, int16_t, int32_t, int64_t>(immsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, vmask, vxrm, vxsat);
      }
    } break;
    case 44: { // vnsrl.wi
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        uint32_t vxsat = 0; // saturation is not relevant for this operation
        vector_op_vix_n<SrlSra, uint8_t, uint16_t, uint32_t, uint64_t>(immsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, vmask, 2, vxsat);
      }
    } break;
    case 45: { // vnsra.wi
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        uint32_t vxsat = 0; // saturation is not relevant for this operation
        vector_op_vix_n<SrlSra, int8_t, int16_t, int32_t, int64_t>(immsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, vmask, 2, vxsat);
      }
    } break;
    case 46: { // vnclipu.wi
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        uint32_t vxrm = this->get_csr(VX_CSR_VXRM, t, wid);
        uint32_t vxsat = this->get_csr(VX_CSR_VXSAT, t, wid);
        vector_op_vix_n<Clip, uint8_t, uint16_t, uint32_t, uint64_t>(immsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, vmask, vxrm, vxsat);
        this->set_csr(VX_CSR_VXSAT, vxsat, t, wid);
      }
    } break;
    case 47: { // vnclip.wi
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        uint32_t vxrm = this->get_csr(VX_CSR_VXRM, t, wid);
        uint32_t vxsat = this->get_csr(VX_CSR_VXSAT, t, wid);
        vector_op_vix_n<Clip, int8_t, int16_t, int32_t, int64_t>(immsrc, warp.vreg_file, rsrc0, rdest, warp.vtype.vsew, warp.vl, vmask, vxrm, vxsat);
        this->set_csr(VX_CSR_VXSAT, vxsat, t, wid);
      }
    } break;
    default:
      std::cout << "Unrecognised vector - immidiate instruction func3: " << func3 << " func6: " << func6 << std::endl;
      std::abort();
    }
  } break;
  case 4: {
    switch (func6) {
    case 0: { // vadd.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix<Add, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 2: { // vsub.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix<Sub, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 3: { // vrsub.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix<Rsub, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 4: { // vminu.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix<Min, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 5: { // vmin.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix<Min, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 6: { // vmaxu.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix<Max, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 7: { // vmax.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix<Max, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 9: { // vand.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix<And, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 10: { // vor.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix<Or, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 11: { // vxor.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix<Xor, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 12: { // vrgather.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_gather<uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, warp.vlmax, vmask);
      }
    } break;
    case 14: { // vslideup.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_slide<uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, 0, vmask, false);
      }
    } break;
    case 15: { // vslidedown.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_slide<uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, warp.vlmax, vmask, false);
      }
    } break;
    case 16: { // vadc.vxm
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_carry<Adc, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl);
      }
    } break;
    case 17: { // vmadc.vx, vmadc.vxm
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_carry_out<Madc, uint8_t, uint16_t, uint32_t, uint64_t, __uint128_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 18: { // vsbc.vxm
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_carry<Sbc, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl);
      }
    } break;
    case 19: { // vmsbc.vx, vmsbc.vxm
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_carry_out<Msbc, uint8_t, uint16_t, uint32_t, uint64_t, __uint128_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 23: {
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        if (vmask) { // vmv.v.x
          if (rsrc1 != 0) {
            std::cout << "For vmv.v.x vs2 must contain v0." << std::endl;
            std::abort();
          }
          auto &src1 = warp.ireg_file.at(t).at(rsrc0);
          vector_op_vix<Mv, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
        } else { // vmerge.vxm
          auto &src1 = warp.ireg_file.at(t).at(rsrc0);
          vector_op_vix_merge<int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
        }
      }
    } break;
    case 24: { // vmseq.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_mask<Eq, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 25: { // vmsne.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_mask<Ne, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 26: { // vmsltu.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_mask<Lt, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 27: { // vmslt.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_mask<Lt, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 28: { // vmsleu.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_mask<Le, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 29: { // vmsle.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_mask<Le, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 30: { // vmsgtu.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_mask<Gt, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 31: { // vmsgt.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_mask<Gt, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 32: { // vsaddu.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        uint32_t vxsat = this->get_csr(VX_CSR_VXSAT, t, wid);
        vector_op_vix_sat<Sadd, uint8_t, uint16_t, uint32_t, uint64_t, __uint128_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, 2, vxsat);
        this->set_csr(VX_CSR_VXSAT, vxsat, t, wid);
      }
    } break;
    case 33: { // vsadd.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        uint32_t vxsat = this->get_csr(VX_CSR_VXSAT, t, wid);
        vector_op_vix_sat<Sadd, int8_t, int16_t, int32_t, int64_t, __int128_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, 2, vxsat);
        this->set_csr(VX_CSR_VXSAT, vxsat, t, wid);
      }
    } break;
    case 34: { // vssubu.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        uint32_t vxsat = this->get_csr(VX_CSR_VXSAT, t, wid);
        vector_op_vix_sat<Ssubu, uint8_t, uint16_t, uint32_t, uint64_t, __uint128_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, 2, vxsat);
        this->set_csr(VX_CSR_VXSAT, vxsat, t, wid);
      }
    } break;
    case 35: { // vssub.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        uint32_t vxsat = this->get_csr(VX_CSR_VXSAT, t, wid);
        vector_op_vix_sat<Ssub, int8_t, int16_t, int32_t, int64_t, __int128_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, 2, vxsat);
        this->set_csr(VX_CSR_VXSAT, vxsat, t, wid);
      }
    } break;
    case 37: { // vsll.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix<Sll, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 39: { // vsmul.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        uint32_t vxrm = this->get_csr(VX_CSR_VXRM, t, wid);
        uint32_t vxsat = this->get_csr(VX_CSR_VXSAT, t, wid);
        vector_op_vix_sat<Smul, int8_t, int16_t, int32_t, int64_t, __int128_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, vxrm, vxsat);
        this->set_csr(VX_CSR_VXSAT, vxsat, t, wid);
      }
    } break;
    case 40: { // vsrl.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix<SrlSra, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 41: { // vsra.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix<SrlSra, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 42: { // vssrl.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        uint32_t vxrm = this->get_csr(VX_CSR_VXRM, t, wid);
        uint32_t vxsat = 0; // saturation is not relevant for this operation
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_scale<SrlSra, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, vxrm, vxsat);
      }
    } break;
    case 43: { // vssra.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        uint32_t vxrm = this->get_csr(VX_CSR_VXRM, t, wid);
        uint32_t vxsat = 0; // saturation is not relevant for this operation
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_scale<SrlSra, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, vxrm, vxsat);
      }
    } break;
    case 44: { // vnsrl.wx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        uint32_t vxsat = 0; // saturation is not relevant for this operation
        vector_op_vix_n<SrlSra, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, 2, vxsat);
      }
    } break;
    case 45: { // vnsra.wx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        uint32_t vxsat = 0; // saturation is not relevant for this operation
        vector_op_vix_n<SrlSra, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, 2, vxsat);
      }
    } break;
    case 46: { // vnclipu.wx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        uint32_t vxrm = this->get_csr(VX_CSR_VXRM, t, wid);
        uint32_t vxsat = this->get_csr(VX_CSR_VXSAT, t, wid);
        vector_op_vix_n<Clip, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, vxrm, vxsat);
        this->set_csr(VX_CSR_VXSAT, vxsat, t, wid);
      }
    } break;
    case 47: { // vnclip.wx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        uint32_t vxrm = this->get_csr(VX_CSR_VXRM, t, wid);
        uint32_t vxsat = this->get_csr(VX_CSR_VXSAT, t, wid);
        vector_op_vix_n<Clip, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, vxrm, vxsat);
        this->set_csr(VX_CSR_VXSAT, vxsat, t, wid);
      }
    } break;
    default:
      std::cout << "Unrecognised vector - scalar instruction func3: " << func3 << " func6: " << func6 << std::endl;
      std::abort();
    }
  } break;
  case 5: { // float vector - scalar
    switch (func6) {
    case 0: { // vfadd.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix<Fadd, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 2: { // vfsub.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix<Fsub, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 4: { // vfmin.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix<Fmin, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 6: { // vfmax.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix<Fmax, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 8: { // vfsgnj.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix<Fsgnj, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 9: { // vfsgnjn.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix<Fsgnjn, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 10: { // vfsgnjx.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix<Fsgnjx, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 14: { // vfslide1up.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix_slide<uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, 0, vmask, true);
      }
    } break;
    case 15: { // vfslide1down.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix_slide<uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, warp.vlmax, vmask, true);
      }
    } break;
    case 16: { // vfmv.s.f
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        if (rsrc1 != 0) {
          std::cout << "For vfmv.s.f vs2 must contain v0." << std::endl;
          std::abort();
        }
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix<Mv, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, std::min(warp.vl, (uint32_t)1), vmask);
      }
    } break;
    case 24: { // vmfeq.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix_mask<Feq, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 23: {
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        if (vmask) { // vfmv.v.f
          if (rsrc1 != 0) {
            std::cout << "For vfmv.v.f vs2 must contain v0." << std::endl;
            std::abort();
          }
          auto &src1 = warp.freg_file.at(t).at(rsrc0);
          vector_op_vix<Mv, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
        } else { // vfmerge.vfm
          auto &src1 = warp.freg_file.at(t).at(rsrc0);
          vector_op_vix_merge<int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
        }
      }
    } break;
    case 25: { // vmfle.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix_mask<Fle, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 27: { // vmflt.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix_mask<Flt, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 28: { // vmfne.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix_mask<Fne, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 29: { // vmfgt.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix_mask<Fgt, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 31: { // vmfge.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix_mask<Fge, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 32: { // vfdiv.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix<Fdiv, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 33: { // vfrdiv.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix<Frdiv, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 36: { // vfmul.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix<Fmul, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 39: { // vfrsub.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix<Frsub, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 40: { // vfmadd.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix<Fmadd, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 41: { // vfnmadd.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix<Fnmadd, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 42: { // vfmsub.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix<Fmsub, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 43: { // vfnmsub.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix<Fnmsub, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 44: { // vfmacc.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix<Fmacc, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 45: { // vfnmacc.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix<Fnmacc, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 46: { // vfmsac.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix<Fmsac, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 47: { // vfnmsac.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix<Fnmsac, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 48: { // vfwadd.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix_w<Fadd, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 50: { // vfwsub.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix_w<Fsub, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 52: { // vfwadd.wf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        uint64_t src1_d = rv_ftod(src1);
        vector_op_vix_wx<Fadd, uint8_t, uint16_t, uint32_t, uint64_t>(src1_d, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 54: { // vfwsub.wf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        uint64_t src1_d = rv_ftod(src1);
        vector_op_vix_wx<Fsub, uint8_t, uint16_t, uint32_t, uint64_t>(src1_d, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 56: { // vfwmul.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix_w<Fmul, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 60: { // vfwmacc.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix_w<Fmacc, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 61: { // vfwnmacc.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix_w<Fnmacc, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 62: { // vfwmsac.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix_w<Fmsac, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 63: { // vfwnmsac.vf
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.freg_file.at(t).at(rsrc0);
        vector_op_vix_w<Fnmsac, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    default:
      std::cout << "Unrecognised float vector - scalar instruction func3: " << func3 << " func6: " << func6 << std::endl;
      std::abort();
    }
  } break;
  case 6: {
    switch (func6) {
    case 8: { // vaaddu.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        uint32_t vxrm = this->get_csr(VX_CSR_VXRM, t, wid);
        uint32_t vxsat = 0; // saturation is not relevant for this operation
        vector_op_vix_sat<Aadd, uint8_t, uint16_t, uint32_t, uint64_t, __uint128_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, vxrm, vxsat);
      }
    } break;
    case 9: { // vaadd.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        uint32_t vxrm = this->get_csr(VX_CSR_VXRM, t, wid);
        uint32_t vxsat = 0; // saturation is not relevant for this operation
        vector_op_vix_sat<Aadd, int8_t, int16_t, int32_t, int64_t, __int128_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, vxrm, vxsat);
      }
    } break;
    case 10: { // vasubu.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        uint32_t vxrm = this->get_csr(VX_CSR_VXRM, t, wid);
        uint32_t vxsat = 0; // saturation is not relevant for this operation
        vector_op_vix_sat<Asub, uint8_t, uint16_t, uint32_t, uint64_t, __uint128_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, vxrm, vxsat);
      }
    } break;
    case 11: { // vasub.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        uint32_t vxrm = this->get_csr(VX_CSR_VXRM, t, wid);
        uint32_t vxsat = 0; // saturation is not relevant for this operation
        vector_op_vix_sat<Asub, int8_t, int16_t, int32_t, int64_t, __int128_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask, vxrm, vxsat);
      }
    } break;
    case 14: { // vslide1up.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_slide<uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, 0, vmask, true);
      }
    } break;
    case 15: { // vslide1down.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_slide<uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, warp.vlmax, vmask, true);
      }
    } break;
    case 16: { // vmv.s.x
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        if (rsrc1 != 0) {
          std::cout << "For vmv.s.x vs2 must contain v0." << std::endl;
          std::abort();
        }
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix<Mv, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, std::min(warp.vl, (uint32_t)1), vmask);
      }
    } break;
    case 32: { // vdivu.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix<Div, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 33: { // vdiv.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix<Div, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 34: { // vremu.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix<Rem, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 35: { // vrem.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix<Rem, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 36: { // vmulhu.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix<Mulhu, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 37: { // vmul.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix<Mul, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 38: { // vmulhsu.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix<Mulhsu, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 39: { // vmulh.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix<Mulh, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 41: { // vmadd.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix<Madd, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 43: { // vnmsub.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix<Nmsub, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 45: { // vmacc.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix<Macc, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 47: { // vnmsac.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix<Nmsac, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 48: { // vwaddu.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_w<Add, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 49: { // vwadd.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_w<Add, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 50: { // vwsubu.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_w<Sub, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 51: { // vwsub.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_w<Sub, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 52: { // vwaddu.wx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_wx<Add, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 53: { // vwadd.wx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        Word src1_ext = sext(src1, warp.vtype.vsew);
        vector_op_vix_wx<Add, int8_t, int16_t, int32_t, int64_t>(src1_ext, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 54: { // vwsubu.wx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_wx<Sub, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 55: { // vwsub.wx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        Word &src1 = warp.ireg_file.at(t).at(rsrc0);
        Word src1_ext = sext(src1, warp.vtype.vsew);
        vector_op_vix_wx<Sub, int8_t, int16_t, int32_t, int64_t>(src1_ext, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 56: { // vwmulu.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_w<Mul, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 58: { // vwmulsu.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_w<Mulsu, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 59: { // vwmul.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_w<Mul, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 60: { // vwmaccu.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_w<Macc, uint8_t, uint16_t, uint32_t, uint64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 61: { // vwmacc.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_w<Macc, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 62: { // vwmaccus.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_w<Maccus, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    case 63: { // vwmaccsu.vx
      for (uint32_t t = 0; t < num_threads; ++t) {
        if (!warp.tmask.test(t))
          continue;
        auto &src1 = warp.ireg_file.at(t).at(rsrc0);
        vector_op_vix_w<Maccsu, int8_t, int16_t, int32_t, int64_t>(src1, warp.vreg_file, rsrc1, rdest, warp.vtype.vsew, warp.vl, vmask);
      }
    } break;
    default:
      std::cout << "Unrecognised vector - scalar instruction func3: " << func3 << " func6: " << func6 << std::endl;
      std::abort();
    }
  } break;
  case 7: {
    uint32_t vma = instr.getVma();
    uint32_t vta = instr.getVta();
    uint32_t vsew = instr.getVsew();
    uint32_t vlmul = instr.getVlmul();

    if (!instr.hasZimm()) { // vsetvl
      uint32_t zimm = rsdata[0][1].u;
      vlmul = zimm & mask_v_lmul;
      vsew = (zimm >> shift_v_sew) & mask_v_sew;
      vta = (zimm >> shift_v_ta) & mask_v_ta;
      vma = (zimm >> shift_v_ma) & mask_v_ma;
    }

    bool negativeLmul = vlmul >> 2;
    uint32_t vlenDividedByLmul = VLEN >> (0x8 - vlmul);
    uint32_t vlenMultipliedByLmul = VLEN << vlmul;
    uint32_t vlenTimesLmul = negativeLmul ? vlenDividedByLmul : vlenMultipliedByLmul;
    uint32_t vsew_bits = 1 << (3 + vsew);
    warp.vlmax = vlenTimesLmul / vsew_bits;
    warp.vtype.vill = (vsew_bits > XLEN) || (warp.vlmax < (VLEN / XLEN));

    Word s0 = instr.getImm(); // vsetivli
    if (!instr.hasImm()) {    // vsetvli/vsetvl
      s0 = rsdata[0][0].u;
    }

    DP(4, "Vset(i)vl(i) - vill: " << +warp.vtype.vill << " vma: " << vma << " vta: " << vta << " lmul: " << vlmul << " sew: " << vsew << " s0: " << s0 << " vlmax: " << warp.vlmax);
    warp.vl = std::min(s0, warp.vlmax);

    if (warp.vtype.vill) {
      this->set_csr(VX_CSR_VTYPE, (Word)1 << (XLEN - 1), 0, wid);
      warp.vtype.vma = 0;
      warp.vtype.vta = 0;
      warp.vtype.vsew = 0;
      warp.vtype.vlmul = 0;
      this->set_csr(VX_CSR_VL, 0, 0, wid);
      rddata[0].i = warp.vl;
    } else {
      warp.vtype.vma = vma;
      warp.vtype.vta = vta;
      warp.vtype.vsew = vsew_bits;
      warp.vtype.vlmul = vlmul;
      Word vtype_ = vlmul;
      vtype_ |= vsew << shift_v_sew;
      vtype_ |= vta << shift_v_ta;
      vtype_ |= vma << shift_v_ma;
      this->set_csr(VX_CSR_VTYPE, vtype_, 0, wid);
      this->set_csr(VX_CSR_VL, warp.vl, 0, wid);
      rddata[0].i = warp.vl;
    }
  }
    this->set_csr(VX_CSR_VSTART, 0, 0, wid);
    break;
  default:
    std::cout << "Unrecognised vector instruction func3: " << func3 << " func6: " << func6 << std::endl;
    std::abort();
  }
}
#endif
// --- End of content from sim/simx/vpu.cpp ---

